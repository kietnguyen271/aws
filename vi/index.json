[{"uri":"https://thienluhoan.github.io/workshop-template/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Tuấn Kiệt\nSố điện thoại: 0977957462\nEmail: kietntse183979@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 28/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/","title":"AWS Cloud Day Vietnam - AI Edition 2025","tags":[],"description":"","content":"AWS Cloud Day Vietnam - AI Edition 2025 - Ngày: 18 tháng 9, 2025 - Địa điểm: Số 2 đường Hải Triều, Phường Bến Nghé, Quận 1, TP. Hồ Chí Minh\nTổng quan sự kiện Một sự kiện quan trọng dành cho cộng đồng công nghệ và doanh nghiệp Việt Nam, tập trung vào việc thúc đẩy chuyển đổi số thông qua sự hội tụ của Điện toán đám mây và Trí tuệ nhân tạo.\nMục tiêu chính:\nPhổ cập AI Tạo sinh: Đưa GenAI từ khái niệm đến ứng dụng thực tế, có nhận thức theo ngữ cảnh cho doanh nghiệp. Gắn kết Kinh doanh \u0026amp; CNTT: Thu hẹp khoảng cách giữa mục tiêu kinh doanh và CNTT, đặc biệt trong lĩnh vực Dịch vụ Tài chính. Thúc đẩy Hiện đại hóa: Cung cấp lộ trình hiện đại hóa theo đặc thù ngành để di chuyển và phát triển ứng dụng cloud-native. Tăng cường Bảo mật: Thúc đẩy tư duy \u0026ldquo;bảo mật ngay từ thiết kế\u0026rdquo; trong toàn bộ vòng đời ứng dụng. Bài học và Erkenntnisse chính Dữ liệu là Yếu tố Tạo nên Sự khác biệt: Một chiến lược dữ liệu toàn diện là điều kiện tiên quyết cho sự thành công của AI Tạo sinh. Hiện đại hóa là một Hành trình Liên tục: Mục tiêu không chỉ là di chuyển mà là \u0026ldquo;Di chuyển để Vận hành\u0026rdquo; và đổi mới không ngừng. Công nghệ phải do Kinh doanh dẫn dắt: Các sáng kiến công nghệ phải được thúc đẩy bởi các kết quả kinh doanh rõ ràng. Bảo mật là Trách nhiệm của Mọi người: Bảo mật phải được tích hợp ngay từ dòng mã đầu tiên. Ứng dụng vào Công việc Kiểm tra Mức độ sẵn sàng của Dữ liệu: Đánh giá chiến lược dữ liệu hiện tại của chúng tôi để đảm bảo nó có thể hỗ trợ các sáng kiến GenAI trong tương lai. Thử nghiệm GenAI trong DevOps: Thử nghiệm với việc tạo mã do AI điều khiển và kiểm thử tự động để cải thiện tốc độ phát triển. Đối chiếu các Nỗ lực Hiện đại hóa: Phân tích các nghiên cứu điển hình từ Honda Việt Nam (di chuyển SAP) và Masterise Group (di chuyển VMware) để hoàn thiện lộ trình hiện đại hóa của chúng tôi. Triển khai \u0026ldquo;Bảo mật ở Quy mô lớn\u0026rdquo;: Tích hợp các công cụ bảo mật và các phương pháp hay nhất trong toàn bộ vòng đời phát triển. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.1-introduction/","title":"5.1 Introduction","tags":[],"description":"","content":"Module 1: Giới Thiệu Hạ Tầng Smoking Cessation Platform Mục tiêu Module Hiểu kiến trúc AWS toàn bộ hệ thống Nắm các thành phần chính của nền tảng Tìm hiểu flow dữ liệu giữa các service Chuẩn bị cho các module tiếp theo Kiến Trúc Hệ Thống Tổng Quát (Hybrid - EC2 + Lambda) Sơ đồ Kiến Trúc AWS Architecture Type: Hybrid (EC2 + Serverless Lambda) Deployment Pattern: EC2 for stateful services, Lambda for event-driven tasks\n[workshop\\assets\\architecture.png]\nCác Thành Phần Chính 1. Frontend Layer (React + Vite) Hosting: S3 + CloudFront\nFeatures:\nResponsive UI cho Web \u0026amp; Mobile Real-time Chat với WebSocket User Authentication (Cognito) Progress Tracking Dashboard Coach Management Interface 2. API Gateway Layer REST API: /api/v1/* endpoints WebSocket: /ws endpoints cho real-time chat\nResponsibilities:\nRequest routing Authentication validation Rate limiting CORS handling 3. Backend Layer (Hybrid: EC2 + Lambda) EC2 Application Servers (Always-on):\nuser-cessation service (Port 8000)\nUser profiles, progress tracking Coaching session management Statistics \u0026amp; analytics social-media service (Port 8000)\nSocial features Notifications Community management Lambda Functions (Event-driven):\nFile Upload Lambda\nHandle image/file uploads to S3 Payment Processing Lambda\nProcess payments \u0026amp; subscriptions Specific Trigger Functions\nWebhooks Scheduled tasks 4. WebSocket \u0026amp; Real-time Layer NLB (Network Load Balancer):\nHandles persistent WebSocket connections Port 443 (HTTPS) Distributes real-time chat traffic Integration with EC2 backend servers 5. Database Layer (EC2-hosted) PostgreSQL Server (DB-PG):\nUser profiles \u0026amp; authentication Progress tracking data Coaching session records Relational data MongoDB Server (DB-Mongo):\nChat message history Social media content Message metadata Flexible schema data 6. Security Layer AWS Cognito: User authentication \u0026amp; authorization IAM Roles: Service-to-service permissions VPC: Network isolation (private subnets for databases) Security Groups: Firewall rules for EC2 \u0026amp; databases SSL/TLS: Data encryption in transit \u0026amp; at rest NLB Security Group: Restricts access to WebSocket port 7. Monitoring \u0026amp; Logging CloudWatch: Logs \u0026amp; Metrics for all services CloudTrail: API audit trail EC2 Instance Monitoring: CPU, memory, disk usage Database Monitoring: Query performance, connections Alarms: Performance \u0026amp; health alerts User Journeys \u0026amp; Data Flow Journey 1: User Registration \u0026amp; Login 1. User đến trang đăng ký ↓ 2. Frontend gửi credentials → API Gateway → Lambda (Auth Service) ↓ 3. Lambda validate \u0026amp; create user trong PostgreSQL (EC2) ↓ 4. AWS Cognito tạo user account ↓ 5. Lambda return access token \u0026amp; refresh token ↓ 6. Frontend lưu token → có quyền truy cập API Journey 2: Real-time Chat 1. User A gửi message ↓ 2. Message được gửi → API Gateway WebSocket endpoint ↓ 3. Lambda (Chat Service) xử lý message ↓ 4. Lưu message vào MongoDB (EC2) ↓ 5. WebSocket broadcast message đến User B (connected) ↓ 6. User B nhận message real-time Journey 3: Progress Tracking 1. User update progress data (e.g., smoke-free days) ↓ 2. Frontend gửi → API Gateway → Lambda (User Service) ↓ 3. Lambda validate \u0026amp; update PostgreSQL (EC2) ↓ 4. Coach nhận notification (thông qua WebSocket) ↓ 5. Dashboard cập nhật real-time Các Công Nghệ \u0026amp; Services Thành Phần Service Chi Tiết Frontend Hosting S3 + CloudFront Static website hosting + CDN Authentication Cognito User authentication \u0026amp; SSO API Management API Gateway REST API routing Compute (Always-on) EC2 (t4g.small) Main application servers Compute (Event-driven) Lambda Specific functions (upload, payment) Real-time NLB + WebSocket WebSocket connections \u0026amp; messaging Database (SQL) EC2 + PostgreSQL User data, relational data Database (NoSQL) EC2 + MongoDB Chat history, social data Storage S3 File uploads \u0026amp; assets Security VPC, Security Groups, IAM Network isolation \u0026amp; access control Monitoring CloudWatch Logs, metrics, alarms CDN CloudFront Content delivery network Các Module Tiếp Theo Module 2: Prerequisites - Chuẩn bị tài khoản \u0026amp; tools Module 3: Setup Cognito - User authentication Module 4: Setup Lambda - Backend functions Module 5: Setup API Gateway - API endpoints Module 6: Verify EC2 Servers \u0026amp; Databases - PostgreSQL + MongoDB on EC2 Module 7: Setup S3 + CloudFront - Frontend hosting Module 8: Setup VPC \u0026amp; Security - Network security Module 9: Monitoring \u0026amp; Logging - System observability Module 10: Cleanup - Xóa resources \u0026amp; cost optimization Checklist Hiểu kiến trúc AWS tổng quát Nắm 6 thành phần chính Hiểu 3 user journeys chính Sẵn sàng cho Module 2 Notes Hệ thống sử dụng Serverless Architecture - không cần quản lý servers Mọi service đều auto-scaling theo demand Pay-as-you-go pricing model Highly available \u0026amp; disaster recovery ready "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"AWS DevOps \u0026amp; Developer Productivity Blog\nTăng tốc phát triển với quyền truy cập an toàn vào Amazon Q Developer bằng PingIdentity by Sid Vantair on 19 JUN 2025 in Amazon Q, AWS IAM Identity Center, Generative AI, Technical How-to Permalink Các khách hàng đang sử dụng Amazon Q Developer, một công cụ hỗ trợ lập trình được tăng cường bởi Generative AI, thường cần xác thực thông qua các nhà cung cấp danh tính (Identity Provider – IdP) hiện có như PingIdentity. Bằng cách tận dụng AWS IAM Identity Center, các tổ chức có thể cho phép nhà phát triển của họ truy cập Amazon Q Developer bằng chính thông tin đăng nhập PingIdentity sẵn có, giúp đơn giản hóa quy trình xác thực và loại bỏ nhu cầu đăng nhập riêng biệt.\nAmazon Q Developer có thể trò chuyện về mã nguồn, cung cấp gợi ý hoàn thiện mã trực tiếp (inline code completions), và tạo mới mã nguồn. Nó cũng quét mã của bạn để tìm lỗ hổng bảo mật và thực hiện cải thiện mã, bao gồm cập nhật ngôn ngữ, gỡ lỗi (debugging) và tối ưu hóa.\nAmazon Q Developer có hai cấp độ. Free Tier được cung cấp miễn phí cho mục đích cá nhân. Pro Tier là phiên bản trả phí, cung cấp các tính năng như kiểm soát truy cập ở cấp độ doanh nghiệp, bảng điều khiển phân tích (analytics dashboard), tùy chỉnh và giới hạn sử dụng cao hơn.\nCác tổ chức kích hoạt Pro Tier của Amazon Q Developer cho nhà phát triển của mình thường xác thực thông qua AWS IAM Identity Center. Cách tiếp cận này phổ biến vì khả năng liên kết (federate) với các nhà cung cấp danh tính bên ngoài.\nTrong bài viết này, chúng tôi sẽ hướng dẫn bạn cách thiết lập PingIdentity làm external IdP cho IAM Identity Center và cho phép các nhà phát triển truy cập Amazon Q Developer bằng thông tin đăng nhập PingIdentity hiện có của họ. các nhà phát triển truy cập Amazon Q Developer bằng thông tin đăng nhập PingIdentity hiện có của họ.\nCác hoạt động\nHình 1 – Tổng quan giải pháp\nThe business challenge Quy trình xác thực diễn ra như sau: Nhà phát triển khởi tạo yêu cầu truy cập Amazon Q Developer.\nIAM Identity Center kiểm tra trạng thái xác thực.\nNếu chưa được xác thực, người dùng sẽ được chuyển hướng đến trang đăng nhập PingIdentity.\nNhà phát triển nhập thông tin đăng nhập PingIdentity.\nPingIdentity xác thực thông tin và gửi phản hồi SAML.\nIAM Identity Center xác minh phản hồi SAML.\nKhi xác minh thành công, quyền truy cập Amazon Q Developer được cấp.\nNhà phát triển bắt đầu sử dụng Amazon Q Developer.\nYêu cầu trước Tài khoản AWS Môi trường PingIdentity có người dùng và nhóm đã được thiết lập sẵn để truy cập Amazon Q Developer IAM Identity Center Gói đăng ký Amazon Q Developer bản Pro Tier Hướng dẫn thực hiện Trong phần này, chúng ta sẽ thực hành cách tạo kết nối dựa trên SAML giữa PingIdentity và IAM Identity Center, giúp bạn có thể truy cập Amazon Q Developer dễ dàng bằng thông tin đăng nhập PingIdentity của mình.\nLưu ý: Bạn sẽ cần chuyển qua lại giữa cổng quản trị PingIdentity và IAM Identity Center trên trình duyệt.\nNên mở hai tab trình duyệt riêng biệt cho từng bảng điều khiển để thao tác thuận tiện hơn.\nBước 1: Kích hoạt AWS Single Sign-On trong PingIdentity Bước này bao gồm việc bật ứng dụng AWS Single Sign-On trong PingIdentity.\nTrong giao diện PingIdentity, đi đến Applications tab \u0026gt; Application Catalog.\nTìm trong danh mục với từ khóa \u0026ldquo;AWS Single Sign-On\u0026rdquo; và chọn dấu + để bắt đầu Quick Setup.\nHình 2 – Danh mục Ứng dụng PingIdentity Alt Text: Ảnh chụp màn hình của giao diện PingIdentity Application Catalog. Từ khóa “aws” được nhập trong thanh tìm kiếm, hiển thị ba kết quả: Amazon Web Services – AWS, AWS Gov-Cloud và AWS Single Sign-On. Tùy chọn \u0026ldquo;AWS Single Sign-On\u0026rdquo; được viền bằng hộp màu đỏ và bao gồm nút dấu cộng để thêm ứng dụng.\n3. Cung cấp Name, SSO Region và SSO Tenant ID, rồi chọn Next Name – Nhập tên phù hợp cho kết nối SSO Region – Nhập vùng (region) thích hợp Tenant ID – Là Identity Store ID Bạn có thể chạy lệnh CLI sau để lấy giá trị này. Đây là chuỗi gồm 10 ký tự chữ và số, bắt đầu bằng tiền tố “d-”:\naws sso-admin list-instances \u0026ndash;query \u0026lsquo;Instances[0].IdentityStoreId\u0026rsquo;\nOutput: “d-XXXXXXXXXX”\n4. Điều hướng đến PingOne Mappings và chọn Email Address từ danh sách thả xuống. Hình 3 – Bản đồ thuộc tính đăng nhập một lần AWS\nAlt Text: Ảnh chụp màn hình cấu hình AWS Single Sign-On trong PingIdentity. Màn hình hiển thị Bước 2 của quá trình thiết lập, trong đó thuộc tính SAML_SUBJECT được ánh xạ với thuộc tính PingOne “Email Address”. Một hộp đỏ làm nổi bật phần ánh xạ trong “PingOne Mappings”.\n5. Tìm kiếm và chọn nhóm mà bạn đã tạo trước đó để cấp quyền truy cập cho Amazon Q Developer, và chọn dấu “+” để thêm nhóm.\n6. Chọn Save. Hình 4 – Chọn các Nhóm thư mục PingIdentity để truy cập Amazon Q Developer Alt Text: Ảnh chụp màn hình của Bước 3 trong quy trình thiết lập AWS Single Sign-On trong PingIdentity. Màn hình hiển thị giao diện chọn nhóm, trong đó nhóm “Amazon Q” được liệt kê. Một biểu tượng dấu cộng (+) xuất hiện bên cạnh nhóm để thêm vào, và nút “Save” màu xanh lam được làm nổi bật ở góc dưới bên phải để xác nhận cấu hình.\nBước 2: Kết nối PingIdentity với IAM Identity Center Bước này bao gồm việc cấu hình PingIdentity với thông tin đăng nhập của AWS IAM Identity Center để hoàn tất quá trình thiết lập xác thực.\nTrong bảng điều khiển PingIdentity, điều hướng đến\nApplications Tab \u0026gt; Applications và chọn ứng dụng bạn đã tạo trước đó ở Bước 1.\nChọn Enable Advanced Configuration và nhấn Enable. Hình 5 – Bật cấu hình nâng cao cho ứng dụng Đăng nhập một lần AWS Alt Text: Ảnh chụp màn hình bảng điều khiển PingIdentity Applications hiển thị ứng dụng AWS Single Sign-On đã được chọn. Bảng tổng quan hiển thị các phần cấu hình chính bao gồm giao thức (SAML), thuộc tính được ánh xạ, chính sách đã chọn, và nhóm truy cập (Amazon Q). Tùy chọn “Enable Advanced Configuration” được làm nổi bật gần cuối bảng.\nCuộn xuống và chọn Download Metadata. Thao tác này sẽ lưu tệp Metadata vào máy tính của bạn; tệp này sẽ được sử dụng sau trong quá trình cấu hình.\nTrong một tab trình duyệt khác, đăng nhập vào AWS IAM Identity Center console của bạn và chọn\nChoose your identity source.\nTrong phần Identity source, chọn Change identity source từ menu thả xuống Actions. Hình 6 – Thay đổi nguồn danh tính trong Bảng điều khiển IAM Identity Center\nAlt Text: Ảnh chụp màn hình trang cài đặt của IAM Identity Center, tập trung vào tab\n“Nguồn danh tính”. Trang hiển thị các chi tiết như nguồn danh tính, phương thức xác thực,\nURL cổng truy cập AWS, URL nhà phát hành và ID kho danh tính. Một menu thả xuống có nhãn\n“Hành động” được mở rộng ở góc trên bên phải, hiển thị các tùy chọn\n“Tùy chỉnh URL cổng truy cập AWS” và “Thay đổi nguồn danh tính”, được đánh dấu bằng khung màu đỏ.\nTrên trang tiếp theo, chọn External identity provider và nhấn Next.\nTrong phần Service provider metadata, sao chép\nIAM Identity Center Assertion Consumer Service (ACS) URL.\nHình 7 – Sao chép URL ACS của Trung tâm Nhận dạng IAM\nAlt Text: Ảnh chụp màn hình bước “Configure external identity provider” trong quá trình thiết lập\nAWS IAM Identity Center. Màn hình hiển thị thông tin service provider metadata, bao gồm\nAWS access portal sign-in URL, IAM Identity Center Assertion Consumer Service (ACS) URL\n(được đánh dấu bằng khung đỏ), và IAM Identity Center issuer URL.\nMột nút có nhãn “Download metadata file” được hiển thị ở góc trên bên phải.\nBây giờ, quay lại tab trình duyệt PingIdentity, điều hướng đến tab\nConfiguration, và chọn biểu tượng cây bút (pencil icon) để chỉnh sửa thông tin chi tiết.\nDán ACS URL mà bạn đã sao chép từ IAM Identity Center console và chọn Save.\nb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2025/06/12/devops-16054-image-26.png\nHình 8 – Cấu hình cài đặt SAML của AWS Single Sign-On trong bảng điều khiển PingIdentity\nAlt Text: Hai ảnh chụp màn hình hiển thị quá trình cấu hình và chỉnh sửa cài đặt SAML cho\nAWS Single Sign-On trong PingIdentity. Ảnh đầu tiên hiển thị giao diện cấu hình tĩnh,\nliệt kê ACS URL, signing key (“PingOne SSO Certificate for Administrators environment”),\nsigning method (“Response”), và signing algorithm.\nẢnh thứ hai hiển thị giao diện chỉnh sửa, trong đó ô nhập ACS URL được đánh dấu bằng khung đỏ,\ncùng với các menu thả xuống để chọn signing key, tùy chọn signing method (Assertion, Response hoặc cả hai),\nvà thuật toán RSA_SHA256. Các màn hình này hướng dẫn người dùng thiết lập hợp SAML bảo mật với AWS SSO.\nBước 3: Cấu hình PingIdentity làm nhà cung cấp danh tính (IdP) bên ngoài trong IAM Identity Center Bước này bao gồm việc thiết lập PingIdentity làm IdP bên ngoài trong\nIAM Identity Center để kích hoạt truy cập liên kết (federated access).\nQuay lại tab trình duyệt trước đó nơi bạn đã mở bảng điều khiển\nIAM Identity Center.\nTải lên tệp PingIdentity IdP SAML metadata đã tải xuống từ bước 3 của phần trước,\nrồi chọn Next.\nHình 9 – AWS IAM Identity Center metadata\nAlt Text: Ảnh chụp màn hình của giao diện cấu hình AWS Identity Center nơi người dùng\ntải lên tệp IdP SAML metadata XML. Tệp metadata được chọn thành công. Bên dưới là các trường\ntrống để nhập thủ công IdP sign-in URL, IdP issuer URL, và IdP certificate.\nNút “Next” được tô sáng màu cam ở góc dưới bên phải, biểu thị bước tiếp theo trong quá trình thiết lập.\nXem lại danh sách các thay đổi. Khi đã sẵn sàng, nhập ACCEPT, rồi chọn\nChange identity source. Bước 4: Bật cấp phát (provisioning) và các phiên làm việc nhận thức danh tính (identity-aware sessions) trong IAM Identity Center\nBước này bao gồm việc cấu hình cấp phát người dùng và bật các phiên làm việc nhận thức danh tính\ntrong AWS IAM Identity Center để hỗ trợ kiểm soát truy cập động.\nTrong bảng điều khiển\nIAM Identity Center Console,\nchọn Settings ở thanh điều hướng bên trái.\nTrên trang Settings, tìm và bật tính năng automatic provisioning.\nHành động này sẽ kích hoạt ngay lập tức quá trình cấp phát tự động trong\nIAM Identity Center và hiển thị thông tin cần thiết bao gồm:\nSCIM endpoint Access token Trong hộp thoại Inbound automatic provisioning, sao chép từng giá trị của các tùy chọn trên.\nBạn sẽ cần dán các giá trị này vào PingIdentity khi cấu hình phần cấp phát sau này.\nChọn Close.\nTiếp theo, bật các tùy chọn identity-aware sessions và automatic provisioning.\nHình 10 – Cài đặt IAM Identity Center cho identity-aware sessions và automatic provisioning\nAlt Text: Hai tùy chọn được hiển thị để cấu hình thêm: “Enable identity-aware sessions”\nvà “Automatic provisioning.” Cả hai đều có nút “Enable” ở phía bên phải, được đánh dấu màu đỏ.\nBước 5: Cấu hình kết nối cấp phát (Provisioning Connections) trong PingIdentity Bước này hướng dẫn cách thiết lập kết nối cấp phát trong PingIdentity\nđể kích hoạt việc quản lý người dùng và nhóm tự động.\nTrong bảng điều khiển PingIdentity, điều hướng đến\nIntegrations \u0026gt; Provisioning.\nChọn biểu tượng dấu cộng (+) → New Connection.\nTrong mục Connection Type, chọn Identity Store. Hình 11 – Cấu hình kết nối Provisioning trong PingIdentity\nAlt Text: Màn hình cấu hình Provisioning trong PingIdentity. Thanh bên trái tô sáng tab\nProvisioning, bảng chính hiển thị hộp thoại Create a New Connection với hai tùy chọn\nIdentity Store và Gateway. Identity Store được chọn bằng nút Select, biểu tượng dấu cộng (+)\nở trên cùng cho phép thêm kết nối mới.\nChọn SCIM outbound từ danh sách tùy chọn và nhấn Next.\nNhập tên cho kết nối và nhấn Next.\nDán SCIM endpoint URL vào trường SCIM BASE URL.\nTrong phần Authentication Method, chọn OAuth 2 Bearer Token.\nDán Access Token vào trường OAuth Access Token.\nNhấn Test Connection để kiểm tra kết nối, sau đó chọn Next.\nHình 12 – Cấu hình chi tiết xác thực (Authentication Details)\nAlt Text: Giao diện PingIdentity hiển thị bước cấu hình xác thực với các trường thông tin\nvề SCIM Base URL, SCIM Version (2.0), OAuth 2 Bearer Token, và OAuth Access Token.\nNút Test Connection và Next hiển thị phía dưới.\nĐiều hướng đến User Filter Expression và thay đổi giá trị thành: userName Eq \u0026ldquo;%s\u0026rdquo;. 11. Chọn Save. (Theo mặc định, kết nối được tạo ở trạng thái Disabled.)\nHình 13 – Chỉnh sửa User Filter Expression cho kết nối\nAlt Text: Bước cuối của trình hướng dẫn Create a New Connection trong PingIdentity hiển thị\ncấu hình User Filter Expression, User Identifier, và tùy chọn nhóm.\nNút Save được tô sáng ở góc dưới bên phải.\nChọn kết nối bạn vừa tạo và bật công tắc (toggle switch) để kích hoạt kết nối. Hình 14 – Kích hoạt kết nối\nAlt Text: Màn hình cấu hình PingIdentity hiển thị tích hợp với IAM Identity Store,\ncó công tắc bật/tắt ở góc trên bên phải được đánh dấu cho thấy kết nối đang được bật.\nBước 6: Cấu hình quy tắc cung cấp (provisioning rules) trong PingIdentity Bước này bao gồm việc thiết lập các quy tắc cung cấp trong PingIdentity\nđể xác định cách người dùng và nhóm được đồng bộ hóa.\nTrong bảng điều khiển PingIdentity, điều hướng đến Integrations \u0026gt; Provisioning.\nChọn biểu tượng dấu cộng \u0026gt; New Rule.\nNhập Tên và Mô tả cho quy tắc.\nChọn Create.\nChọn biểu tượng dấu cộng để chọn Kết nối (Connection) bạn đã tạo ở bước trước.\nChọn Save.\nHình 15 – Thêm kết nối IAM Identity Center vào quy tắc\nAlt Text: Ảnh chụp màn hình hiển thị các bước cuối cùng trong việc kết nối\nIAM Identity Center với IAM Identity Store bằng PingIdentity.\nHình đầu tiên hiển thị kết nối IAM Identity Store được liệt kê trong phần Available Connections\nvới biểu tượng dấu cộng (+) để bắt đầu liên kết.\nHình thứ hai hiển thị kết nối đã chọn từ PingOne Directory (P1) làm nguồn\nvà IAM Identity Store (SCIM) làm đích, với tùy chọn “Save” để lưu cấu hình. 7. Nếu bạn muốn đồng bộ người dùng từ thư mục PingIdentity, hãy tạo bộ lọc người dùng (User Filter).\nĐể thực hiện, điều hướng đến User Filter và chọn biểu tượng bút chì để chỉnh sửa.\nChọn bộ lọc phù hợp từ danh sách thả xuống tùy theo trường hợp sử dụng của bạn và chọn Save.\nỞ đây, tôi đã chọn Group Name được chỉ định cho quyền truy cập Amazon Q Developer. Hình 16 – Bộ lọc người dùng trong PingIdentity\nAlt Text: Ảnh chụp màn hình giao diện “Edit User Filter” trong IAM Identity Center.\nBộ lọc người dùng được cấu hình để cung cấp người dùng thuộc các nhóm có tên chứa\n“Amazon Q Developer”. Logic điều kiện được đặt thành khớp nếu “Any” (bất kỳ) điều kiện nào đúng.\nNếu bạn muốn đồng bộ một nhóm từ thư mục PingIdentity, hãy tạo group provisioning.\nĐể làm vậy, điều hướng đến Group Provisioning và chọn biểu tượng bút chì để chỉnh sửa.\nChọn nhóm thích hợp được chỉ định cho quyền truy cập Amazon Q Developer và chọn Save. Hình 17 – Cấu hình Group Provisioning trong PingIdentity\nAlt Text: Ảnh chụp màn hình giao diện “Edit Group Provisioning” trong\nIAM Identity Center. Nhóm “Amazon Q Developer” được chọn cho việc cung cấp ra ngoài.\nNút “Save” được tô sáng ở góc dưới bên trái.\nĐiều hướng đến Attribute Mapping và chọn biểu tượng bút chì để chỉnh sửa cài đặt.\nXóa thuộc tính Primary Phone trong PingOne Directory.\nThêm một thuộc tính mới và chọn Username làm thuộc tính từ PingOne Directory\nvà displayName làm thuộc tính trong IAM Identity Store.\nChọn Save.\nHình 18 – Cấu hình ánh xạ thuộc tính (Attribute Mapping) trong PingIdentity\nAlt Text: Ảnh chụp màn hình giao diện “Edit Attribute Mapping” của IAM Identity Center\ntrong PingIdentity. Màn hình hiển thị danh sách ánh xạ thuộc tính giữa PingOne Directory\nvà IAM Identity Store, bao gồm các thuộc tính như Family Name, Given Name, Username,\nEmail Address, và Primary Phone. Một ánh xạ mới được thêm vào với\nUsername → displayName. Nút Add và nút Save được đánh dấu để hướng dẫn thao tác. 15. Chọn quy tắc bạn đã tạo và bật công tắc (toggle) để kích hoạt quy tắc.\nĐiều này sẽ tự động cung cấp người dùng/nhóm từ PingIdentity sang IAM Identity Center thông qua SCIM.\nHình 19 – Trạng thái đồng bộ người dùng và nhóm từ PingIdentity qua SCIM\nAlt Text: Bản tóm tắt đồng bộ IAM Identity Center hiển thị việc cung cấp người dùng và nhóm thành công.\nHình đầu tiên tô sáng hai người dùng bị ảnh hưởng và đã đồng bộ thành công.\nHình thứ hai tô sáng một nhóm đã được đồng bộ thành công.\nTrạng thái đồng bộ được đánh dấu là “ACTIVE”, xác nhận tích hợp giữa PingOne và AWS IAM Identity Center đã thành công.\nBước 7: Cấp quyền truy cập cho Amazon Q Developer Bước này bao gồm việc xác định và đăng ký (subscribe) các nhóm cần được cấp quyền sử dụng Amazon Q Developer.\nTrong bảng điều khiển\nAmazon Q Developer console,\ntại mục Subscriptions, thêm các nhóm của IAM Identity Center cần quyền truy cập vào Amazon Q Developer.\nChọn Subscribe và tìm kiếm tên nhóm.\nChọn Assign.\nHình 20 – Trang đăng ký Amazon Q Developer\nAlt Text: Ảnh chụp màn hình trang “Subscriptions” của Amazon Q Developer trong AWS Management Console.\nTab “Groups” được chọn, hiển thị “Amazon Q Developer” với trạng thái đăng ký là Subscribed.\nNhóm “Amazon Q Developer” được đánh dấu bằng khung đỏ.\nThiết lập Amazon Q Developer với IAM Identity Center Phần này hướng dẫn bạn cài đặt tiện ích mở rộng Amazon Q Developer và thiết lập xác thực thông qua IAM Identity Center.\nĐể cài đặt extension Amazon Q Developer trong môi trường phát triển tích hợp (IDE), hãy hoàn tất các bước được mô tả trong\nAWS documentation.\nSau khi tiện ích được cài đặt, chọn biểu tượng Amazon Q trong IDE của bạn.\nChọn một tùy chọn đăng nhập (Sign-in option).\nChọn Use with Pro license rồi chọn Continue.\nTiếp tục bằng cách nhấn Continue.\nNhập Start URL — bạn có thể lấy URL này (AWS access portal URL) từ\nbảng điều khiển IAM Identity Center Console.\nHình 21 – URL cổng truy cập IAM Identity Center\nAlt Text: Ảnh chụp màn hình trang cài đặt của IAM Identity Center trong AWS Console,\nhiển thị cấu hình nguồn danh tính. Phần “Identity source” được thiết lập là\nExternal identity provider sử dụng xác thực SAML 2.0 và cung cấp SCIM.\nKhung đỏ làm nổi bật AWS access portal URL và Identity Store ID.\nTab “Settings” được chọn từ bảng điều hướng bên trái.\nNhập Region nơi lưu trữ thư mục danh tính, rồi chọn Continue.\nChọn Open trên cửa sổ bật lên để chuyển hướng đến trình duyệt.\nTrình duyệt sẽ dẫn bạn đến URL PingOne, nơi bạn nhập thông tin\nđăng nhập PingIdentity, sau đó chọn Sign On.\nKhi xác thực thành công, chọn Allow access trong cửa sổ bật lên\nđể hoàn tất đăng nhập. Hình 22 – Thiết lập tiện ích mở rộng Amazon Q Developer trong Visual Studio Code\nAlt Text: Một bản ghi màn hình trong Visual Studio Code cho thấy người dùng\nchọn biểu tượng Amazon Q ở thanh bên trái. Màn hình chuyển sang cửa sổ đăng nhập,\nhiển thị thông báo rằng người dùng phải xác thực bằng thông tin đăng nhập\nPingIdentity thông qua IAM Identity Center trước khi có thể truy cập các\ntính năng của Amazon Q Developer. Thông báo nhấn mạnh rằng việc xác thực là\nbắt buộc để tiếp tục.\nKiểm tra cấu hình Sau khi hoàn thành bước trước thành công, bạn có thể tận dụng các gợi ý mã\ntừ Amazon Q Developer. Hình 23 – Ví dụ về Amazon Q Developer\nAlt Text: Bản ghi màn hình của Visual Studio Code cho thấy Amazon Q Developer tạo ra\nmột đoạn mã mẫu trực tiếp trong trình soạn thảo.\nDọn dẹp Để tránh phát sinh chi phí sau khi kiểm thử giải pháp này, hãy thực hiện các bước sau để\nxóa tất cả tài nguyên đã được cấp phát:\n1. Xóa cấu hình ứng dụng PingIdentity Trong bảng điều khiển PingIdentity, điều hướng đến Applications. Tìm và xóa ứng dụng AWS Single Sign-On đã được cấu hình cho IAM Identity Center. 2. Đặt lại cấu hình IAM Identity Center Trong bảng điều khiển AWS IAM Identity Center:\nĐiều hướng đến Settings → Identity source. Thay đổi nguồn danh tính về IAM Identity Center directory mặc định\nnếu bạn không còn sử dụng PingIdentity. 3. Thu hồi đăng ký và quyền truy cập Trong bảng điều khiển Amazon Q Developer:\nTruy cập Subscriptions và xóa các nhóm được gán như\nAmazon Q Developer hoặc CodeWhisperer trial.\nThao tác này sẽ hủy kích hoạt quyền truy cập và ngăn chặn các khoản phí phát sinh trong tương lai.\n4. Gỡ tiện ích mở rộng Amazon Q Developer Nếu muốn, bạn có thể gỡ cài đặt tiện ích mở rộng Amazon Q Developer khỏi\nVisual Studio Code để hoàn nguyên hoàn toàn môi trường phát triển. Kết luận Trong bài viết này, chúng tôi đã trình bày cách sử dụng thông tin xác thực PingIdentity\nhiện có để truy cập Amazon Q Developer thông qua tích hợp với IAM Identity Center.\nChúng tôi đã cung cấp hướng dẫn chi tiết từng bước để cấu hình\nPingIdentity làm nhà cung cấp danh tính bên ngoài (IdP) cho IAM Identity Center.\nCuối cùng, chúng tôi đã mô tả cách kết nối tiện ích mở rộng Amazon Q Developer\ntrong IDE của bạn với AWS bằng thông tin đăng nhập PingIdentity,\ngiúp bạn truy cập Amazon Q Developer một cách liền mạch.\nNếu bạn có bất kỳ nhận xét hoặc câu hỏi nào, hãy chia sẻ trong phần bình luận bên dưới.\nĐể tìm hiểu thêm về các dịch vụ AWS Amazon Q Developer IAM Identity Center AWS Toolkit for Visual Studio Code Về tác giả Sid Vantair là một Kiến trúc sư Giải pháp (Solutions Architect) tại AWS, phụ trách các tài khoản chiến lược.\nAnh luôn tận tâm trong việc giải quyết các vấn đề kỹ thuật phức tạp nhằm giúp khách hàng vượt qua những trở ngại.\nNgoài công việc, anh trân trọng thời gian bên gia đình và khuyến khích tinh thần ham học hỏi ở các con của mình.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"AWS for Industries\nTrợ lý Ảo Năng Lượng: Chuyển đổi dịch vụ khách hàng ngành tiện ích với AWS Generative AI by Darren Roback and Jeremy Cianella on 10 JUL 2025 in\nAmazon Bedrock, Amazon Bedrock Guardrails,\nAmazon CloudWatch, Amazon Connect,\nAmazon DynamoDB, Amazon Lex,\nAmazon Timestream, AWS Lambda,\nEnergy (Oil \u0026amp; Gas), Industries – Permalink\nTrong kỷ nguyên chuyển đổi số ngày càng mạnh mẽ, các nhà cung cấp dịch vụ điện (electric utility providers) đang phải đối mặt với những thách thức chưa từng có trong việc đáp ứng kỳ vọng của khách hàng về dịch vụ nhanh chóng, hiệu quả và dễ tiếp cận.\nCác utility contact centers đặc biệt gặp khó khăn trong việc cung cấp dịch vụ khách hàng hiệu quả. Hệ thống Interactive Voice Response (IVR) truyền thống có thể xử lý tốt các yêu cầu trực tiếp, rõ ràng thông qua thao tác phím bấm hoặc các lệnh thoại cơ bản — chẳng hạn như báo mất điện hoặc kiểm tra số dư tài khoản. Tuy nhiên, những lệnh phức tạp, mơ hồ và nhiều lượt (multi-turn) thường phải chuyển sang nhân viên thật, tạo ra nút thắt trong quá trình phục vụ.\nGiới hạn này trở nên nghiêm trọng hơn trong các sự kiện thời tiết khắc nghiệt hoặc khi mất điện trên diện rộng, khi lượng cuộc gọi có thể tăng vọt chỉ trong vài phút — thường khiến ngay cả những trung tâm được bố trí đầy đủ nhân sự cũng bị quá tải. Thách thức càng gia tăng bởi nhu cầu tích hợp với nhiều hệ thống backend khác nhau như Customer Information Systems (CIS), Billing Information System (BIS), Meter Data Management Systems (MDMS), Outage Management Systems (OMS) và nhiều knowledge bases để xử lý các yêu cầu của khách hàng. Tất cả những điều này dẫn đến thời gian xử lý lâu hơn và làm tăng khả năng gây thất vọng cho khách hàng.\nCác utility contact centers hiện đại cần xử lý hiệu quả những gì chúng tôi gọi là “ABCDs” trong dịch vụ khách hàng ngành tiện ích. Mỗi chức năng cốt lõi này đòi hỏi phải truy cập vào các hệ thống khác nhau và kiến thức chuyên ngành cụ thể:\nAccount management: Mở, đóng, truy xuất và cập nhật thông tin tài khoản khách hàng; thường cần tương tác với CIS.\nBilling: Truy xuất số dư tài khoản, lịch sử hóa đơn và xử lý thanh toán — thường cần tương tác với BIS.\nConsumption: Phân tích và giải thích các mô hình tiêu thụ năng lượng từ dữ liệu smart meter — thường cần tương tác với MDMS.\nDispatch: Tạo yêu cầu dịch vụ, báo cáo sự cố/mất điện, kiểm tra trạng thái yêu cầu và lên lịch bảo trì — thường cần tương tác với OMS.\nĐể quản lý hiệu quả các chức năng này, các customer service representatives cần được đào tạo chuyên sâu và có kinh nghiệm. Họ phải hiểu cấu trúc giá điện phức tạp, phân giải dữ liệu tiêu thụ năng lượng, giải thích cách tính hóa đơn, và điều hướng các chính sách và quy trình phức tạp. Kiến thức chuyên sâu này mất nhiều tháng để hình thành, dẫn đến thời gian onboarding dài cho nhân viên mới và khó duy trì chất lượng dịch vụ nhất quán trên mọi tương tác với khách hàng.\nNhững hạn chế của hệ thống IVR truyền thống và sự phức tạp trong vận hành ngành tiện ích đã mở ra cơ hội cho các giải pháp tiên tiến dựa trên AI. Generative AI — với khả năng hiểu ngôn ngữ tự nhiên, xử lý truy vấn phức tạp, và tạo ra phản hồi giống con người — mang đến hướng tiếp cận đầy hứa hẹn cho những thách thức này.\nCác Large Language Models (LLMs) cho phép chúng ta xây dựng virtual assistants có khả năng hiểu ý định của khách hàng chính xác hơn, xử lý phạm vi yêu cầu rộng hơn mà không cần sự can thiệp của con người, đồng thời đưa ra các phản hồi tinh tế và nhận thức ngữ cảnh tốt hơn.\nĐể giải quyết những thách thức này, chúng tôi đã phát triển Energy Virtual Assistant — một cách tiếp cận tiên tiến cho dịch vụ khách hàng, kết hợp Generative AI với agentic capabilities, hỗ trợ ra quyết định thông minh thông qua chain-of-thought reasoning và tích hợp với các hệ thống năng lượng cũng như tận dụng dữ liệu hiện có của doanh nghiệp tiện ích. Giải pháp này kết hợp sức mạnh của LLMs với kiến thức chuyên ngành và khả năng tích hợp hệ thống các thiết bị trong dịch vụ khách hàng ngành năng lượng.\nTrong bài viết này, chúng tôi sẽ thảo luận về lợi ích của Generative AI trong dịch vụ khách hàng, trình bày kiến trúc của giải pháp, cung cấp hướng dẫn triển khai từng bước, và chia sẻ các bước tiếp theo để triển khai giải pháp này trong contact center của các nhà cung cấp tiện ích.\nLợi ích của Generative AI trong dịch vụ khách hàng Generative AI đại diện cho một bước nhảy vọt trong công nghệ dịch vụ khách hàng,\nmang đến một bộ năng lực toàn diện giúp định hình lại cách các tổ chức tương tác với\nkhách hàng của họ.\nCá nhân hóa ở quy mô lớn Không giống các hệ thống truyền thống, generative AI có thể tạo ra các phản hồi\nkhông chỉ chính xác mà còn được cá nhân hóa theo phong cách giao tiếp, sở thích và\nlịch sử tương tác của từng khách hàng. Các tiếp cận này biến dịch vụ khách hàng\nthông thường thành một trải nghiệm tương tác tinh tế và mang tính cá nhân cao,\nkhiến khách hàng cảm thấy được thấu hiểu thực sự.\nTrí tuệ cảm xúc và phân tích cảm xúc Nhờ vào khả năng sentiment analysis nâng cao, generative AI có thể phát hiện\nnhững sắc thái tinh tế trong giao tiếp của khách hàng, từ đó điều chỉnh giọng điệu\nvà cách tiếp cận phù hợp với trạng thái cảm xúc của họ. Dù khách hàng thể hiện sự tức giận,\nbối rối hay hài lòng, hệ thống đều có thể đưa ra phản hồi đồng cảm và phù hợp với\nngữ cảnh, phản ánh mức độ thấu hiểu gần như con người.\nNăng lực đa ngôn ngữ và hiểu biết văn hóa Generative AI phá vỡ rào cản ngôn ngữ bằng khả năng hỗ trợ đa ngôn ngữ mạnh mẽ\nvới độ trôi chảy gần như người bản xứ ở nhiều ngôn ngữ khác nhau.\nHơn cả việc dịch thuật, khả năng này còn đảm bảo giao tiếp phù hợp về mặt văn hóa,\nhiểu được những sắc thái ngữ cảnh và ngôn ngữ mà các công cụ dịch truyền thống thường bỏ qua.\nĐiều này tạo nên trải nghiệm dịch vụ khách hàng mang tính toàn cầu nhưng vẫn gần gũi\nvà được cá nhân hóa theo từng khu vực.\nTích hợp dữ liệu thống nhất Generative AI hoạt động như một bộ điều phối dữ liệu tinh vi, tích hợp liền mạch\nthông tin từ các silo dữ liệu trong tổ chức. Việc tạo ra một cái nhìn toàn diện về\nHiệu quả vận hành và tối ưu chi phí Generative AI còn có thể thúc đẩy hiệu quả chi phí đáng kể bằng cách giảm thời gian\nxử lý trung bình (handle time), tăng tỷ lệ giải quyết ngay trong lần liên hệ đầu tiên\n(first-contact resolution rate), tự động hóa toàn diện các yêu cầu thường xuyên và\nloại bỏ chi phí làm thêm giờ nhờ khả năng sẵn sàng 24/7.\nKhả năng mở rộng vượt trội Các nền tảng dịch vụ khách hàng trong ngành tiện ích thường gặp khó khăn với biến\nđộng về khối lượng tương tác, đặc biệt trong các tình huống khẩn cấp như mất điện\ndiện rộng, bão lũ hoặc cháy rừng.\nCác contact center sử dụng generative AI có thể nhanh chóng mở rộng quy mô khi nhu cầu tăng\nđột biến, duy trì chất lượng dịch vụ ổn định dù phải xử lý mười hay mười nghìn tương tác cùng lúc.\nTính linh hoạt này đảm bảo khả năng hỗ trợ khách hàng đáng tin cậy trong mọi tình huống.\nKhả năng hoạt động liên tục Điều quan trọng nhất là generative AI cho phép cung cấp dịch vụ khách hàng liên tục\n24/7 mà không cần chi phí cao cho mô hình nhân sự truyền thống.\nKhách hàng có thể truy cập hỗ trợ bất kỳ lúc nào, từ đó cải thiện đáng kể khả năng\ntiếp cận dịch vụ và mức độ hài lòng tổng thể.\nTổng quan giải pháp Energy Virtual Assistant được thiết kế để hỗ trợ các tình huống sử dụng phổ biến\ntrong dịch vụ khách hàng ngành tiện ích, chẳng hạn như báo cáo sự cố mất điện,\nkiểm tra dữ liệu phân tích mức tiêu thụ, cập nhật thông tin tài khoản và xử lý\nthanh toán hóa đơn.\nKhách hàng trải nghiệm với Energy Virtual Assistant thông qua nhiều kênh\n(voice hoặc chat), được hỗ trợ bởi Generative AI để cung cấp phản hồi nhanh chóng,\nchính xác, thông minh và mang tính cá nhân hóa. Energy Virtual Assistant được xây dựng bằng cách kết hợp nhiều dịch vụ của Amazon Web Services (AWS), bao gồm:\nAmazon Connect: Là giải pháp contact center trên nền tảng đám mây, cho phép doanh nghiệp cung cấp dịch vụ khách hàng ở bất kỳ quy mô nào. Nó hỗ trợ giao tiếp đa kênh (omni-channel communication), định tuyến theo kỹ năng (skills-based routing), và các tính năng được hỗ trợ bởi AI như conversational IVR. Amazon Connect đóng vai trò là điểm đầu vào cho khách hàng khi họ tương tác với Energy Virtual Assistant qua kênh thoại.\nAmazon Lex: Là dịch vụ AI được quản lý toàn phần, cho phép xây dựng giao diện hội thoại (chatbot) bằng giọng nói hoặc văn bản. Nó sử dụng công nghệ nền tảng của Amazon Alexa. Amazon Lex đóng vai trò là lớp giao diện hội thoại cho Energy Virtual Assistant, giúp hiểu và xử lý ngôn ngữ tự nhiên (natural language understanding).\nAmazon Bedrock: Là dịch vụ được quản lý toàn phần cung cấp quyền truy cập vào các foundation models (FMs) hiệu năng cao thông qua một unified API. Amazon Bedrock mang đến năng lực Generative AI cho Energy Virtual Assistant.\nAgents for Amazon Bedrock: Là tính năng cho phép người dùng tạo các AI agents có khả năng tự động phân tích và thực thi các tác vụ nghiệp vụ phức tạp bằng cách điều phối FMs, knowledge bases và APIs. Energy Virtual Assistant là một Bedrock agent sử dụng chain-of-thought reasoning và tích hợp với các hệ thống năng lượng để xử lý yêu cầu khách hàng.\nAWS Lambda: Là dịch vụ serverless compute thực thi mã nguồn khi có sự kiện xảy ra. Lambda đóng vai trò quan trọng trong Agents for Amazon Bedrock bằng cách cung cấp lớp xử lý (compute layer) cho các API integration tới các hệ thống năng lượng backend.\nAmazon DynamoDB: Là dịch vụ NoSQL database được quản lý toàn phần, không cần máy chủ (serverless), cung cấp hiệu năng nhanh, ổn định và khả năng mở rộng linh hoạt. Trong giải pháp này, DynamoDB được sử dụng để mô phỏng các hệ thống năng lượng như Account, Billing và Outage Management.\nAmazon Timestream: Là dịch vụ cơ sở dữ liệu time series được quản lý toàn phần, được thiết kế để thu thập, lưu trữ và phân tích dữ liệu chuỗi thời gian. Trong trường hợp này, Timestream được dùng để lưu trữ dữ liệu tiêu thụ năng lượng, thường được gọi là MDMS.\nGuardrails for Amazon Bedrock: Là tính năng giúp triển khai các biện pháp kiểm soát an toàn như lọc nội dung, chặn chủ đề, lọc từ khóa, và ẩn thông tin nhạy cảm nhằm bảo vệ tương tác giữa khách hàng và foundation model (FM).\nTrước khi đi vào phần kiến trúc giải pháp, hãy xem cách giải pháp này thay đổi các tình huống dịch vụ khách hàng trong ngành tiện ích.\nGiả sử một khách hàng gọi điện phản ánh về hóa đơn cao bất thường. Trước đây, nhân viên phải kiểm tra nhiều hệ thống khác nhau: lịch sử sử dụng điện, biểu đồ đo, biểu giá điện, thậm chí là dữ liệu thời tiết. Với giải pháp của chúng tôi, virtual assistant có thể tự động thu thập và phân tích toàn bộ thông tin đó, đồng thời cung cấp lời giải thích và khuyến nghị phù hợp theo ngữ cảnh cho khách hàng — hoàn toàn không cần sự can thiệp của con người.\nKiến trúc giải pháp Kiến trúc giải pháp dưới đây mô tả tổng quan về các thành phần được sử dụng trong hệ thống này, và để minh họa, chúng ta sẽ cùng xem xét từng phần.\nHình 1: Solution architecture\nKhách hàng sử dụng điện (energy customers) tương tác với nhà cung cấp tiện ích (utility provider) thông qua nhiều loại yêu cầu phổ biến qua kênh thoại (voice channel). Mặc dù giải pháp này được thiết kế để phục vụ khách hàng sử dụng thoại, nó có thể mở rộng để hỗ trợ các kênh khác trong tương lai.\nKhách hàng gọi vào Amazon Connect và ngay lập tức được đưa vào một luồng tương tác (contact flow) trong Amazon Connect.\nMột bot Amazon Lex được nhúng vào luồng Amazon Connect và đóng vai trò là giao diện speech-to-text cho khách hàng khi họ tương tác với Energy Virtual Assistant.\nEnergy Virtual Assistant được hỗ trợ bởi một Amazon Bedrock agent, có nhiệm vụ tiếp nhận, xử lý và phân loại các yêu cầu từ khách hàng.\nAmazon Bedrock agent lấy lịch sử hội thoại của khách hàng, các hành động khả dụng và yêu cầu hiện tại, sau đó gửi đến một foundation model (FM) để xử lý.\nFoundation model (FM) sử dụng chain-of-thought reasoning để xác định các bước thích hợp nhằm đáp ứng yêu cầu của khách hàng.\nCác action groups đại diện cho các hành động và tích hợp mà agent có thể gọi để xử lý yêu cầu của khách hàng.\nCác hành động được cấu hình trong giải pháp này bao gồm:\nAccount Action Group: Thực hiện các hành động như mở tài khoản mới, truy xuất và cập nhật thông tin tài khoản, hoặc đóng tài khoản.\nBilling Action Group: Thực hiện các hành động như truy xuất số dư tài khoản, lịch sử thanh toán, và xử lý các khoản thanh toán của khách hàng.\nTicketing Action Group: Thực hiện các hành động như tạo ticket dịch vụ, kiểm tra trạng thái ticket, truy xuất tất cả ticket của một tài khoản cụ thể, báo cáo sự cố mất điện và lập lịch bảo trì.\nConsumption Action Group: Dùng để truy xuất thông tin tiêu thụ năng lượng, cung cấp tính chi phí dựa trên mức tiêu thụ, và giải thích các mô hình sử dụng năng lượng.\nDate/Time Action Group: Dùng để xác định ngày giờ hiện tại và hỗ trợ các yêu cầu có phạm vi thời gian (range-based requests) mà FM cần để phục vụ khách hàng.\nKhi các hành động cần thiết đã được thực hiện, một Amazon Bedrock FM sẽ được sử dụng để xử lý và chuẩn bị phản hồi cuối cùng gửi lại cho khách hàng.\nLuồng cuộc gọi Amazon Connect Luồng cuộc gọi dưới đây mô tả các bước được thực hiện khi khách hàng tương tác với Amazon Connect qua kênh thoại. Để minh họa rõ hơn, chúng ta sẽ cùng xem xét chi tiết từng bước.\nHình 2: Amazon Connect call flow\nKhi khách hàng bắt đầu vào luồng Amazon Connect, khối Enable Logging được sử dụng để bật ghi nhật ký (flow logs), các log này được lưu trữ trong Amazon CloudWatch. Flow logs rất hữu ích để khắc phục sự cố và theo dõi các bước cụ thể được thực hiện trong một cuộc gọi của khách hàng.\nKhối Set Language được sử dụng để thiết lập ngôn ngữ và giọng nói cho chức năng text-to-speech (TTS) trong contact flow.\nKhối Main Menu được sử dụng để phát lời chào ban đầu cho người gọi và cũng là nơi bot Amazon Lex (với các intents đã được cấu hình) được kích hoạt để tương tác với khách hàng.\nCác intents cụ thể được sử dụng trong luồng này bao gồm:\nEnergyVirtualAgentIntent: đại diện cho Amazon Bedrock Energy Virtual Agent, được dùng để xử lý tất cả các yêu cầu của khách hàng như báo cáo sự cố mất điện, kiểm tra dữ liệu tiêu thụ, cập nhật thông tin tài khoản và xử lý thanh toán hóa đơn. Intent này được cấu hình với các utterances khác nhau để hiểu và phân loại các yêu cầu khác nhau mà khách hàng có thể nói với Amazon Bedrock agent.\nSpeakToAgentIntent: dùng để chuyển cuộc gọi trực tiếp của khách hàng đến nhân viên thật trong contact center. Intent này được cấu hình với các utterances tương ứng với các cụm từ khách hàng sử dụng khi họ muốn nói chuyện với nhân viên thật.\nGoodbyeIntent: được dùng để kết thúc tương tác của khách hàng với contact center. Intent này được cấu hình với các utterances kết thúc cuộc gọi.\nKhối Set Queue được sử dụng để xác định hàng đợi (queue) mà khách hàng sẽ được đưa vào nếu họ muốn nói chuyện với nhân viên thật.\nKhối Transfer to Queue được dùng để định tuyến khách hàng đến hàng đợi của nhân viên thật.\nKhối Queue at Capacity được sử dụng để thông báo cho khách hàng biết rằng hàng đợi đã đầy, thông qua một thông báo phát bằng text-to-speech.\nKhối Goodbye Prompt được sử dụng để gửi lời chào tạm biệt đến khách hàng thông qua thông báo text-to-speech.\nKhối Error Prompt được sử dụng để thông báo cho khách hàng biết rằng có sự cố xảy ra trong luồng, cũng thông qua một thông báo text-to-speech.\nĐiều kiện tiên quyết Trước khi bắt đầu, hãy đảm bảo rằng trong môi trường của bạn đã có các thành phần sau:\nCreated an Amazon Connect instance\nđược sử dụng để hỗ trợ khách hàng tương tác với Energy Virtual Assistant thông qua kênh thoại đến (inbound voice channel).\nClaimed an Amazon Connect phone number\nđược liên kết với luồng (flow) được tạo trong quá trình triển khai.\nAn Amazon Connect BasicQueue\nđược tạo mặc định cùng với Amazon Connect.\nEnabled access to Claude 3.5 Haiku\ntrong Amazon Bedrock, đóng vai trò là FM (foundation model) cho Amazon Bedrock agent.\nChúng tôi sử dụng hồ sơ suy luận Claude 3.5 (Claude 3.5 inference profile) trong giải pháp này, điều đó có nghĩa là bạn cần bật quyền truy cập mô hình tại các AWS Regions us-east-1, us-east-2 và us-west-2. Permissions to deploy the AWS CloudFormation template\nTriển khai giải pháp Quá trình triển khai giải pháp này bao gồm các bước sau:\nTạo CloudFormation stack, triển khai toàn bộ các thành phần cơ bản.\nCấu hình EnergyVirtualAgent Lex Bot intent, vì tại thời điểm viết bài này, Amazon Lex chưa hỗ trợ việc tạo intent thông qua CloudFormation hoặc API.\nLiên kết Amazon Connect phone number với Amazon Connect flow.\nTrong quá trình triển khai, hệ thống sẽ tự động tạo dữ liệu khách hàng giả lập trong các hệ thống Account, Billing và Consumption. Cụ thể, các bộ dữ liệu (datasets) được tạo bao gồm:\nAccountData: năm khách hàng giả định, bao gồm các trường dữ liệu như\nAccountNumber, CustomerName, EmailAddress, MeterNumber, PhoneNumber, PremiseNumber, RateCode và ServiceAddress.\nBillingData: mười hai tháng dữ liệu thanh toán cho mỗi khách hàng, bao gồm\nBillingDate, BillingStatus, DueDate, EnergyCharge, KWhConsumption,\nServiceCharge và TotalAmount.\nIntervalData: ba tháng dữ liệu tiêu thụ theo chu kỳ 15 phút cho mỗi đồng hồ đo, bao gồm\nL1–L2–L3 Voltage và Current, InstantaneousPower và Frequency.\nTạo CloudFormation stack Trước khi bắt đầu, hãy clone\nAWS Samples Energy Virtual Assistant GitHub repository\nvề máy cục bộ của bạn, vì chúng ta sẽ sử dụng tệp YAML CloudFormation cho phần đầu tiên của quá trình triển khai.\nThực hiện các bước sau:\nTruy cập AWS CloudFormation console và chọn\nCreate stack \u0026gt; With new resources (standard).\nTrong phần Prerequisite – Prepare template, chọn Choose an existing template và sau đó chọn Upload a template file.\nNhấn Choose file, sau đó từ repository vừa clone, điều hướng đến thư mục\n\\deployment và tải lên tệp cloudformation_template.yaml.\nChọn Next để chuyển sang màn hình Specify stack details.\nTrong trường Stack name, nhập EnergyVirtualAssistant.\nTrong trường ConnectInstanceArn, nhập Amazon Resource Name (ARN) của Amazon Connect instance của bạn.\nTrong trường ConnectQueueArn, nhập ARN của hàng đợi Amazon Connect BasicQueue.\nChọn Next để chuyển sang màn hình Configure stack options.\nChọn hộp kiểm xác nhận rằng AWS CloudFormation có thể tạo IAM resources với tên tùy chỉnh.\nChọn Next để tiếp tục đến màn hình Review and create.\nXem lại tất cả cấu hình, sau đó chọn Submit để tạo CloudFormation stack.\nSau khi hoàn tất nhập thông tin, khởi chạy stack và chờ cho đến khi trạng thái chuyển sang CREATE_COMPLETE trước khi tiếp tục các bước kế tiếp.\nCấu hình Lex Bot Khi quá trình triển khai CloudFormation stack hoàn tất, bạn có thể tiếp tục cấu hình Amazon Bedrock agent intent trong Amazon Lex bot.\nTrong bước này, chúng ta sẽ sử dụng các giá trị EnergyVirtualAgentId và\nEnergyVirtualAgentAliasId được tạo ra từ kết quả (outputs) của CloudFormation stack. Thực hiện các bước sau:\nTruy cập Amazon Lex console và chọn EnergyVirtualAgentLexBot đã được tạo sẵn cho bạn.\nTrong phần Draft version và English (US), chọn Intents.\nChọn menu Add intent và chọn Use built-in intent.\nChọn AMAZON.BedrockAgentIntent – GenAI feature cho loại built-in intent.\nỞ trường Intent name, nhập EnergyVirtualAgentIntent và chọn Add.\nỞ trường Description, nhập:\nIntent to handle customer energy requests.\nỞ trường Bedrock Agent ID, nhập giá trị EnergyVirtualAgentId lấy từ phần output của CloudFormation.\nỞ trường Agent Alias ID, nhập giá trị EnergyVirtualAgentAliasId lấy từ phần output của CloudFormation.\nTruy cập thư mục \\deployment trong repository đã clone và mở tệp\nagent_intent_utterances.md.\nTrong phần Sample utterances, chọn Plain text và dán toàn bộ nội dung utterances từ tệp vừa mở.\nChọn Save intent ở cuối màn hình.\nChọn Build ở góc trên bên phải màn hình để áp dụng các thay đổi.\nTruy cập trang Bot versions và chọn Create version.\nChọn Create để tạo một phiên bản bot mới và chờ cho đến khi quá trình hoàn tất.\nTrong phần Deployment, chọn Aliases và chọn PROD alias.\nChọn Associate version with alias và chọn phiên bản bot mới vừa tạo.\nChọn Associate để hoàn tất quá trình liên kết.\nLiên kết số điện thoại Bây giờ bạn đã sẵn sàng để liên kết Amazon Connect phone number (đã được claim trước đó) với contact flow được tạo trong quá trình triển khai CloudFormation stack.\nThực hiện các bước sau:\nĐăng nhập vào Amazon Connect instance của bạn và truy cập trang Phone numbers.\nChọn số điện thoại của bạn trong danh sách.\nTrong phần Contact flow/IVR, nhập EnergyVirtualAgentFlow vào ô tìm kiếm.\nChọn EnergyVirtualAgentFlow và chọn Save để liên kết số điện thoại với luồng này.\nKiểm thử giải pháp Trong repository này, thư mục test bao gồm nhiều kịch bản kiểm thử (test scenarios) mà bạn có thể sử dụng để tương tác và kiểm thử Energy Virtual Assistant.\nĐể trải nghiệm và tương tác với Energy Virtual Assistant, hãy gọi đến số điện thoại Amazon Connect mà bạn đã liên kết với contact flow, sau đó đặt các câu hỏi cho Amazon Bedrock agent, sử dụng thông tin tài khoản giả lập đã được tạo sẵn trong quá trình triển khai.\nTùy chỉnh giải pháp Người đọc được khuyến khích tùy chỉnh giải pháp này sao cho phù hợp với nhu cầu thực tế của mình, sau khi đã clone repository về máy cục bộ. Các bảng DynamoDB và Timestream trong backend — được sử dụng như bản mô phỏng cho các hệ thống CRM, Billing, Outage, và MDMS — có thể sẽ khác trong môi trường thực tế.\nTrước tiên, bạn nên xác định loại yêu cầu khách hàng (customer requests) mà bạn muốn hệ thống xử lý, sau đó tùy chỉnh các hệ thống backend cần thiết để hỗ trợ các tương tác đó.\nGiải pháp này được thiết kế chủ yếu nhằm minh hoạ “art-of-the-possible” (tiềm năng ứng dụng thực tế) của trợ lý AI sinh sinh (generative AI–enabled assistants), đồng thời đóng vai trò như một công cụ tăng tốc (acceleration vehicle) cho các hoạt động proof-of-concept (POC).\nDọn dẹp tài nguyên Để xóa giải pháp và tránh phát sinh chi phí thêm cho các tài nguyên AWS được sử dụng, hãy thực hiện các bước sau:\nĐăng nhập vào Amazon Connect instance của bạn và truy cập trang Phone numbers.\nChọn số điện thoại của bạn trong danh sách.\nTrong phần Contact flow/IVR, nhập EnergyVirtualAgentFlow vào ô tìm kiếm.\nBỏ chọn (deselect) luồng EnergyVirtualAgentFlow và chọn Save để xóa liên kết số điện thoại khỏi luồng.\nTruy cập CloudFormation console trong tài khoản AWS của bạn.\nTìm stack EnergyVirtualAssistant và chọn Delete.\nHành động này sẽ xóa toàn bộ tài nguyên được triển khai bởi CloudFormation stack, ngoại trừ các CloudWatch log groups được tạo cho Lambda functions và Amazon Connect instance.\nBạn có thể giữ lại hoặc xóa chúng tùy theo nhu cầu.\nTóm tắt Trong giải pháp này, chúng tôi đã minh hoạ cách xây dựng agentic solutions trên\nAmazon Bedrock và cách kết hợp nhiều dịch vụ AWS để tự động hóa quy trình chăm sóc khách hàng.\nViệc ứng dụng generative AI trong dịch vụ khách hàng mang lại nhiều lợi ích vượt trội so với IVR truyền thống, chẳng hạn như:\nThoát khỏi các luồng IVR cứng nhắc dựa trên quy tắc. Cung cấp dịch vụ khách hàng liên tục 24/7. Tự động mở rộng quy mô trong những giai đoạn có lưu lượng cao. Chúng tôi khuyến khích bạn triển khai, kiểm thử và tùy chỉnh giải pháp này trong môi trường của mình để nhanh chóng nhận thấy giá trị thực tế của việc sử dụng generative AI nhằm nâng cao trải nghiệm và hiệu quả dịch vụ khách hàng.\nDarren Roback Darren là Sr. Solutions Architect tại Amazon Web Services (AWS), làm việc tại St. Louis, Missouri.\nAnh có hơn 20 năm kinh nghiệm trong lĩnh vực công nghệ thông tin (IT) và đặc biệt đam mê các lĩnh vực Data Analytics, Generative AI, Internet of Things (IoT), cũng như Security and Compliance.\nTại AWS, Darren hợp tác cùng các khách hàng trong ngành năng lượng và tiện ích (energy and utility) để giúp đưa ra quyết các thách thức kinh doanh bằng công nghệ của AWS.\nNgoài công việc, anh yêu thích chế tác gỗ (woodworking) và dành thời gian cho gia đình.\nJeremy Cianella Jeremy Cianella là Sr. Solutions Architect làm việc tại Miami, Florida, phụ trách hỗ trợ các khách hàng trong lĩnh vực tiện ích (utility) và năng lượng tái tạo (renewables).\nAnh có hơn 15 năm kinh nghiệm làm việc trong vận hành hệ thống tiện ích, kinh tế doanh nghiệp (enterprise architecture) và công nghệ đám mây (cloud technologies), giúp khách hàng thực hiện các sáng kiến chuyển đổi số (digital transformation).\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Xây dựng đường ống streaming serverless bảo mật với Amazon MSK Serverless, Amazon EMR Serverless và IAM by Shubham Purwar, Nitin Kumar, and Prashanthi Chinthala on 02 JUN 2025 in\nAmazon Athena, Amazon EMR,\nAmazon Managed Streaming for Apache Kafka (Amazon MSK),\nAnalytics, AWS Big Data\nPermalink • Comments • Share\nSự tăng trưởng theo cấp số nhân và khối lượng khổng lồ của dữ liệu streaming đã khiến nó trở thành một nguồn tài nguyên quan trọng đối với các tổ chức trên toàn thế giới.\nĐể khai thác tối đa tiềm năng này, phân tích thời gian thực (real-time analytics) là yếu tố cần thiết để trích xuất các thông tin có thể hành động (actionable insights).\nĐược tạo ra từ nhiều nguồn khác nhau, bao gồm mạng xã hội, cảm biến Internet of Things (IoT) và tương tác của người dùng, dữ liệu streaming giúp doanh nghiệp phản ứng nhanh với các xu hướng và sự kiện mới, đưa ra quyết định sáng suốt, và duy trì lợi thế cạnh tranh.\nThông thường, các ứng dụng streaming sử dụng Apache Kafka để thu nhận dữ liệu (data ingestion) và Apache Spark Structured Streaming để xử lý.\nTuy nhiên, việc tích hợp và bảo mật các thành phần này đòi hỏi đa nhiều thách thức đáng kể cho người dùng.\nSự phức tạp trong việc quản lý chứng chỉ (certificates), keystore, và cấu hình TLS để kết nối Spark Streaming với Kafka brokers đôi khi đòi hỏi chuyên môn kỹ thuật cao.\nMột nền tảng serverless được quản lý (managed serverless framework) sẽ giúp đơn giản hóa đáng kể quy trình này, loại bỏ nhu cầu cấu hình thủ công và giúp tích hợp liền mạch giữa các thành phần quan trọng.\nĐể đơn giản hóa việc quản lý và bảo mật trong kiến trúc streaming truyền thống, bạn có thể sử dụng Amazon Managed Streaming for Apache Kafka (Amazon MSK).\nDịch vụ được quản lý toàn phần (fully managed) này giúp đơn giản hóa quá trình thu nhận và xử lý dữ liệu.\nAmazon MSK Serverless loại bỏ nhu cầu quản lý cụm (cluster management) và tự động mở rộng (scaling), đồng thời tăng cường bảo mật bằng cách tích hợp với AWS Identity and Access Management (IAM) để xác thực (authentication) và ủy quyền (authorization).\nCách tiếp cận hợp nhất này thay thế quy trình phức tạp trong quản lý chứng chỉ và khóa bảo mật được yêu cầu bởi xác thực client TLS (TLS client authentication) thông qua AWS Certificate Manager, giúp tinh gọn vận hành và nâng cao bảo vệ dữ liệu.\nVí dụ: khi một client cố gắng gửi dữ liệu vào cluster, MSK Serverless sẽ xác minh danh tính (identity) và quyền truy cập (permissions) của client thông qua IAM.\nĐể xử lý dữ liệu hiệu quả, bạn có thể sử dụng Amazon EMR Serverless cùng với ứng dụng Spark được xây dựng trên Spark Structured Streaming framework, cho phép xử lý dữ liệu gần thời gian thực (near real-time).\nCấu hình này giúp xử lý liền mạch các khối dữ liệu lớn từ MSK Serverless, sử dụng IAM authentication để đảm bảo tốc độ và bảo mật cao trong quá trình xử lý.\nBài viết này trình bày một giải pháp toàn diện đầu-cuối (end-to-end solution) để xử lý dữ liệu từ MSK Serverless bằng EMR Serverless Spark Streaming job, được bảo mật bằng IAM authentication.\nNgoài ra, bài viết còn minh họa cách truy vấn dữ liệu đã xử lý bằng Amazon Athena, mang đến quy trình xử lý và phân tích dữ liệu tích hợp, liền mạch.\nGiải pháp này cho phép truy vấn dữ liệu gần thời gian thực (near real-time querying) của dữ liệu mới nhất được xử lý từ MSK Serverless và EMR Serverless thông qua Athena, mang lại phân tích và thông tin tức thời (instant insights \u0026amp; analytics).\nTổng quan giải pháp Sơ đồ dưới đây minh họa kiến trúc (architecture) mà bạn sẽ triển khai trong bài viết này. Quy trình làm việc bao gồm các bước sau:\nKiến trúc bắt đầu với MSK Serverless cluster được cấu hình xác thực bằng IAM.\nMột Amazon Elastic Compute Cloud (Amazon EC2) instance chạy tập lệnh Python producer.py đóng vai trò là trình tạo dữ liệu (data producer), gửi dữ liệu mẫu đến Kafka topic trong cluster.\nSpark Streaming job lấy dữ liệu từ Kafka topic, lưu trữ vào Amazon Simple Storage Service (Amazon S3) và tạo bảng tương ứng trong AWS Glue Data Catalog.\nTrong quá trình tiêu thụ dữ liệu liên tục từ Kafka topic, job luôn cập nhật dữ liệu mới nhất.\nVới checkpointing được bật, job theo dõi các bản ghi đã xử lý, cho phép tiếp tục từ điểm dừng trước đó trong trường hợp có sự cố, đảm bảo quá trình xử lý dữ liệu liền mạch.\nĐể phân tích dữ liệu, người dùng có thể sử dụng Athena — một dịch vụ truy vấn serverless. Athena cho phép thực hiện các truy vấn SQL tương tác trực tiếp trên dữ liệu trong Amazon S3, mà không cần quản lý cơ sở hạ tầng phức tạp.\nĐiều kiện tiên quyết Trước khi bắt đầu, hãy đảm bảo rằng bạn đã có:\nTài khoản AWS đang hoạt động với tính năng thanh toán (billing) được bật\nNgười dùng IAM có quyền administrator access (AdministratorAccess policy) hoặc các quyền cụ thể để tạo và quản lý các tài nguyên như: virtual private cloud (VPC), subnet, security group, IAM roles, NAT gateway, internet gateway, EC2 client, MSK Serverless, EMR Serverless, Amazon EMR Studio và S3 buckets\nDung lượng VPC (VPC capacity) đủ trong AWS Region bạn chọn\nMặc dù việc sử dụng IAM user có administrator access sẽ hoạt động tốt,\nnhưng khuyến nghị rằng trong môi trường production, bạn nên tuân theo nguyên tắc phân quyền tối thiểu (principle of least privilege) — bằng cách tạo custom IAM policies chỉ bao gồm các quyền cần thiết.\nNgười dùng IAM mà chúng ta tạo trong hướng dẫn này có gán AdministratorAccess policy, tuy nhiên bạn không nhất thiết cần quyền cao như vậy.\nĐối với bài viết này, chúng ta sẽ tạo các tài nguyên của giải pháp trong Region us-east-2, sử dụng AWS CloudFormation templates.\nTrong các phần tiếp theo, chúng tôi sẽ hướng dẫn bạn cách cấu hình tài nguyên và triển khai giải pháp.\nCreate MSK Serverless and EMR Serverless resources Stack vpc-msk-emr-serverless-studio.yaml sẽ tạo các tài nguyên sau:\nVPC, subnet, security group, IAM roles, NAT gateway, internet gateway, EC2 client, MSK Serverless, EMR Serverless, EMR Studio, và S3 buckets.\nĐể tạo các tài nguyên cho giải pháp này, hãy thực hiện các bước sau:\nKhởi chạy stack vpc-msk-emr-serverless-studio bằng CloudFormation template.\nAmazon Web Services Sign-In\nCung cấp các giá trị tham số (parameter values) như được liệt kê trong bảng sau.\nParameters Description Sample value EnvironmentName Tên môi trường được thêm làm tiền tố (prefix) cho các tên tài nguyên. msk-emr-serverless-pipeline InstanceType Loại EC2 instance dành cho Amazon MSK client. t2.micro LatestAmiId ID của Amazon Linux 2023 AMI mới nhất cho EC2 instance. Bạn có thể sử dụng giá trị mặc định. /aws/service/ami-amazon-linux-latest/al2023-ami-kernel-6.1-x86_64 VpcCIDR Phạm vi địa chỉ IP (CIDR notation) cho VPC này. 10.192.0.0/16 Parameters Description Sample value PublicSubnet1CIDR Phạm vi địa chỉ IP (CIDR notation) cho public subnet trong Availability Zone đầu tiên. 10.192.10.0/24 PublicSubnet2CIDR Phạm vi địa chỉ IP (CIDR notation) cho public subnet trong Availability Zone thứ hai. 10.192.11.0/24 PrivateSubnet1CIDR Phạm vi địa chỉ IP (CIDR notation) cho private subnet trong Availability Zone đầu tiên. 10.192.20.0/24 Parameters Description Sample value PrivateSubnet2CIDR Phạm vi địa chỉ IP (CIDR notation) cho private subnet trong Availability Zone thứ hai. 10.192.21.0/24 Quá trình tạo stack có thể mất khoảng 10 phút để hoàn tất.\nSau khi stack được tạo xong, bạn có thể kiểm tra thông tin trong tab Outputs\nđể xem các giá trị đầu ra (outputs) của stack. Tiếp theo, bạn sẽ thiết lập quá trình thu nhận dữ liệu (data ingestion) vào Kafka topic từ Kafka EC2 instance\nProduce records to Kafka topic Thực hiện các bước sau để thiết lập data ingestion:\nTruy cập Amazon EC2 console, đến EC2 instance mà bạn đã tạo bằng CloudFormation template.\nĐăng nhập vào EC2 instance bằng Session Manager, một tính năng của AWS Systems Manager.\nChọn instance có tên msk-emr-serverless-blog, sau đó chọn Connect để kết nối.\nTạo Kafka topic trong MSK Serverless từ EC2 instance.\na.Trong lệnh export sau, hãy thay thế my-endpoint bằng giá trị MSKBootstrapServers được hiển thị trong Outputs của CloudFormation stack:$ sudo su - ec2-user $ BS=\u0026lt;your-msk-serverless-endpoint (e.g.) boot-xxxxxx.yy.kafka-serverless.us-east-2.amazonaws.com:9098\u0026gt;\nb.Chạy lệnh sau trên EC2 instance để tạo một Kafka topic có tên sales_data_topic.\nKafka client đã được cài đặt sẵn trong thư mục /home/ec2-user của người dùng ec2-user, kèm theo MSK IAM Authentication JAR và tệp cấu hình client tại đường dẫn /home/ec2-user/kafka_2.12-2.8.1/bin/client.properties — trong đó đã bao gồm các thuộc tính cấu hình IAM authentication. Mã sau đây hiển thị nội dung của tệp client.properties: security.protocol=SASL_SSL sasl.mechanism=AWS_MSK_IAM sasl.jaas.config=software.amazon.msk.auth.iam.IAMLoginModule required; sasl.client.callback.handler.class=software.amazon.msk.auth.iam.IAMClientCallbackHandler\n/home/ec2-user/kafka_2.12-2.8.1/bin/kafka-topics.sh \u0026ndash;bootstrap-server $BS \u0026ndash;command-config /home/ec2-user/kafka_2.12-2.8.1/bin/client.properties \u0026ndash;create \u0026ndash;topic sales_data_topic \u0026ndash;partitions 10\nCreated topic sales_data_topic.\n5.Chạy lệnh sau để gửi dữ liệu (produce records) vào Kafka topic bằng tập lệnh Python syntheticSalesDataProducer.py có sẵn trong EC2 instance. Hãy cập nhật giá trị Region cho phù hợp với khu vực AWS bạn đang sử dụng.\nnohup python3 -u syntheticSalesDataProducer.py \u0026ndash;num_records 1000 \u0026ndash;sales_data_topic sales_data_topic \u0026ndash;bootstrap_server $BS \u0026ndash;region=us-east-2 \u0026gt; syntheticSalesDataProducer.log \u0026amp;\nTìm hiểu về Amazon MSK IAM authentication với EMR Serverless Amazon MSK IAM authentication cho phép xác thực (authentication) và ủy quyền (authorization) an toàn cho các Kafka cluster (MSK Serverless) bằng cách sử dụng IAM roles.\nKhi được tích hợp với EMR Serverless Spark Streaming, Amazon MSK IAM authentication cho phép các Spark job truy cập Kafka topics một cách an toàn, sử dụng IAM roles để kiểm soát quyền truy cập chi tiết (fine-grained access control). Điều này đảm bảo quy trình xử lý và truyền dữ liệu (data processing and streaming) được bảo mật cao.\nCấu hình IAM policy Để cho phép EMR Serverless jobs xác thực với MSK Serverless cluster thông qua IAM, bạn cần gắn (attach) các quyền liên quan đến Kafka vào IAM role của EMR Serverless job execution.\nCác quyền này cho phép job thực hiện những thao tác cần thiết trên Kafka cluster, Kafka topics, và consumer groups.\nChính sách IAM policy sau đây cần được gắn vào EMR Serverless job execution role để cung cấp các quyền cần thiết:\n{ \u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;, \u0026ldquo;Statement\u0026rdquo;: [ { \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kafka-cluster:Connect\u0026rdquo;, \u0026ldquo;kafka-cluster:DescribeCluster\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: [ \u0026ldquo;arn:aws:kafka:::cluster/\u0026lt;SERVERLESS_CLUSTER_NAME\u0026gt;/\u0026rdquo; ], \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo; }, { \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kafka-cluster:CreateTopic\u0026rdquo;, \u0026ldquo;kafka-cluster:DescribeTopic\u0026rdquo;, \u0026ldquo;kafka-cluster:WriteData\u0026rdquo;, \u0026ldquo;kafka-cluster:ReadData\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: [ \u0026ldquo;arn:aws:kafka:::topic/\u0026lt;SERVERLESS_CLUSTER_NAME\u0026gt;//\u0026rdquo; ], \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo; }, { \u0026ldquo;Action\u0026rdquo;: [ \u0026ldquo;kafka-cluster:AlterGroup\u0026rdquo;, \u0026ldquo;kafka-cluster:DescribeGroup\u0026rdquo; ], \u0026ldquo;Resource\u0026rdquo;: [ \u0026ldquo;arn:aws:kafka:::group/\u0026lt;SERVERLESS_CLUSTER_NAME\u0026gt;//\u0026rdquo; ], \u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Allow\u0026rdquo; } ] }\nMã cấu hình trên liên quan đến các hành động (actions) sau:\nConnect, DescribeCluster – Cần thiết để khởi tạo kết nối bảo mật và lấy thông tin metadata.\nDescribeTopic, ReadData, WriteData – Cho phép đọc và ghi dữ liệu (tiêu thụ và sản xuất dữ liệu).\nCreateTopic (tùy chọn) – Cho phép tạo topic động khi cần.\nAlterGroup, DescribeGroup – Cần thiết để quản lý consumer group trong các streaming jobs.\nCác quyền này đảm bảo rằng Spark Streaming job có thể xác thực (authenticate) và tương tác an toàn với MSK Serverless resources bằng IAM role của nó.\nCác thư viện phụ thuộc cần thiết Để bật Amazon MSK IAM authentication trong Spark (đặc biệt là trên EMR Serverless), bạn cần bao gồm các JAR phụ thuộc sau trong Spark Streaming job thông qua tham số sparkSubmitParameters:\nspark-sql-kafka-0-10_2.12 – Trình Kafka connector cho Spark Structured Streaming. Cung cấp DataFrame API để đọc và ghi dữ liệu từ/đến Kafka.\naws-msk-iam-auth – JAR này cung cấp cơ chế xác thực IAM cần thiết để kết nối với MSK Serverless thông qua cơ chế AWS_MSK_IAM SASL mechanism.\nBạn có thể thêm trực tiếp các thư viện phụ thuộc này bằng cách chỉ định chúng trong đối số \u0026ndash;packages khi gửi EMR Serverless job.\nVí dụ: packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,software.amazon.msk:aws-msk-iam-auth:2.2.0\nKhi job được gửi đi, EMR Serverless sẽ tự động tải xuống các JAR này từ Maven Central (hoặc từ kho lưu trữ khác mà bạn đã cấu hình) trong quá trình chạy (runtime).\nBạn không cần gói (bundle) thủ công các JAR này, trừ khi bạn cần sử dụng ngoại tuyến (offline) hoặc yêu cầu phiên bản cụ thể.\nCấu hình Spark Streaming job cho Amazon MSK IAM authentication Trong ứng dụng Spark Streaming của bạn, hãy cấu hình Kafka source với các thuộc tính SASL để kích hoạt IAM-based authentication.\nĐoạn mã sau minh họa cấu hình cần thiết:\ntopic_df = (spark.readStream .format(\u0026ldquo;kafka\u0026rdquo;) .option(\u0026ldquo;kafka.bootstrap.servers\u0026rdquo;, kafka_bootstrap_servers) .option(\u0026ldquo;subscribe\u0026rdquo;, topic_input) .option(\u0026ldquo;startingOffsets\u0026rdquo;, \u0026ldquo;earliest\u0026rdquo;) .option(\u0026ldquo;kafka.security.protocol\u0026rdquo;,\u0026ldquo;SASL_SSL\u0026rdquo;) option(\u0026ldquo;kafka.sasl.mechanism\u0026rdquo;,\u0026ldquo;AWS_MSK_IAM\u0026rdquo;) .option(\u0026ldquo;kafka.sasl.jaas.config\u0026rdquo;,\u0026ldquo;software.amazon.msk.auth.iam.IAMLoginModule required;\u0026rdquo;) .option(\u0026ldquo;kafka.sasl.client.callback.handler.class\u0026rdquo;,\u0026ldquo;software.amazon.msk.auth.iam.IAMClientCallbackHandler\u0026rdquo;) .load() .selectExpr(\u0026ldquo;CAST(value AS STRING)\u0026rdquo;) )\nCác thuộc tính chính bao gồm:\nkafka.security.protocol = SASL_SSL – Kích hoạt truyền thông mã hóa (encrypted communication) qua SSL với SASL authentication.\nkafka.sasl.mechanism = AWS_MSK_IAM – Chỉ định Kafka sử dụng cơ chế xác thực dựa trên IAM (IAM-based SASL mechanism).\nkafka.sasl.jaas.config = software.amazon.msk.auth.iam.IAMLoginModule required;\n– Xác định module đăng nhập (login module) do AWS cung cấp để tích hợp IAM.\nkafka.sasl.client.callback.handler.class = software.amazon.msk.auth.iam.IAMClientCallbackHandler\n– Xử lý việc ký và xác thực thực tế bằng IAM role. Với các thiết lập này, Spark sẽ sử dụng IAM credentials được gán với EMR Serverless job execution role để xác thực với MSK Serverless, mà không cần thêm bất kỳ credentials, chứng chỉ (certificates) hoặc bí mật (secrets) nào khác.\nXử lý dữ liệu bằng EMR Serverless streaming job với Amazon MSK IAM authentication Thực hiện các bước sau để chạy Spark Streaming job nhằm xử lý dữ liệu từ MSK Serverless:\nGửi (submit) Spark Streaming job đến EMR Serverless bằng AWS Command Line Interface (AWS CLI) — công cụ này đã được cài sẵn trên EC2 instance.\nĐăng nhập vào EC2 instance bằng Session Manager.\nChọn instance có tên msk-emr-serverless-blog, sau đó chọn Connect. Chạy lệnh sau để gửi (submit) streaming job.\nCung cấp các tham số (parameters) lấy từ CloudFormation stack output. sudo su - ec2-user\naws emr-serverless start-job-run \u0026ndash;application-id \u0026ndash;execution-role-arn \u0026ndash;mode \u0026lsquo;STREAMING\u0026rsquo; \u0026ndash;job-driver \u0026lsquo;{ \u0026ldquo;sparkSubmit\u0026rdquo;: { \u0026ldquo;entryPoint\u0026rdquo;: \u0026ldquo;s3:///emr_pyspark_streaming_script/pysparkStreamingBlog.py\u0026rdquo;, \u0026ldquo;entryPointArguments\u0026rdquo;:[\u0026quot;\u0026ndash;topic_input\u0026quot;,\u0026ldquo;sales_data_topic\u0026rdquo;,\u0026quot;\u0026ndash;kafka_bootstrap_servers\u0026quot;,\u0026quot;\u0026quot;,\u0026quot;\u0026ndash;output_s3_path\u0026quot;,\u0026ldquo;s3:///output/sales-order-data/\u0026rdquo;,\u0026quot;\u0026ndash;checkpointLocation\u0026quot;,\u0026ldquo;s3:///checkpointing/checkpoint-sales-order-data/\u0026rdquo;,\u0026quot;\u0026ndash;database_name\u0026quot;,\u0026ldquo;emrblog\u0026rdquo;,\u0026quot;\u0026ndash;table_name\u0026quot;,\u0026ldquo;sales_order_data\u0026rdquo;], \u0026ldquo;sparkSubmitParameters\u0026rdquo;: \u0026ldquo;\u0026ndash;conf spark.hadoop.hive.metastore.client.factory.class=com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory \u0026ndash;conf spark.executor.cores=2 \u0026ndash;conf spark.executor.memory=5g \u0026ndash;conf spark.driver.cores=2 \u0026ndash;conf spark.driver.memory=5g \u0026ndash;conf spark.executor.instances=5 \u0026ndash;packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,software.amazon.msk:aws-msk-iam-auth:2.2.0\u0026rdquo; }}\u0026rsquo; 4. Sau khi bạn gửi (submit) job, hãy đăng nhập vào EMR Studio bằng URL được hiển thị trong giá trị EmrServerlessStudioURL từ CloudFormation stack output.\nTrong thanh điều hướng (navigation pane), chọn Applications trong phần Serverless.\nChọn application ID tương ứng với giá trị\nEmrServerlessSparkApplicationID từ CloudFormation stack output.\nTrong tab Streaming job runs, xác minh rằng job đã được gửi thành công, và chờ cho đến khi job bắt đầu chạy.\nXác thực dữ liệu trong Athena Sau khi EMR Serverless Spark Streaming job đã chạy và tạo bảng dữ liệu đã xử lý (processed data table) trong Data Catalog, hãy thực hiện các bước sau để xác thực dữ liệu bằng Athena:\nMở Athena console, truy cập query editor.\nChọn Data Catalog làm nguồn dữ liệu (data source).\nChọn database emrblog — được tạo bởi streaming job.\nĐể xác thực dữ liệu, chạy truy vấn (query) sau:\nSELECT DATE_TRUNC(\u0026#39;minute\u0026#39;, date) AS minute_window, ROUND(SUM(total_amount), 2) AS total_amount FROM emrblog.sales_order_data WHERE DATE_TRUNC(\u0026#39;day\u0026#39;, date) = CURRENT_DATE GROUP BY DATE_TRUNC(\u0026#39;minute\u0026#39;, date) ORDER BY minute_window DESC; Clean up Để xóa các tài nguyên và tránh phát sinh chi phí, hãy thực hiện các bước sau:\nĐăng nhập vào EMR Studio bằng URL được hiển thị trong giá trị\nEmrServerlessStudioURL của CloudFormation stack output.\nTrong thanh điều hướng (navigation pane), chọn Applications trong phần Serverless.\nChọn application ID tương ứng với giá trị\nEmrServerlessSparkApplicationID trong CloudFormation stack output.\nTrong tab Streaming job runs, chọn job đang chạy và hủy (cancel) job đó.\nTruy cập AWS CloudFormation console và xóa stack có tên\nvpc-msk-emr-serverless-studio.\nConclusion Trong bài viết này, chúng tôi đã trình bày một pipeline serverless để xử lý dữ liệu streaming với IAM authentication, giúp bạn tập trung vào việc khai thác thông tin phân tích (analytics insights) thay vì quản lý hạ tầng phức tạp.\nBạn có thể tùy chỉnh mã Spark Streaming trong EMR Serverless để áp dụng các chuyển đổi (transformations) và bộ lọc (filters), đảm bảo rằng dữ liệu hợp lệ được tải vào Amazon S3.\nGiải pháp này kết hợp sức mạnh của Amazon EMR Serverless Spark Streaming và MSK Serverless, được tích hợp an toàn thông qua IAM authentication — cho phép bạn đơn giản hóa quy trình streaming mà không cần lo về việc quản lý tích hợp giữa Amazon MSK và Amazon EMR Spark Streaming.\nVề các tác giả Shubham Purwar là AWS Analytics Specialist Solution Architect.\nAnh hỗ trợ các tổ chức khai thác tối đa tiềm năng dữ liệu của họ bằng cách thiết kế và triển khai các giải pháp phân tích (analytics solutions) có khả năng mở rộng (scalable), bảo mật (secure) và hiệu năng cao (high-performance) trên nền tảng AWS.\nVới kiến thức chuyên sâu về các dịch vụ phân tích của AWS, Shubham hợp tác chặt chẽ với khách hàng để hiểu rõ yêu cầu kinh doanh riêng biệt và xây dựng các giải pháp tùy chỉnh (customized solutions) mang lại thông tin có thể hành động (actionable insights), góp phần thúc đẩy tăng trưởng doanh nghiệp.\nTrong thời gian rảnh, Shubham thích dành thời gian cho gia đình và du lịch khắp thế giới.\nNitin Kumar là Cloud Engineer (ETL) tại AWS, chuyên về AWS Glue.\nVới hơn 10 năm kinh nghiệm, anh có thể mạnh trong việc hỗ trợ khách hàng xử lý khối lượng dữ liệu lớn (big data workloads), tập trung vào xử lý dữ liệu (data processing) và phân tích dữ liệu (analytics).\nAnh luôn tận tâm giúp khách hàng vượt qua các thách thức liên quan đến ETL, đồng thời xây dựng các pipeline xử lý và phân tích dữ liệu có khả năng mở rộng (scalable) trên AWS.\nTrong thời gian rảnh, Nitin thích xem phim, nấu ăn và dành thời gian cho gia đình. Prashanthi Chinthala là Cloud Engineer (DIST) tại AWS.\nCô hỗ trợ khách hàng giải quyết các thách thức liên quan đến Amazon EMR và xây dựng các pipeline xử lý và phân tích dữ liệu (data processing \u0026amp; analytics pipelines) có khả năng mở rộng (scalable) trên nền tảng AWS.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Worklog của em được ghi lại trong suốt 12 tuần thực tập tại First Cloud Journey, bao gồm các nội dung chính như sau:\nTuần 1: Làm quen với môi trường AWS, IAM, MFA, AWS CLI và các dịch vụ cơ bản\nTuần 2: Mạng AWS: VPC, Subnet, Route Table, VPN, VPC Peering và Transit Gateway\nTuần 3: Làm việc với S3, RDS, Cloud9; tham gia Cloud Day Vietnam; nghiên cứu cơ bản cho kiến trúc dự án nhóm\nTuần 4: Tìm hiểu nhóm dịch vụ Storage, VM Import/Export và bắt đầu xây dựng proposal dự án\nTuần 5: Thiết kế giao diện dự án (Admin/Staff), xây dựng login flow và phối hợp với Backend\nTuần 6: Thiết kế kiến trúc AWS cho dự án, nhận phản hồi mentor và chỉnh sửa; chuẩn bị thi giữa kỳ\nTuần 7: Triển khai Frontend serverless, API Gateway, Lambda và thực hành xác thực với Cognito\nTuần 8: Nghiên cứu các trụ cột AWS Architecture: Security, Resilience, Performance, Cost Optimization\nTuần 9: API Gateway nâng cao: Path Parameters, Query Strings, Integration Proxy, Usage Plan và CloudWatch Logs\nTuần 10: Xây dựng Lambda CRUD, import Excel vào DynamoDB, kiểm thử API bằng Postman và triển khai validation\nTuần 11: DevOps trên AWS: IaC, Containers, Canary Deployment, Stage Variables, Route 53\nTuần 12: CloudFront, Docker, ECR, phát triển Auto Scoring Lambda và lưu kết quả vào DynamoDB\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.1-week1/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Understand and practice AWS networking services, especially Amazon VPC and its components. Set up and configure network connections in a Hybrid Cloud environment: VPN, DirectConnect, Hybrid DNS. Implement and configure advanced AWS networking features: VPC Peering, Transit Gateway, Network ACL, Load Balancer. Gain experience with CloudFormation to automate network resource deployment. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about AWS Virtual Private Cloud (VPC) + Subnet + Route table + ENI, EIP + Endpoint + Internet gateway - VPC Security and Multi-VPC features - VPN - DirectConnect - LoadBalancer - ExtraResources 15/09/2025 15/09/2025 https://youtu.be/O9Ac_vGHquM?si=_eLRx1ohGnWONjq6 3 - Practice Amazon VPC and AWS Site-to-Site VPN connections - Practice: + Create VPC + Deploying Amazon EC2 Instances + Setting Up Site-to-Site VPN Connection in AWS 16/09/2025 16/09/2025 https://000003.awsstudygroup.com 4 - Set up Hybrid DNS with Route 53 Resolver - Practice: + Initialize CloudFormation Template + Connecting to RDGW + Deploy Microsoft AD + Setup DNS 17/09/2025 17/09/2025 https://000010.awsstudygroup.com 5 - Setting up VPC Peering - Cross-Peer DNS - Network ACL 18/09/2025 18/09/2025 https://000019.awsstudygroup.com/vi/ 6 - Set up AWS Transit Gateway - Practice: + Create Transit Gateway + Create Transit Gateway Attachments + Create Transit Gateway Route Tables + Add Transit Gateway Routes to VPC Route Tables 19/09/2025 19/09/2025 https://000020.awsstudygroup.com/ Week 2 Achievements: Explored AWS VPC and its components: Subnet, Route Table, ENI, EIP, Endpoint, Internet Gateway. Understood VPC security concepts and Multi-VPC features. Learned the basics of VPN, DirectConnect, Load Balancer, and extra resources. Practiced creating a VPC and deploying EC2 instances inside it. Set up a Site-to-Site VPN connection between on-premises and AWS. Improved hands-on skills with AWS virtual networking. Configured Hybrid DNS with Route 53 Resolver. Deployed Microsoft AD using CloudFormation and set up DNS. Successfully connected to RDGW. Configured VPC Peering between multiple VPCs. Set up Cross-Peer DNS for domain resolution across VPCs. Managed network security using Network ACL. Deployed and configured AWS Transit Gateway. Created Transit Gateway Attachments and Route Tables. Added Transit Gateway routes to VPC Route Tables. Completed a multi-VPC network connectivity model. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 4 Hiểu rõ các nhóm dịch vụ cốt lõi của AWS: Compute, Storage, Networking và Database. Nâng cao kỹ năng thao tác với AWS thông qua cả Management Console và AWS CLI. Khám phá các dịch vụ lưu trữ như S3, Amazon Storage Gateway, Snow Family, AWS Backup và Amazon FSx. Thực hành VM Import/Export để nhập máy ảo lên AWS và xuất instance từ AWS về máy cục bộ. Tham gia sự kiện AWS GenAI Builder Club và ghi nhận các nội dung quan trọng. Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference Material 2 - Tìm hiểu các dịch vụ lưu trữ của AWS:\n+ S3\n+ Amazon Storage Gateway\n+ Snow Family\n- Tìm hiểu giải pháp Disaster Recovery trên AWS\n- Làm quen với AWS Backup 29/09/2025 29/09/2025 https://youtu.be/hsCfP0IxoaM?si=IChJwQVIszhhCfZC 3 - Nghiên cứu VM Import/Export\n- Thực hành:\n+ Nhập máy ảo từ môi trường cục bộ lên AWS\n+ Xuất instance từ AWS về máy cục bộ 30/09/2025 30/09/2025 https://000014.awsstudygroup.com 4 - Viết đề xuất (proposal) cho dự án nhóm 01/10/2025 01/10/2025 5 - Tìm hiểu Amazon FSx for Windows File Server\n- Thực hành:\n+ Tạo các file share mới\n+ Quản lý session người dùng và các tệp đang mở 02/10/2025 02/10/2025 https://000025.awsstudygroup.com/vi/ 6 - Tham gia sự kiện AWS GenAI Builder Club và ghi chú lại các điểm chính 03/10/2025 03/10/2025 Kết quả đạt được trong tuần Nắm được mục đích và cách tổ chức của các nhóm dịch vụ trọng tâm trên AWS: Compute, Storage, Networking và Database. Sử dụng thành thạo AWS Management Console để định vị và thao tác với các dịch vụ cần thiết. Cài đặt, cấu hình AWS CLI đầy đủ (Access Key, Secret Key, Region mặc định…). Áp dụng CLI để thực hiện các thao tác cơ bản: Kiểm tra thông tin tài khoản và cấu hình Liệt kê danh sách region được hỗ trợ Xem và quản lý EC2 instances, key pairs Truy vấn thông tin các dịch vụ đang chạy Hoàn thành thực hành VM Import/Export giữa môi trường local và AWS. Thực hành giải pháp lưu trữ và sao lưu qua S3, AWS Backup và FSx. Tham gia AWS GenAI Builder Club và tổng hợp lại các nội dung chính. Cải thiện khả năng quản lý tài nguyên AWS bằng cả Console và CLI song song. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.7-week7/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives Study and understand the main pillars of the AWS Well-Architected Framework: Secure Architectures (IAM, MFA, SCP, KMS, Security Groups, NACLs, GuardDuty, Shield, WAF, Secrets Manager) Resilient Architectures (Multi-AZ/Region, Auto Scaling, Route 53, Load Balancing, Backup \u0026amp; Restore) High-Performance Architectures (Compute scaling, storage layers, caching, CloudFront) Cost-Optimized Architectures (Cost Explorer, Budgets, Saving Plans, NAT Gateway optimization, Storage Tiering) Learn and deploy API Gateway Proxy Resource. Tasks Completed This Week Day Task Start Date Completion Date Reference Material 2 - Studied Secure Architectures:\n+ IAM, MFA, SCP, KMS\n+ Security Groups, NACLs, GuardDuty, Shield, WAF, Secrets Manager 27/10/2025 27/10/2025 3 - Learned about Resilient Architectures:\n+ Multi-AZ/Region, Auto Scaling\n+ Route 53, Load Balancing, Backup \u0026amp; Restore 28/10/2025 28/10/2025 4 - Explored High-Performing Architectures:\n+ Compute scaling (EC2, Lambda, Fargate)\n+ Storage services, caching, CloudFront 29/10/2025 29/10/2025 5 - Studied Cost-Optimized Architectures:\n+ Cost Explorer, Budgets, Saving Plans\n+ NAT Gateway optimization, Storage Tiering 30/10/2025 30/10/2025 6 - Learned about API Gateway Proxy Resource and deployed the configuration following the tutorial 31/10/2025 31/10/2025 https://youtu.be/zZzHTHs72Sk?si=qhdd4v0mADIh3MJ0 Week 8 Outcomes Completed the study of all major AWS architecture pillars: Security best practices and protective AWS services Resiliency patterns for multi-AZ and multi-region systems High-performance strategies across compute, storage, and caching Cost optimization techniques using AWS tools and architectures Successfully deployed an API Gateway Proxy Resource. Finished all tasks from Day 2 through Day 6 on schedule. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 8 Tìm hiểu và nắm vững các trụ cột chính trong AWS Well-Architected Framework: Kiến trúc bảo mật (IAM, MFA, SCP, KMS, Security Groups, NACLs, GuardDuty, Shield, WAF, Secrets Manager) Kiến trúc có độ bền cao (Multi-AZ/Region, Auto Scaling, Route 53, Load Balancer, Backup \u0026amp; Restore) Kiến trúc hiệu năng cao (tối ưu Compute, giải pháp lưu trữ, Caching, CloudFront) Kiến trúc tối ưu chi phí (Cost Explorer, Budgets, Saving Plans, tối ưu NAT Gateway, Storage Tiering) Triển khai API Gateway Proxy Resource. Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference Material 2 - Nghiên cứu kiến trúc bảo mật:\n+ IAM, MFA, SCP, KMS\n+ Security Groups, NACLs, GuardDuty, Shield, WAF, Secrets Manager 27/10/2025 27/10/2025 3 - Tìm hiểu kiến trúc chịu lỗi và khả năng phục hồi:\n+ Multi-AZ/Region, Auto Scaling\n+ Route 53, Load Balancing, Backup \u0026amp; Restore 28/10/2025 28/10/2025 4 - Học về kiến trúc hiệu năng cao:\n+ Compute scaling (EC2, Lambda, Fargate)\n+ Storage (S3, EFS, EBS), Caching, CloudFront 29/10/2025 29/10/2025 5 - Kiến trúc tối ưu chi phí:\n+ Cost Explorer, Budgets, Saving Plans\n+ NAT Gateway optimization, Storage Tiering 30/10/2025 30/10/2025 6 - Tìm hiểu về Proxy Resource và triển khai thực tế trên API Gateway 31/10/2025 31/10/2025 https://youtu.be/zZzHTHs72Sk?si=qhdd4v0mADIh3MJ0 Kết quả đạt được trong tuần Hoàn tất việc tìm hiểu về các trụ cột của kiến trúc AWS: Kiến trúc bảo mật và các dịch vụ security quan trọng Kiến trúc chịu lỗi và khả năng phục hồi hệ thống Kiến trúc tối ưu hiệu năng cho compute, storage và caching Tối ưu chi phí trên AWS bằng các công cụ và phương pháp chuẩn Triển khai thành công API Gateway Proxy Resource theo hướng dẫn. Hoàn thành đầy đủ các nhiệm vụ từ ngày 2 đến ngày 6 đúng tiến độ. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 9 Tìm hiểu và mở rộng kiến thức về các khái niệm quan trọng trong API Gateway: Path Parameters Query String Parameters Lambda Integration Proxy Usage Plan \u0026amp; API Key Cấu hình CloudWatch Logs cho API Gateway Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference Material 2 - Tìm hiểu về Path Parameters trong API Gateway 03/11/2025 03/11/2025 https://youtu.be/5cMHc1kiq2M?si=zip07VzxdNcjCQpF 3 - Nghiên cứu Query String Parameters trong API Gateway 04/11/2025 04/11/2025 https://youtu.be/BZbF5n39Xnc?si=QHhm0xDo36cuOFcI 4 - Học cách sử dụng Lambda Integration Proxy 05/11/2025 05/11/2025 https://youtu.be/369Em-gKTlE?si=veLKX3EbbLW-S6uO 5 - Tìm hiểu Usage Plan và API Key 06/11/2025 06/11/2025 https://youtu.be/rMG5-pklJO0?si=n14pWvOIGxTkbbw0 6 - Cấu hình CloudWatch Logs cho API Gateway 07/11/2025 07/11/2025 https://youtu.be/OIR2I4CC4N8?si=_5A7an6gxSFcuepv Kết quả đạt được trong tuần Hoàn thành việc học các nội dung: Path Parameters và Query String Parameters Cách hoạt động của Lambda Integration Proxy Tạo và cấu hình Usage Plan và API Key Bật và cấu hình CloudWatch Logs cho API Gateway Toàn bộ các nhiệm vụ từ ngày 2 đến ngày 6 đều được hoàn thành đúng kế hoạch. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Hiểu và thực hành các dịch vụ mạng của AWS, đặc biệt là Amazon VPC và các thành phần của nó. Thiết lập và cấu hình kết nối mạng trong môi trường Hybrid Cloud: VPN, DirectConnect, Hybrid DNS. Triển khai và cấu hình các tính năng mạng nâng cao của AWS: VPC Peering, Transit Gateway, Network ACL, Load Balancer. Làm quen với CloudFormation để tự động hóa việc triển khai tài nguyên mạng. Các công việc cần triển khai trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu về AWS Virtual Private Cloud (VPC) + Subnet + Route table + ENI, EIP + Endpoint + Internet gateway - Bảo mật VPC và các tính năng Multi-VPC - VPN - DirectConnect - LoadBalancer - ExtraResources 15/09/2025 15/09/2025 https://youtu.be/O9Ac_vGHquM?si=_eLRx1ohGnWONjq6 3 - Thực hành Amazon VPC và kết nối AWS Site-to-Site VPN - Thực hành: + Tạo VPC + Triển khai Amazon EC2 Instances + Thiết lập kết nối Site-to-Site VPN trong AWS 16/09/2025 16/09/2025 https://000003.awsstudygroup.com 4 - Thiết lập Hybrid DNS với Route 53 Resolver - Thực hành: + Khởi tạo CloudFormation Template + Kết nối tới RDGW + Triển khai Microsoft AD + Cấu hình DNS 17/09/2025 17/09/2025 https://000010.awsstudygroup.com 5 - Thiết lập VPC Peering - Cross-Peer DNS - Network ACL 18/09/2025 18/09/2025 https://000019.awsstudygroup.com/vi/ 6 - Thiết lập AWS Transit Gateway - Thực hành: + Tạo Transit Gateway + Tạo Transit Gateway Attachments + Tạo Transit Gateway Route Tables + Thêm Transit Gateway Routes vào VPC Route Tables 19/09/2025 19/09/2025 https://000020.awsstudygroup.com/ Kết quả đạt được tuần 2: Khám phá AWS VPC và các thành phần của nó: Subnet, Route Table, ENI, EIP, Endpoint, Internet Gateway. Hiểu các khái niệm về bảo mật VPC và các tính năng Multi-VPC. Nắm được kiến thức cơ bản về VPN, DirectConnect, Load Balancer và các tài nguyên bổ trợ. Thực hành tạo VPC và triển khai EC2 instances bên trong. Thiết lập kết nối Site-to-Site VPN giữa hệ thống on-premises và AWS. Cải thiện kỹ năng thực hành với mạng ảo AWS. Cấu hình Hybrid DNS với Route 53 Resolver. Triển khai Microsoft AD bằng CloudFormation và cấu hình DNS. Kết nối thành công tới RDGW. Cấu hình VPC Peering giữa nhiều VPC. Thiết lập Cross-Peer DNS để phân giải tên miền giữa các VPC. Quản lý bảo mật mạng bằng Network ACL. Triển khai và cấu hình AWS Transit Gateway. Tạo Transit Gateway Attachments và Route Tables. Thêm các tuyến Transit Gateway vào VPC Route Tables. Hoàn thành mô hình kết nối mạng multi-VPC. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/","title":"Khám Phá Agentic AI – Workshop Amazon QuickSuite","tags":[],"description":"","content":"Khám Phá Agentic AI – Workshop Amazon QuickSuite - Ngày: 7 tháng 11, 2025 - Địa điểm: Văn phòng AWS Việt Nam, Bitexco Financial Tower, TP.HCM\nTổng quan sự kiện Một workshop đặc biệt tập trung vào sự chuyển dịch từ AI Tạo sinh (Generative AI) thụ động sang AI Tác tử (Agentic AI) tự chủ. Sự kiện đã có buổi trình diễn trực tiếp đầu tiên của Amazon QuickSuite tại Việt Nam và giới thiệu Chương trình AWS LIFT để giảm bớt rào cản tài chính cho việc áp dụng.\nMục tiêu chính:\nĐịnh nghĩa Agentic AI: Làm rõ khái niệm về các tác tử AI tự chủ có khả năng suy luận và thực thi nhiệm vụ. Giới thiệu Amazon QuickSuite: Trình diễn nền tảng hợp nhất giữa trực quan hóa dữ liệu (QuickSight) và AI tạo sinh (Quick Suite Q). Hỗ trợ học tập thực hành: Cung cấp một môi trường thực tế để xây dựng các khái niệm AI với sự hướng dẫn của chuyên gia. Thúc đẩy áp dụng: Cung cấp khoản tín dụng 80.000 USD thông qua Chương trình AWS LIFT để thúc đẩy R\u0026amp;D. Bài học và Erkenntnisse chính Tập trung vào tính tự chủ: Mục tiêu thiết kế của Agentic AI là xây dựng các hệ thống hành động thay mặt người dùng, không chỉ cung cấp thông tin. Cách tiếp cận hệ sinh thái là rất quan trọng: Các tác tử hiệu quả đòi hỏi một mạng lưới công cụ được kết nối, giống như mạng lưới được cung cấp bởi QuickSuite, để liên kết các nguồn dữ liệu với logic hành động. Việc áp dụng sớm tạo ra lợi thế: Việc thành thạo các công cụ như QuickSuite trước khi chúng trở nên phổ biến sẽ mang lại một lợi thế cạnh tranh đáng kể. Nguồn vốn thúc đẩy sự đổi mới: Các ưu đãi tài chính như chương trình LIFT cho phép các công ty thử nghiệm và đổi mới nhanh hơn. Ứng dụng vào Công việc Khám phá QuickSuite cho Phân tích: Nghiên cứu việc tích hợp QuickSight và Quick Suite Q để tạo ra các \u0026ldquo;Tác tử Phân tích\u0026rdquo; có thể tự động hóa việc báo cáo và phân tích dữ liệu. Đảm bảo kinh phí cho R\u0026amp;D: Đăng ký Chương trình AWS LIFT để đảm bảo các khoản tín dụng cho các dự án nghiên cứu và phát triển liên quan đến AI sắp tới. Xác định các trường hợp sử dụng tự động hóa: Kiểm tra các hoạt động nội bộ để tìm các tác vụ lặp đi lặp lại, nhiều bước phù hợp để một tác tử AI thực hiện tự chủ. Hợp tác với các đối tác triển khai: Hợp tác với các đối tác như Cloud Kinetics để thiết kế và triển khai kiến trúc phức tạp, giảm thiểu rủi ro phát triển nội bộ. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.2-perequisites/","title":"5.2 Prerequisites","tags":[],"description":"","content":"Module 2: Prerequisites - Chuẩn Bị Tài Khoản \u0026amp; Tools Mục tiêu Module Tạo \u0026amp; cấu hình AWS account Thiết lập IAM roles \u0026amp; policies Verify quyền truy cập cần thiết Setup cost monitoring \u0026amp; alerts Phần 1: AWS Account Setup Bước 1: Tạo AWS Account Nếu chưa có AWS account:\nTruy cập https://aws.amazon.com/ Click \u0026ldquo;Create an AWS Account\u0026rdquo; Điền email, password, account name Chọn Support Plan (Free tier available) Verify email \u0026amp; setup billing information Bước 2: Login vào AWS Console Truy cập https://console.aws.amazon.com/ Nhập root account email \u0026amp; password Verify MFA (Multi-Factor Authentication) nếu được yêu cầu Note: Nên bật MFA cho root account để bảo mật\nPhần 2: IAM Setup - Tạo Admin User Bước 1: Truy cập IAM Dashboard Từ AWS Console, tìm kiếm \u0026ldquo;IAM\u0026rdquo; Click \u0026ldquo;IAM\u0026rdquo; từ services list Click \u0026ldquo;Users\u0026rdquo; trong navigation menu Bước 2: Tạo IAM User cho Workshop Click \u0026ldquo;Create user\u0026rdquo; Nhập User name: \u0026ldquo;workshop-admin\u0026rdquo; Check \u0026ldquo;Provide user access to the AWS Management Console - optional\u0026rdquo; Check \u0026ldquo;Users must create a new password at next sign-in - Recommended\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Bước 3: Gán Permissions Chọn \u0026ldquo;Attach policies directly\u0026rdquo;\nTìm và check policies sau:\nAdministratorAccess (cho phép toàn bộ services) Click \u0026ldquo;Next\u0026rdquo;\nBước 4: Review \u0026amp; Create Review thông tin user Click \u0026ldquo;Create user\u0026rdquo; Download \u0026ldquo;.csv\u0026rdquo; file chứa credentials Bước 5: Login bằng IAM User Copy User sign-in link từ confirmation screen Mở link trong browser mới Login bằng user name \u0026amp; password Phần 3: Verify Permissions Kiểm tra quyền truy cập AWS Services Login vào AWS Console bằng IAM user Truy cập từng service để verify quyền: Cognito: https://console.aws.amazon.com/cognito/ Lambda: https://console.aws.amazon.com/lambda/ EC2: https://console.aws.amazon.com/ec2/ API Gateway: https://console.aws.amazon.com/apigateway/ S3: https://console.aws.amazon.com/s3/ VPC: https://console.aws.amazon.com/vpc/ Kiểm tra: Bạn nên thấy \u0026ldquo;Create application\u0026rdquo; (không phải error message)\nPhần 4: Resources Naming Convention Để quản lý resources dễ dàng, sử dụng naming convention:\n{project-name}-{service}-{environment} Examples:\nsmoking-cessation-cognito-dev smoking-cessation-lambda-auth-dev smoking-cessation-db-pg-dev (PostgreSQL on EC2) smoking-cessation-db-mongo-dev (MongoDB on EC2) smoking-cessation-api-dev smoking-cessation-frontend-dev smoking-cessation-vpc-dev Benefit: Dễ tìm kiếm \u0026amp; quản lý resources trong console\nTroubleshooting Không thể tạo IAM User Kiểm tra: Bạn đã login bằng root account hay IAM user khác? Solution: Login lại bằng root account để tạo IAM user Permission Denied errors Verify: IAM policies attached to user Kiểm tra: Policies có include service bạn đang sử dụng không? Contact AWS support nếu cần elevated permissions Notes Từ bây giờ, tất cả actions đều sử dụng IAM user, không phải root Mỗi service sẽ có specific IAM role (created ở modules tiếp theo) Free Tier cung cấp sufficient resources cho learning Kết Quả Đạt Được Sau Module 2, bạn sẽ có:\nAWS account đã activate IAM user \u0026ldquo;workshop-admin\u0026rdquo; có quyền admin Quyền truy cập tất cả AWS services cần thiết Sẵn sàng cho Module 3 (Setup Cognito) "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Đề Xuất Hệ Thống Hỗ Trợ Cai Thuốc Lá 1. Tóm tắt Điều hành Bản đề xuất này mô tả thiết kế và triển khai một Nền tảng Hỗ trợ Cai Thuốc Lá dựa trên đám mây, nhằm giúp người dùng bỏ thuốc thông qua việc theo dõi dữ liệu, phân tích hành vi, huấn luyện bằng AI và tương tác cộng đồng.\nHệ thống tích hợp một hạ tầng backend hiện đại, có khả năng mở rộng, được triển khai trên AWS Cloud, đảm bảo tính sẵn sàng cao, bảo mật và trải nghiệm người dùng liền mạch.\nMục tiêu là cung cấp một hành trình thông minh và cá nhân hóa để người dùng theo dõi, lập kế hoạch và đạt được mục tiêu cai thuốc—đồng thời mang đến cho quản trị viên và huấn luyện viên các công cụ để hỗ trợ và hướng dẫn họ.\n2. Mục tiêu Hệ thống Giúp người dùng xây dựng và theo dõi các kế hoạch cai thuốc được cá nhân hóa. Theo dõi hành vi hút thuốc và tiến trình sức khỏe theo thời gian thực. Cung cấp huấn luyện bằng AI, nhắc nhở và thông điệp động viên. Cho phép tương tác và khích lệ giữa các thành viên trong cộng đồng. Cung cấp hạ tầng điện toán đám mây an toàn và có khả năng mở rộng. 3. Các Tính năng Chính Tính năng cho Người dùng Đăng ký \u0026amp; Gói thành viên: Người dùng có thể đăng ký, chọn các gói dịch vụ và thanh toán cho các tính năng cao cấp. Theo dõi tình trạng hút thuốc: Ghi lại số lượng thuốc lá sử dụng mỗi ngày, chi phí và tần suất. Kế hoạch cai thuốc cá nhân: Tạo và điều chỉnh kế hoạch cai dựa trên thói quen và mục tiêu của người dùng. Theo dõi tiến trình: Hiển thị các thống kê như số ngày không hút thuốc, tiền tiết kiệm và cải thiện sức khỏe. Thông báo động viên: Gửi tự động nhắc nhở và thông điệp khích lệ theo định kỳ. Thành tựu \u0026amp; Huy hiệu: Mở khóa các cột mốc như “7 ngày không hút thuốc” hoặc “Tiết kiệm 100K”. Tương tác cộng đồng: Chia sẻ thành tích, lời khuyên và động viên trong mạng lưới hỗ trợ. Tác tử AI Coaching: Hướng dẫn cá nhân hóa dựa trên công nghệ máy học. Tích hợp thiết bị sức khỏe: Thu thập dữ liệu từ các thiết bị đeo thông minh hoặc IoT để theo dõi tiến trình. Tính năng cho Quản trị viên \u0026amp; Nhà vận hành Dashboard \u0026amp; Báo cáo: Giám sát chỉ số người dùng, mức độ tương tác và phân tích tác động sức khỏe. Cổng huấn luyện viên: Huấn luyện viên có thể tương tác với người dùng qua chat hoặc video. Quản lý phản hồi \u0026amp; đánh giá: Theo dõi và phản hồi mức độ hài lòng của người dùng. Quản lý thanh toán \u0026amp; gói dịch vụ: Quản lý các gói phí và đăng ký của người dùng. 4. Kiến trúc Hệ thống (AWS Cloud) Hệ thống tận dụng các dịch vụ do AWS quản lý để đảm bảo khả năng mở rộng và bảo mật, như được minh họa trong sơ đồ kiến trúc.\nLớp Frontend Amazon S3 lưu trữ website tĩnh (frontend React hoặc Angular). Amazon CloudFront phân phối nội dung toàn cầu và xử lý mã hóa SSL/TLS. Xác thực \u0026amp; Phân quyền Amazon Cognito quản lý đăng ký, đăng nhập và liên kết danh tính, đảm bảo truy cập an toàn cho cả người dùng và huấn luyện viên. Lớp Ứng dụng AWS Lambda xử lý các tác vụ serverless như thanh toán hoặc các hoạt động API nhẹ. Network Load Balancer (NLB) phân phối các yêu cầu đến các instance EC2 backend. EC2 (Private Subnet) chạy các microservice cốt lõi: User Service Cessation Service Social Media Service Lớp Dữ liệu PostgreSQL Databases cho dữ liệu người dùng và cai thuốc (trên EC2 hoặc RDS). MongoDB cho tính năng xã hội và dữ liệu phi cấu trúc. S3 Bucket (Backup) lưu trữ bản sao lưu cơ sở dữ liệu được mã hóa định kỳ. DevOps Pipeline GitLab CI/CD Pipeline tự động triển khai lên Amazon ECR và EC2. VPC Endpoint đảm bảo kết nối an toàn với các dịch vụ AWS mà không cần ra Internet. EC2 Instance Connect Endpoint cho phép truy cập quản trị có kiểm soát. Hình 1 – Kiến trúc điện toán đám mây AWS cho Nền tảng Hỗ trợ Cai Thuốc Lá 5. Bảo mật và Tuân thủ Mã hóa dữ liệu: Tất cả dữ liệu nhạy cảm được mã hóa khi truyền (TLS) và khi lưu trữ (AES-256). IAM Policies: Kiểm soát truy cập chi tiết cho từng vai trò hệ thống. Private Subnets: Backend và cơ sở dữ liệu biệt lập khỏi Internet công cộng. VPC Link \u0026amp; Endpoints: Đảm bảo giao tiếp nội bộ an toàn giữa các dịch vụ. Chiến lược sao lưu: Sao lưu tự động hàng ngày lên S3 với versioning và lifecycle policy. 6. Khả năng mở rộng và Hiệu năng Auto Scaling: EC2 và Lambda tự động mở rộng khi nhu cầu tăng. CDN Caching: CloudFront lưu cache nội dung giúp tăng tốc phân phối toàn cầu. Load Balancing: NLB phân phối lưu lượng và đảm bảo chịu lỗi. Microservices tách biệt: Cho phép mở rộng độc lập từng dịch vụ. 7. Phát triển trong tương lai Tích hợp với ứng dụng di động Android và iOS. Dự đoán nguy cơ tái hút sử dụng AI nâng cao dựa trên hành vi người dùng. Chat và tư vấn video thời gian thực. Tích hợp cổng thanh toán bên thứ ba. Các thử thách gamification và hệ thống phần thưởng. 8. Kết quả kỳ vọng Tăng tỷ lệ bỏ thuốc thành công. Tăng động lực và mức độ tương tác của người dùng. Hệ thống có khả năng mở rộng để hỗ trợ lượng người dùng lớn. Nền tảng an toàn, tuân thủ và dễ bảo trì. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 10 Củng cố kiến thức nền tảng về API Gateway và cơ chế tích hợp dịch vụ. Xây dựng và triển khai Lambda để xử lý upload dữ liệu Excel vào DynamoDB. Phát triển đầy đủ các thao tác CRUD bằng Lambda kết hợp DynamoDB. Cấu hình API Gateway và kiểm thử Lambda thông qua Postman. Tìm hiểu và áp dụng kỹ thuật xác thực cấu trúc request bằng API Gateway Models. Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference Material 2 - Tìm hiểu tổng quan về API Gateway 10/11/2025 10/11/2025 https://youtu.be/YjOjDtprDSo?si=NYb88SlpO2VMhLYx 3 - Tạo Lambda function để đọc file Excel và lưu dữ liệu vào DynamoDB 11/11/2025 11/11/2025 4 - Xây dựng Lambda function xử lý CRUD cho dữ liệu 12/11/2025 12/11/2025 5 - Cấu hình API Gateway và kiểm thử Lambda bằng Postman 13/11/2025 13/11/2025 https://000079.awsstudygroup.com/ 6 - Áp dụng Body Validation bằng API Gateway Models 14/11/2025 14/11/2025 https://youtu.be/tmhZbcqlEiQ?si=MBkltclc2rWTlHKr Kết quả đạt được trong tuần Nắm vững hơn luồng hoạt động và kiến trúc của API Gateway. Viết và triển khai Lambda để đọc file Excel, phân tích dữ liệu và lưu vào DynamoDB thành công. Phát triển đầy đủ chức năng CRUD dựa trên Lambda + DynamoDB. Cấu hình và kiểm thử API Gateway bằng Postman, đảm bảo các endpoint hoạt động đúng. Thực hiện validation dữ liệu đầu vào bằng API Gateway Models, giúp đảm bảo độ chính xác và chuẩn hóa request. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 11 Tăng cường hiểu biết về các thực hành DevOps trên AWS: Infrastructure as Code (IaC) Container Services và các công cụ điều phối Monitoring \u0026amp; Observability Triển khai API ở nhiều môi trường bằng Stage Variables Nắm và áp dụng kỹ thuật Canary Deployment trên API Gateway Sử dụng ANY Method cho API Gateway để xử lý linh hoạt endpoint Tìm hiểu Route 53 và cơ chế DNS routing trên AWS Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference Material 2 - Tìm hiểu DevOps trên AWS:\n+ IaC\n+ Container Services\n+ Monitoring \u0026amp; Observability 17/11/2025 17/11/2025 3 - Áp dụng Stage Variables để triển khai API lên nhiều môi trường 18/11/2025 18/11/2025 https://youtu.be/nubjfS50wFg?si=XQsWE01pyAtyrJh8 4 - Thực hành Canary Deployment trên API Gateway 19/11/2025 19/11/2025 https://youtu.be/BAjj_XUXnVA?si=21aaQMnOoLTGAeGk 5 - Sử dụng ANY Method trong API Gateway 20/11/2025 20/11/2025 https://youtu.be/nXqXJPepMJU?si=mwUbp48qdAHSHaT7 6 - Tìm hiểu Amazon Route 53 và các khái niệm định tuyến DNS 21/11/2025 21/11/2025 https://youtu.be/JRZiQFVWpi8?si=hIE5i0OnqhTw-5nI Kết quả đạt được trong tuần Hiểu rõ các khái niệm DevOps trong AWS bao gồm IaC, container services và công cụ giám sát. Triển khai API đa môi trường thông qua Stage Variables. Ứng dụng Canary Deployment để kiểm thử và phát hành thay đổi một cách an toàn. Sử dụng ANY Method trong API Gateway để tăng tính linh hoạt cho routing. Nắm được nguyên tắc hoạt động và định tuyến DNS bằng Amazon Route 53. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 12 Tìm hiểu khái niệm CloudFront và cách tính chi phí sử dụng. Nắm kiến thức nền tảng về Docker và quy trình container hóa. Học cách sử dụng Amazon ECR và đẩy Docker image lên ECR. Xây dựng Lambda function để thực hiện Auto Scoring dựa trên mô hình Machine Learning. Bổ sung chức năng lưu kết quả Auto Scoring vào DynamoDB. Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference Material 2 - Tìm hiểu CloudFront và mô hình tính phí 24/11/2025 24/11/2025 3 - Học cách sử dụng Docker 25/11/2025 25/11/2025 4 - Tìm hiểu về Amazon ECR và các lệnh đẩy Docker image lên ECR 26/11/2025 26/11/2025 5 - Xây dựng Auto Scoring Function trên AWS Lambda 27/11/2025 27/11/2025 6 - Tích hợp chức năng lưu kết quả Auto Scoring vào DynamoDB 28/11/2025 28/11/2025 Kết quả đạt được trong tuần Hiểu kiến trúc tổng quan của CloudFront và mô hình định giá. Thành thạo các thao tác cơ bản với Docker: build image và chạy container. Đẩy thành công Docker image lên Amazon ECR bằng AWS CLI. Xây dựng Lambda function xử lý Auto Scoring dựa trên mô hình ML. Hoàn thiện việc lưu trữ kết quả Auto Scoring vào DynamoDB để phục vụ truy xuất và phân tích. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.3-event3/","title":"AWS Cloud Mastery Series #3 - Chuyên sâu về Trụ cột Bảo mật","tags":[],"description":"","content":"AWS Cloud Mastery Series #3 - Chuyên sâu về Trụ cột Bảo mật - Ngày: 1 tháng 12, 2025 - Địa điểm: Bitexco Financial Tower, 2 Đ. Hải Triều, Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nTổng quan sự kiện Một buổi workshop chuyên sâu tập trung vào Trụ cột Bảo mật (Security Pillar) trong Khuôn khổ AWS Well-Architected. Sự kiện cung cấp kiến thức và các phương pháp thực hành tốt nhất để bảo vệ khối lượng công việc trên đám mây.\nMục tiêu chính:\nHiểu sâu về Trụ cột Bảo mật: Phân tích các nguyên tắc thiết kế và các lĩnh vực chính của bảo mật trên AWS. Quản lý Danh tính và Truy cập: Tìm hiểu sâu về AWS IAM, MFA và các phương pháp hay nhất để kiểm soát truy cập. Bảo vệ Dữ liệu: Khám phá các kỹ thuật mã hóa dữ liệu khi lưu trữ (at-rest) và khi truyền (in-transit). Tự động hóa và Giám sát: Học cách sử dụng AWS Config, CloudTrail và Security Hub để giám sát và tự động hóa các biện pháp kiểm soát bảo mật. Bài học và Erkenntnisse chính Bảo mật là Trách nhiệm chung: Hiểu rõ mô hình trách nhiệm chung và vai trò của khách hàng trong việc bảo mật ứng dụng trên đám mây. Bảo mật theo lớp (Defense in Depth): Áp dụng nhiều lớp bảo mật để bảo vệ tài nguyên một cách toàn diện. Tự động hóa là Chìa khóa: Tự động hóa các quy trình kiểm tra và khắc phục bảo mật giúp giảm thiểu sai sót của con người và phản ứng nhanh hơn với các mối đe dọa. Ứng dụng vào Công việc Đánh giá lại Chính sách IAM: Rà soát và củng cố các chính sách IAM hiện tại theo nguyên tắc đặc quyền tối thiểu (least privilege). Triển khai Giám sát Bảo mật: Thiết lập AWS Security Hub để có một cái nhìn tổng quan, tập trung về tình hình bảo mật. Tăng cường Mã hóa Dữ liệu: Đảm bảo tất cả dữ liệu nhạy cảm được mã hóa bằng AWS KMS. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-setup-cognito/","title":"5.3 Setup Cognito","tags":[],"description":"","content":"Module 3: Create Cognito User Pool \u0026amp; Authentication Mục tiêu Module Tạo Cognito User Pool mới Cấu hình Sign-up \u0026amp; Sign-in options Tạo App Client cho frontend Thiết lập User Groups (admin, coach, user) Tạo test users Test authentication flow Duration: 3-4 giờ\nPhần 1: Tạo Cognito User Pool Bước 1: Truy cập Cognito Console Login vào AWS Console (https://console.aws.amazon.com/) Tìm kiếm \u0026ldquo;Cognito\u0026rdquo; Click vào \u0026ldquo;Cognito\u0026rdquo; từ services list Click \u0026ldquo;User pools\u0026rdquo; (left menu) Click \u0026ldquo;Create user pool\u0026rdquo; Bước 2: Điền \u0026ldquo;Set up resources for your application\u0026rdquo; Sau khi click \u0026ldquo;Create user pool\u0026rdquo;, bạn sẽ thấy form \u0026ldquo;Set up resources for your application\u0026rdquo;:\n2.1 Define your application Application type: Chọn \u0026ldquo;Single-page application (SPA)\u0026rdquo; Đây là loại ứng dụng React của bạn Name your application: Nhập smoking-cessation-app Giới hạn: 128 ký tự, chỉ chứa chữ, số, spaces, +, =, ,, ., @, - 2.2 Options for sign-in identifiers Chọn các tùy chọn này:\n☑️ Email (Check) ☐ Phone number (Uncheck) ☐ Username (Uncheck) Lý do: Email là cách đơn giản nhất để users đăng nhập\n2.3 Self-registration ☑️ Enable self-registration (Check) Điều này cho phép users tự đăng ký trên platform Sẽ hiển thị link \u0026ldquo;Sign up\u0026rdquo; trên login page 2.4 Required attributes for sign-up Chọn các attributes bắt buộc:\n☑️ email (Already checked vì bạn selected Email for sign-in) ☑️ name (Check - lưu tên người dùng) 2.5 Add a return URL (optional) Click vào field \u0026ldquo;Return URL\u0026rdquo;\nNhập: https://localhost:3000/callback\nĐây là nơi Cognito sẽ redirect sau khi login thành công Note: For development, localhost hỗ trợ HTTP; for production, phải là HTTPS Sau khi điền xong, click \u0026ldquo;Create user directory\u0026rdquo; button ở dưới\nBước 3: Configure Security Requirements Sau khi click \u0026ldquo;Authentication methods\u0026rdquo;, bạn sẽ đến trang \u0026ldquo;Authentication methods\u0026rdquo;:\nPassword policy:\nChon Cognito defaults trong Password policy mode Edit email configuration:\nChọn Send email with Cognito trong Email provider Bấm Save changes Account recovery:\nSelf-service account recovery: ☑️ Enable Recovery method: ☑️ Email ☑️ SMS Bước 4: Configure Sign-up Experience Trang \u0026ldquo;Configure sign-up experience\u0026rdquo;:\nSelf-registration (đã bật ở bước 2):\nEnable self-registration: ✅ Yes Allow users to sign themselves up: ✅ Yes Standard attributes to collect:\n☑️ email (Required) ☑️ name (Required) ☐ phone_number (Optional - không cần) ☐ family_name (Optional - không cần) Verification settings:\nHow will a user be confirmed?: Email Cognito sẽ gửi confirmation link qua email Click \u0026ldquo;Next\u0026rdquo;\nBước 5: Configure Message Delivery Trang \u0026ldquo;Configure message delivery\u0026rdquo;:\nEmail provider:\nSelect: Cognito (default) Note: Free tier cho phép 50 emails/ngày. Cho production, sử dụng Amazon SES. From email address:\nUse Cognito default email Emails sẽ gửi từ no-reply@cognito.amazonaws.com Click \u0026ldquo;Next\u0026rdquo;\nBước 6: Review \u0026amp; Create Trang cuối \u0026ldquo;Review and create\u0026rdquo;:\nReview tất cả settings bạn đã cấu hình:\nApplication type: Single-page application (SPA) Application name: smoking-cessation-app Sign-in experience Security requirements Sign-up experience Message delivery Scroll xuống, nhập User pool name:\nName: smoking-cessation-users Đây là tên của User Pool (khác với Application name) Click \u0026ldquo;Create user pool\u0026rdquo;\n⏳ Chờ khoảng 2-3 phút để user pool được tạo. Bạn sẽ thấy success message khi xong.\nBước 7: Success Page - Quick Setup Guide Sau khi user pool được tạo, bạn sẽ thấy trang \u0026ldquo;Set up resources for your application\u0026rdquo; với các tùy chọn:\nTrang này hiển thị:\n\u0026ldquo;Your application \u0026hellip; have been created successfully!\u0026rdquo; - Thông báo thành công \u0026ldquo;Check out your sign-in page\u0026rdquo; - Liên kết để test login page \u0026ldquo;What\u0026rsquo;s the development platform for your single page application?\u0026rdquo; - Các tùy chọn (React, Angular, JavaScript) Code examples - Hướng dẫn tích hợp với frontend Lưu ý: Bạn sẽ cấu hình code tích hợp ở Module tiếp theo. Bây giờ, hãy click \u0026ldquo;Go to overview\u0026rdquo; ở phía dưới để đi tới user pool overview page.\nPhần 2: Lấy User Pool ID Sau khi user pool được tạo:\nBạn sẽ nhìn thấy success message Note lại User Pool ID: Format là ap-southeast-1_xxxxxxxxxxxxx Ví dụ: ap-southeast-1_GAXOSoku5 Lưu vào file .env: COGNITO_USER_POOL_ID=ap-southeast-1_dskxxxxt3 COGNITO_REGION=ap-southeast-1 Phần 3: Tạo App Client Bước 1: Truy cập App Integration Từ User Pool dashboard (smoking-cessation-users) Left menu: Click \u0026ldquo;App integration\u0026rdquo; Click \u0026ldquo;App clients and analytics\u0026rdquo; Click \u0026ldquo;Create app client\u0026rdquo; Bước 2: Configure App Client App client name: smoking-cessation-frontend Refresh token expiration: 30 days Access token expiration: 1 hour (3600 seconds) ID token expiration: 1 hour (3600 seconds) Token validity units: hours Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Authentication Flows Authentication flows and security Select: ✅ ALLOW_USER_PASSWORD_AUTH (for username/password login) ✅ ALLOW_REFRESH_TOKEN_AUTH (for refresh token rotation) ✅ ALLOW_USER_SRP_AUTH (secure password authentication) Click \u0026ldquo;Next\u0026rdquo; Bước 4: Configure Hosted UI (Optional but Recommended) Hosted UI settings Hosted UI domain name: smoking-cessation-dev Click \u0026ldquo;Check availability\u0026rdquo; If taken, append -{number} (e.g., smoking-cessation-dev-2) Allowed callback URLs (add for your frontend): For development: http://localhost:3000/callback For production: https://yourdomain.com/callback Allowed sign-out URLs: For development: http://localhost:3000/logout For production: https://yourdomain.com/logout Allowed OAuth 2.0 scopes: ✅ openid ✅ email ✅ profile Click \u0026ldquo;Next\u0026rdquo; Bước 5: Advanced Security Settings Advanced security settings Prevent user existence errors: ✅ Enable This prevents attackers from discovering valid usernames Click \u0026ldquo;Create app client\u0026rdquo; ⏳ Chờ app client được tạo\nBước 6: Lấy App Client ID Sau khi App Client được tạo:\nTìm Client ID ở phần app client details Ví dụ: 4175kqc33olfjinhkll4jme379 Lưu vào .env: COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 Phần 4: Tạo User Groups Bước 1: Truy cập User Groups Từ User Pool (smoking-cessation-users) Left menu: Click \u0026ldquo;User groups\u0026rdquo; Click \u0026ldquo;Create group\u0026rdquo; Bước 2: Tạo Admin Group Group name: admins Description: Platform administrators with full access Assign IAM role to this group: (Optional, skip for now) Click \u0026ldquo;Create group\u0026rdquo; Bước 3: Tạo Coach Group Click \u0026ldquo;Create group\u0026rdquo; Group name: coaches Description: Coaches who help users quit smoking Click \u0026ldquo;Create group\u0026rdquo; Bước 4: Tạo User Group Click \u0026ldquo;Create group\u0026rdquo; Group name: users Description: Regular users of the platform Click \u0026ldquo;Create group\u0026rdquo; Phần 5: Tạo Test Users Bước 1: Truy cập Users Từ User Pool (smoking-cessation-users) Left menu: Click \u0026ldquo;Users\u0026rdquo; Click \u0026ldquo;Create user\u0026rdquo; Bước 2: Tạo Admin User Username: admin-test Email address: admin@test.com Temporary password: TempAdminPass123! Mark email as verified: ✅ Check Mark phone number as verified: ☐ Click \u0026ldquo;Create user\u0026rdquo; Bước 3: Gán Admin User vào Admin Group Click vào user admin-test vừa tạo Scroll xuống \u0026ldquo;Group membership\u0026rdquo; Click \u0026ldquo;Add user to groups\u0026rdquo; Chọn admins group Click \u0026ldquo;Add user to groups\u0026rdquo; Bước 4: Tạo Coach User Trở về Users list Click \u0026ldquo;Create user\u0026rdquo; Username: coach-test Email address: coach@test.com Temporary password: TempCoachPass123! Mark email as verified: ✅ Check Click \u0026ldquo;Create user\u0026rdquo; Bước 5: Gán Coach User vào Coach Group Click vào user coach-test Scroll xuống \u0026ldquo;Group membership\u0026rdquo; Click \u0026ldquo;Add user to groups\u0026rdquo; Chọn coaches group Click \u0026ldquo;Add user to groups\u0026rdquo; Bước 6: Tạo Regular User Trở về Users list Click \u0026ldquo;Create user\u0026rdquo; Username: user-test Email address: user@test.com Temporary password: TempUserPass123! Mark email as verified: ✅ Check Click \u0026ldquo;Create user\u0026rdquo; Gán vào users group (tương tự bước 5) Phần 6: Set Permanent Passwords (Optional) Nếu bạn muốn users có thể đăng nhập ngay mà không cần đổi temporary password:\nTừ Users list Click vào user (e.g., admin-test) Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Set password\u0026rdquo; Permanent password: AdminPass123! Make this permanent password: ✅ Check Click \u0026ldquo;Set password\u0026rdquo; Phần 7: Cấu hình App Client Thêm (Authentication Methods) Bước 1: Cấu hình App Client Details Từ User Pool → App integration → App clients Click vào smoking-cessation-frontend Scroll down → \u0026ldquo;Client secret\u0026rdquo; ⚠️ Lưu ý: Nếu bạn tạo Client Secret, frontend JavaScript không thể sử dụng được (vì không thể lưu secret an toàn trên client) Khuyến cáo: Không tạo Client Secret cho public frontend Leave \u0026ldquo;Client secret\u0026rdquo; as-is (không tạo) Phần 8: Enable Cognito Hosted UI (Optional) Bước 1: Cấu hình Hosted UI Domain Từ User Pool → App integration → Domain name If already configured → Skip If not → Click \u0026ldquo;Create domain\u0026rdquo; Domain prefix: smoking-cessation-dev Click \u0026ldquo;Create domain\u0026rdquo; ⏳ Chờ 1-2 phút để domain được tạo\nBước 2: Test Hosted UI Từ App integration → App clients Click vào smoking-cessation-frontend Scroll xuống \u0026ldquo;Hosted UI settings\u0026rdquo; Tìm Hosted UI domain URL: Format: https://smoking-cessation-dev.auth.us-east-1.amazoncognito.com Click link để open Hosted UI Login test: Username: admin-test Password: AdminPass123! Should redirect to http://localhost:3000/callback (or configured callback URL) Phần 9: Thông Tin Tóm Tắt Lưu lại những thông tin này vào .env file:\n# Cognito Configuration COGNITO_REGION=us-east-1 COGNITO_USER_POOL_ID=us-east-1_dskUsnKt3 COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 COGNITO_DOMAIN=smoking-cessation-dev COGNITO_HOSTED_UI_DOMAIN=https://smoking-cessation-dev.auth.us-east-1.amazoncognito.com # Test User Credentials (để remove trước production) TEST_ADMIN_USER=admin-test TEST_ADMIN_PASSWORD=AdminPass123! TEST_COACH_USER=coach-test TEST_COACH_PASSWORD=TempCoachPass123! TEST_USER=user-test TEST_USER_PASSWORD=TempUserPass123! Phần 10: Troubleshooting \u0026ldquo;Email already exists\u0026rdquo; Vấn đề: Tạo user nhưng email đã tồn tại\nGiải pháp:\nTừ Users list Tìm user với email đó Delete nó (nếu test user) Tạo user mới với email khác \u0026ldquo;Temporary password doesn\u0026rsquo;t meet requirements\u0026rdquo; Vấn đề: Password không đủ requirements\nGiải pháp:\nPassword phải: Minimum 12 characters Có uppercase (A-Z) Có lowercase (a-z) Có number (0-9) Có special character (!@#$%^\u0026amp;*) Ví dụ hợp lệ: TempPass123!, AdminTest456! \u0026ldquo;Hosted UI domain not available\u0026rdquo; Vấn đề: Domain đã bị dùng\nGiải pháp:\nThêm số vào suffix: smoking-cessation-dev-2 Hoặc dùng tên khác Checklist User Pool \u0026ldquo;smoking-cessation-users\u0026rdquo; tạo thành công App Client \u0026ldquo;smoking-cessation-frontend\u0026rdquo; tạo thành công 3 User Groups created (admins, coaches, users) 3 test users created \u0026amp; assigned to groups Permanent passwords set for test users Hosted UI domain configured Login test successful with admin-test user .env file updated với Cognito credentials Sẵn sàng cho Module 4 (Setup Lambda) Kết Quả Đạt Được Sau Module 3, bạn sẽ có:\n✅ Cognito User Pool hoạt động đầy đủ ✅ App Client để frontend connect ✅ User Groups (admins, coaches, users) cho role-based access control ✅ Test users để verify authentication flow ✅ Hosted UI domain có thể dùng cho login/signup ✅ Credentials được lưu để dùng trong modules tiếp theo "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/","title":"Blogs","tags":[],"description":"","content":"Blog 1 – Truy cập Amazon Q Developer an toàn bằng PingIdentity Blog này giải thích cách các tổ chức có thể tích hợp PingIdentity với AWS IAM Identity Center để cung cấp cơ chế xác thực SAML an toàn cho Amazon Q Developer.\nBài viết hướng dẫn chi tiết cách cấu hình PingIdentity làm nhà cung cấp danh tính (IdP), kích hoạt AWS SSO, trao đổi metadata, thiết lập SCIM provisioning để đồng bộ người dùng và nhóm, và gán quyền truy cập Amazon Q Developer Pro.\nNgoài ra, blog cũng mô tả quy trình đăng nhập trong IDE bằng thông tin đăng nhập PingIdentity, giúp lập trình viên truy cập Amazon Q Developer một cách liền mạch mà không cần tài khoản AWS riêng biệt.\nBlog 2 – Xây dựng Trợ lý Ảo Ngành Năng lượng với Amazon Bedrock, Amazon Connect và Amazon Lex Blog này giới thiệu cách xây dựng Energy Virtual Assistant hỗ trợ khách hàng giao tiếp bằng ngôn ngữ tự nhiên thông qua Amazon Connect, Amazon Lex và Amazon Bedrock Agents.\nGiải pháp cho phép tự động hóa các tác vụ phổ biến trong ngành tiện ích — như báo cáo mất điện, tra cứu hóa đơn, cập nhật thông tin tài khoản và phân tích mức tiêu thụ điện — bằng cách tích hợp Lex, Bedrock Agent, DynamoDB, Timestream và các hệ thống backend mô phỏng.\nBài viết cung cấp hướng dẫn từng bước triển khai CloudFormation, cấu hình intent trong Lex, liên kết số điện thoại Amazon Connect, và kiểm thử toàn bộ luồng hội thoại.\nGiải pháp minh hoạ cách generative AI có thể hiện đại hóa trung tâm hỗ trợ khách hàng bằng khả năng tự động hóa thông minh và phản hồi theo ngữ cảnh.\nBlog 3 – Xây dựng pipeline streaming serverless bảo mật với Amazon MSK Serverless và Amazon EMR Serverless Blog này trình bày cách xây dựng pipeline streaming serverless hoàn chỉnh, sử dụng Amazon MSK Serverless để thu nhận dữ liệu Kafka và Amazon EMR Serverless để xử lý dữ liệu bằng Spark Structured Streaming theo thời gian gần thực.\nBài viết giải thích cách IAM authentication thay thế cơ chế quản lý chứng chỉ TLS truyền thống, cho phép Spark kết nối bảo mật với MSK mà không cần keystore hay secret.\nNội dung bao gồm triển khai CloudFormation, tạo Kafka topic, tạo dữ liệu streaming từ EC2, cấu hình Spark với IAM authentication, ghi dữ liệu xử lý vào Amazon S3, tạo bảng Glue Data Catalog, và truy vấn kết quả bằng Amazon Athena.\nGiải pháp chứng minh cách doanh nghiệp có thể đơn giản hóa kiến trúc streaming, tăng cường bảo mật và mở rộng quy mô mà không cần quản lý máy chủ hay cluster.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 3 Duy trì sự tương tác với các hoạt động của First Cloud Journey và trao đổi cùng các thành viên. Củng cố kiến thức nền tảng về các dịch vụ AWS; thực hành thao tác với cả AWS Console và AWS CLI. Hoàn thành các bài lab thực hành liên quan đến Amazon S3 và Amazon RDS; bước đầu tìm hiểu GenAI thông qua Amazon Bedrock. Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference 2 - Tìm hiểu tổng quan AWS Cloud9 (môi trường này không khả dụng trong setup hiện tại).\n- Tiếp tục đọc tài liệu và chuẩn bị trước các bước lab cho Amazon S3 và Amazon RDS. 16/09/2025 16/09/2025 https://000057.awsstudygroup.com/vi/1-introduce/ 3 - Hoàn thành bài thực hành S3:\n+ Lưu trữ và upload dữ liệu\n+ Quản lý và tổ chức các đối tượng\n+ Thiết lập quyền truy cập và cấu hình bảo mật cơ bản 17/09/2025 17/09/2025 https://us-east-1.console.aws.amazon.com/s3/bucket/create 4 - Tham gia sự kiện Cloud Day Vietnam và ghi nhận những kiến thức liên quan đến ứng dụng AI trong tự động hóa và tối ưu hoạt động doanh nghiệp. 18/09/2025 18/09/2025 — 5 - Thực hiện cấu hình RDS, phát sinh nhiều lỗi trong quá trình setup.\n- Tra cứu tài liệu, đọc hướng dẫn và phác thảo bảng dữ liệu cần sử dụng trong bài lab. 19/09/2025 19/09/2025 https://us-east-1.console.aws.amazon.com/rds/home 6 - Thực hành RDS:\n+ Khắc phục các lỗi gặp phải\n+ Tạo lại bảng dữ liệu và kiểm tra kết nối\n+ Hoàn tất toàn bộ bài lab RDS 20/09/2025 20/09/2025 https://us-east-1.console.aws.amazon.com/rds/home Kết quả đạt được trong tuần Duy trì thói quen học tập đều đặn và hoàn thành các bài lab theo kế hoạch. Thành thạo hơn trong việc tìm kiếm dịch vụ và thao tác trên AWS Management Console. Hoàn tất các bài lab S3 và RDS, đồng thời ghi chép lại quy trình xử lý lỗi để sử dụng trong các tuần sau. Tìm hiểu Amazon Bedrock và cách gọi API của các foundation model; nhận thấy tầm quan trọng của chất lượng dữ liệu đối với kết quả GenAI. Tự tin hơn khi chuyển đổi giữa Console và CLI trong các tác vụ hàng ngày. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/","title":"Các sự kiện đã tham gia","tags":[],"description":"","content":"Sự kiện 1 Tên sự kiện: AWS Cloud Day Vietnam - AI Edition 2025\nNgày: 18 tháng 9, 2025\nĐịa điểm: Số 2 đường Hải Triều, Phường Bến Nghé, Quận 1, TP. Hồ Chí Minh\nTổng quan Sự kiện và Hoạt động chính Sự kiện AWS Cloud Day Vietnam - AI Edition 2025 đóng vai trò là một diễn đàn then chốt nhằm thúc đẩy quá trình chuyển đổi số của Việt Nam, khai thác sức mạnh của Điện toán đám mây và Trí tuệ nhân tạo. Sự kiện đã khám phá bốn chủ đề cốt lõi:\nPhổ cập AI Tạo sinh cho Doanh nghiệp. Thu hẹp khoảng cách giữa Kinh doanh và CNTT trong lĩnh vực Tài chính. Thúc đẩy Hiện đại hóa theo ngành. Tăng cường các Khuôn khổ Bảo mật. Các hoạt động trong ngày bao gồm các phiên họp toàn thể cấp cao với sự tham gia của các quan chức chính phủ và lãnh đạo ngành, sau đó là các chuyên đề kỹ thuật chuyên sâu tập trung vào Chiến lược Dữ liệu, DevOps, và Lộ trình Di chuyển lên Đám mây.\nBài học Chính và Kết quả Hiểu biết Chiến lược: Có được sự hiểu biết sâu sắc hơn về sự tương tác quan trọng giữa AI Tạo sinh và một chiến lược dữ liệu vững chắc, được xác định là động lực chính cho sự thành công trong các doanh nghiệp hiện đại. Tư duy \u0026ldquo;Di chuyển để Vận hành\u0026rdquo;: Phát triển sự đánh giá cao đối với khuôn khổ \u0026ldquo;Migrate to Operate\u0026rdquo;, nhấn mạnh việc sử dụng AI để tinh giản hoạt động và tối ưu hóa chi phí sau khi di chuyển lên đám mây. Kiến thức Kỹ thuật: Thu được những hiểu biết sâu sắc về việc tích hợp AI Tạo sinh trong vòng đời DevOps, đặc biệt là trong việc tự động hóa tạo mã và kiểm thử. Đổi mới về Bảo mật: Tìm hiểu về phương pháp \u0026ldquo;Bảo mật ngay từ thiết kế\u0026rdquo; (Security by Design), tập trung vào việc nhúng các biện pháp bảo mật trong suốt vòng đời ứng dụng thay vì chỉ dựa vào các biện pháp phòng thủ ở vành đai. Sự kiện này đã cung cấp kiến thức vô giá và những bài học thực tế, nâng cao hơn nữa sự hiểu biết của tôi về sự giao thoa giữa AI, điện toán đám mây và bảo mật trong bối cảnh các giải pháp doanh nghiệp hiện đại.\nSự kiện 2 Tên sự kiện: Khám Phá Agentic AI – Workshop Amazon QuickSuite\nNgày: 7 tháng 11, 2025\nĐịa điểm: Văn phòng AWS Việt Nam, Tháp Tài chính Bitexco, Quận 1, TP. Hồ Chí Minh\nTổng quan Sự kiện và Hoạt động chính Workshop \u0026ldquo;Khám Phá Agentic AI – Amazon QuickSuite\u0026rdquo;, được tổ chức với sự hợp tác của Cloud Kinetics, là một phiên kỹ thuật chiến lược đánh dấu sự phát triển từ AI Tạo sinh thụ động sang AI Tác tử tự chủ. Sự kiện nổi bật với buổi trình diễn trực tiếp đầu tiên của Amazon QuickSuite tại Việt Nam. Workshop tập trung vào bốn trụ cột chính:\nĐịnh nghĩa mô hình \u0026ldquo;Agentic\u0026rdquo;: Tự chủ, Suy luận và Thực thi. Tích hợp Dữ liệu và AI thông qua hệ sinh thái Amazon QuickSuite. Thực hành xây dựng các khái niệm AI với các chuyên gia kỹ thuật của AWS. Hỗ trợ tài chính cho đổi mới thông qua Chương trình AWS LIFT. Chương trình nghị sự kết hợp các phiên kiến trúc lý thuyết với các workshop thực hành sử dụng Amazon QuickSight và Quick Suite Q, cho phép người tham dự xây dựng các khái niệm AI chức năng trong thời gian thực.\nBài học Chính và Kết quả Thay đổi Mô hình: Hiểu rõ sự chuyển đổi từ AI Tạo sinh (tạo nội dung) sang AI Tác tử (thực thi tác vụ tự chủ), nơi các hệ thống có thể nhận thức môi trường và hành động độc lập để giải quyết các vấn đề kinh doanh. Hệ sinh thái Hợp nhất: Có được những hiểu biết thực tế về Amazon QuickSuite, học cách tích hợp trí tuệ doanh nghiệp (QuickSight) với các khả năng tạo sinh để tạo ra các \u0026ldquo;Tác tử Phân tích\u0026rdquo; giúp tinh giản hoạt động. Linh hoạt trong Vận hành: Nhận ra giá trị chiến lược của khuôn khổ \u0026ldquo;Quick\u0026rdquo;, nhấn mạnh vào việc triển khai nhanh chóng và \u0026ldquo;Thời gian tạo ra Giá trị\u0026rdquo;, cho phép các doanh nghiệp triển khai các giải pháp AI phức tạp với tốc độ cao. Hỗ trợ Chiến lược: Tìm hiểu về Chương trình AWS LIFT (cung cấp tín dụng lên tới 80.000 USD), xác định đây là một cơ chế quan trọng để giảm thiểu rủi ro cho R\u0026amp;D và thúc đẩy việc áp dụng tính toán hiệu năng cao. Workshop này đã cung cấp một lộ trình cụ thể để xây dựng các hệ thống doanh nghiệp tự chủ, kết hợp kiến thức lý thuyết với kỹ năng kỹ thuật thực hành và các hiểu biết tài chính chiến lược để thúc đẩy chuyển đổi số.\nSự kiện 3 Tên sự kiện: AWS Cloud Mastery Series #3 - Chuyên sâu về Trụ cột Bảo mật\nNgày: 1 tháng 12, 2025\nĐịa điểm: Trực tuyến\nTổng quan Sự kiện và Hoạt động chính Workshop chuyên sâu này tập trung vào Trụ cột Bảo mật của Khuôn khổ AWS Well-Architected. Buổi học cung cấp một phương pháp có cấu trúc để đánh giá và bảo mật các khối lượng công việc trên đám mây, bao gồm các lĩnh vực chính như:\nCác phương pháp hay nhất về Quản lý Danh tính và Truy cập (IAM). Các kỹ thuật bảo vệ dữ liệu để mã hóa dữ liệu khi lưu trữ và khi truyền. Các biện pháp kiểm soát phát hiện sử dụng AWS Config, CloudTrail và Security Hub. Bảo vệ cơ sở hạ tầng và phản ứng sự cố tự động. Bài học Chính và Kết quả Mô hình Trách nhiệm Chung: Hiểu rõ về sự phân chia trách nhiệm bảo mật giữa AWS và khách hàng. Bảo mật theo lớp: Học cách áp dụng phương pháp bảo mật đa lớp để bảo vệ tài nguyên đám mây một cách toàn diện, từ rìa mạng đến dữ liệu cá nhân. Bảo mật Tự động: Hiểu được tầm quan trọng của việc tự động hóa các kiểm tra và khắc phục bảo mật để giảm thiểu lỗi của con người và cho phép phản ứng nhanh hơn với các mối đe dọa. Tình trạng Bảo mật Chủ động: Có được các kỹ năng sử dụng các công cụ của AWS để chủ động giám sát và cải thiện tình trạng bảo mật của môi trường đám mây. Sự kiện 4 Tên sự kiện: AWS Cloud Mastery Series #2 - DevOps trên AWS\nNgày: 17 tháng 11, 2025\nĐịa điểm: Tháp Tài chính Bitexco, Quận 1, TP. Hồ Chí Minh\nTổng quan Sự kiện và Hoạt động chính Buổi học chuyên sâu cả ngày này tập trung vào việc triển khai văn hóa và các phương pháp DevOps trên AWS. Workshop bao gồm toàn bộ vòng đời CI/CD, từ kiểm soát nguồn đến triển khai tự động, và khám phá các công nghệ hiện đại bao gồm:\nInfrastructure as Code (IaC) với AWS CloudFormation và CDK. Container hóa với Docker, ECR và ECS/EKS. Xây dựng các đường ống CI/CD tự động bằng bộ dịch vụ AWS Code. Triển khai khả năng quan sát với CloudWatch và AWS X-Ray để truy vết phân tán. Bài học Chính và Kết quả Tự động hóa Toàn diện: Nắm vững khái niệm xây dựng các đường ống phát hành phần mềm hoàn toàn tự động, giảm thiểu sự can thiệp thủ công và tăng tần suất triển khai. IaC là Tiêu chuẩn: Hiểu rằng việc quản lý cơ sở hạ tầng dưới dạng mã là điều cần thiết để có thể lặp lại, nhất quán và ngăn ngừa sự thay đổi cấu hình. Khả năng quan sát trong các Hệ thống Phân tán: Học cách sử dụng AWS X-Ray để truy vết các yêu cầu thông qua các microservice, cung cấp những hiểu biết quan trọng để gỡ lỗi và tối ưu hóa hiệu suất. Đo lường Thành công của DevOps: Có được kiến thức về các chỉ số DORA chính (Tần suất triển khai, MTTR, v.v.) để đo lường và cải thiện hiệu suất của nhóm. Sự kiện 5 Tên sự kiện: AWS Cloud Mastery Series #1 – AI/ML/GenAI trên AWS\nNgày: 15/11/2025\nĐịa điểm: Bitexco Financial Tower, Quận 1, TP. HCM\nTổng quan và hoạt động chính của sự kiện AWS Cloud Mastery Series #1 là workshop chuyên sâu tập trung vào AI/ML và Generative AI trên AWS, bao gồm:\nWelcome \u0026amp; networking Tổng quan thị trường AI/ML tại Việt Nam Chuyên sâu Amazon SageMaker (chuẩn bị dữ liệu, huấn luyện, MLOps, triển khai) Demo trực tiếp: SageMaker Studio Coffee break Generative AI với Amazon Bedrock (so sánh mô hình nền tảng, Prompt Engineering, RAG, Bedrock Agents, Guardrails) Demo trực tiếp: Xây dựng chatbot GenAI với Bedrock Những bài học và kết quả đạt được Hiểu rõ quy trình AI/ML end-to-end: Nắm được cách SageMaker vận hành toàn bộ vòng đời ML. Kỹ năng triển khai GenAI: Học các phương pháp RAG, Prompt Engineering và sử dụng Agents. Nắm vững MLOps: Tầm quan trọng của tự động hóa trong vòng đời mô hình. Bảo mật AI: Ý nghĩa của Bedrock Guardrails trong việc triển khai AI an toàn. Sự kiện 6 Tên sự kiện: CloudThinker – Xây dựng Agentic AI \u0026amp; Tối ưu hóa Ngữ cảnh với Amazon Bedrock\nThời gian: 9:00, ngày 05 tháng 12 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, 02 đường Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Tham dự seminar kỹ thuật do CloudThinker và AWS tổ chức, tập trung vào kiến trúc, mô hình phát triển và chiến lược tối ưu hóa cho hệ thống Agentic AI xây dựng trên Amazon Bedrock.\nBài học rút ra: Phiên chia sẻ nhấn mạnh sự phát triển của DevSecOps, cho thấy rằng các phương pháp hiện đại vượt xa phạm vi tự động hóa pipeline CI/CD. Bảo mật cần được tích hợp xuyên suốt vòng đời phát triển phần mềm, và AI—đặc biệt là các hệ thống agentic—đóng vai trò quan trọng trong phát hiện lỗ hổng sớm, tự động hóa kiểm thử và phản ứng nhanh với sự cố.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.4-event4/","title":"AWS Cloud Mastery Series #2 - DevOps trên AWS","tags":[],"description":"","content":"AWS Cloud Mastery Series #2 - DevOps trên AWS - Ngày: 17 tháng 11, 2025 (Cả ngày) - Địa điểm: Bitexco Financial Tower, Quận 1, TP. Hồ Chí Minh\nTổng quan Sự kiện Sự kiện chuyên sâu kéo dài cả ngày này tập trung vào việc áp dụng Văn hóa DevOps, các công cụ CI/CD (Tích hợp liên tục/Triển khai liên tục) của AWS, và các công nghệ hiện đại hóa như Infrastructure as Code (IaC) và Containerization.\nMục tiêu chính:\nPhát triển Tư duy DevOps: Hiểu rõ văn hóa, nguyên tắc và các chỉ số hiệu suất chính (DORA, MTTR, deployment frequency). Xây dựng CI/CD: Nắm vững cách sử dụng bộ dịch vụ AWS Code (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) để tự động hóa quy trình phát hành. Triển khai IaC: Thực hành triển khai và quản lý cơ sở hạ tầng bằng AWS CloudFormation và AWS CDK. Hiện đại hóa Ứng dụng: Tìm hiểu về containerization, lưu trữ (ECR), và quản lý orchestration (ECS/EKS). Cải thiện Observability: Thiết lập hệ thống giám sát toàn diện bằng CloudWatch và AWS X-Ray để truy vết phân tán. Bài học và Kiến thức cốt lõi (Key Takeaways) Văn hóa là Nền tảng: DevOps là sự kết hợp giữa văn hóa, nguyên tắc và công cụ; các chỉ số DORA là thước đo quan trọng cho sự thành công của đội ngũ. Tự động hóa Triệt để: Toàn bộ quá trình từ mã nguồn (CodeCommit) đến triển khai (CodePipeline/CodeDeploy) phải được tự động hóa, ưu tiên các chiến lược triển khai an toàn như Blue/Green và Canary. IaC là Bắt buộc: Quản lý cơ sở hạ tầng dưới dạng mã (IaC) giúp tăng khả năng lặp lại, giảm thiểu lỗi thủ công, và dễ dàng phát hiện độ lệch (drift detection) trong CloudFormation. Container cho Microservices: Sử dụng Docker cùng với các dịch vụ quản lý container của AWS (ECS, EKS, App Runner) là mô hình chuẩn để triển khai kiến trúc microservices. Tracing Phân tán: AWS X-Ray rất cần thiết để hiểu rõ hiệu suất và điểm nghẽn trong các hệ thống phân tán, bổ sung cho các metrics và logs truyền thống của CloudWatch. Ứng dụng vào Công việc (Application to Work) Đo lường DORA: Bắt đầu đo lường các chỉ số DORA (Tần suất triển khai, Thời gian quay vòng thay đổi, Thời gian phục hồi sự cố, Tỷ lệ lỗi thay đổi) cho các dự án hiện tại. Chuyển đổi Pipeline: Lựa chọn một quy trình triển khai thủ công hoặc bán tự động và chuyển đổi hoàn toàn sang AWS CodePipeline với các bước Build (CodeBuild) và Deployment (CodeDeploy) tự động. Thí điểm CDK: Bắt đầu thí điểm sử dụng AWS CDK để định nghĩa và triển khai một dịch vụ nhỏ, tận dụng các ngôn ngữ lập trình quen thuộc (ví dụ: Python/TypeScript). Tích hợp X-Ray: Áp dụng AWS X-Ray cho các microservices mới được phát triển để thu thập dữ liệu truy vết (tracing data) và phân tích hiệu suất giữa các thành phần. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-setup-lambda/","title":"5.4 Setup Lambda","tags":[],"description":"","content":"Module 4: Create Lambda Functions Mục tiêu Module Tạo 5 Lambda functions từ đầu Cấu hình IAM roles \u0026amp; permissions Thiết lập environment variables Cấu hình Cognito post-confirmation trigger Test Lambda functions Setup monitoring \u0026amp; alarms Duration: 4-5 giờ\nLambda Functions Overview Lambda functions sẽ xử lý các specific events:\nFunction Region Runtime Purpose Memory Timeout CognitoPostConfirmationTrigger us-east-1 nodejs20.x Create user profile khi user signup 256 MB 30s AdminManageCoachesFunction ap-southeast-1 nodejs20.x Manage coaches (CRUD operations) 512 MB 30s image-upload-lambda ap-southeast-1 nodejs20.x Handle image uploads to S3 256 MB 60s leaflungs-websocket-authorizer ap-southeast-1 nodejs20.x Authorize WebSocket connections 256 MB 30s PaymentFunction ap-southeast-1 nodejs24.x Process payments 512 MB 60s Phần 1: Create IAM Role for Lambda Functions Bước 1: Truy cập IAM Console Login vào AWS Console bằng IAM user Tìm kiếm \u0026ldquo;IAM\u0026rdquo; Click \u0026ldquo;IAM\u0026rdquo; từ services list Left menu: Click \u0026ldquo;Roles\u0026rdquo; Click \u0026ldquo;Create role\u0026rdquo; Bước 2: Configure Trust Relationship Trusted entity type: Select \u0026ldquo;AWS service\u0026rdquo; Service or use case: Search và click \u0026ldquo;Lambda\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Bước 3: Add Permissions Search và check policies: ✅ AWSLambdaVPCAccessExecutionRole (for EC2 database access) ✅ AWSLambdaBasicExecutionRole (for CloudWatch logs) ✅ AmazonS3FullAccess (for image upload function) ✅ SecretsManagerReadSecret (for database credentials) Click \u0026ldquo;Next\u0026rdquo; Bước 4: Review \u0026amp; Create Role name: smoking-cessation-lambda-role Description: Lambda execution role for smoking cessation platform Click \u0026ldquo;Create role\u0026rdquo; ⏳ Chờ role được tạo\nBước 5: Note Role ARN Click vào role vừa tạo: smoking-cessation-lambda-role Copy Role ARN: Format là arn:aws:iam::014097726842:role/smoking-cessation-lambda-role Lưu lại để dùng trong modules tiếp theo Phần 2: Create Cognito Post-Confirmation Trigger (us-east-1) Bước 1: Truy cập Lambda Console Login vào AWS Console Tìm kiếm \u0026ldquo;Lambda\u0026rdquo; Click \u0026ldquo;Lambda\u0026rdquo; service Chọn region: us-east-1 (phải giống với Cognito) Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Function Basics Function name: smoking-cessation-cognito-post-confirmation Runtime: nodejs20.x Execution role: Select \u0026ldquo;Use an existing role\u0026rdquo; Existing role: smoking-cessation-lambda-role (từ Phần 1) Click \u0026ldquo;Create function\u0026rdquo; ⏳ Chờ function được tạo (khoảng 1-2 phút)\nBước 3: Configure General Settings Scroll xuống \u0026ldquo;General configuration\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Memory: 256 MB (default) Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Environment Variables Scroll xuống \u0026ldquo;Environment variables\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Add the following variables: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager later) PG_DATABASE = smoking_cessation PG_PORT = 5432 COGNITO_USER_POOL_ID = (get from Module 3) Click \u0026ldquo;Save\u0026rdquo; Bước 5: Add Placeholder Code Click \u0026ldquo;Code\u0026rdquo; tab In the code editor, replace everything with: exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Cognito post-confirmation event:\u0026#39;, JSON.stringify(event, null, 2)); try { const userId = event.request.userAttributes.sub; const email = event.request.userAttributes.email; const name = event.request.userAttributes.name; console.log(`Creating user profile for ${email}`); // TODO: Implement database connection to PostgreSQL // Create user record in users table // Initialize coaching session if needed return event; } catch (error) { console.error(\u0026#39;Error in post-confirmation:\u0026#39;, error); throw error; } }; Click \u0026ldquo;Deploy\u0026rdquo; Bước 6: Add Cognito Trigger (Later) Note: Sau khi deploy code, bạn sẽ cấu hình Cognito trigger ở Phần 8\nPhần 3: Create Admin Manage Coaches Function (ap-southeast-1) Bước 1: Switch to ap-southeast-1 Region Top left: Click region dropdown Select ap-southeast-1 Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Function Function name: smoking-cessation-admin-manage-coaches Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; ⏳ Chờ function được tạo\nBước 3: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;General configuration\u0026rdquo; Memory: 512 MB (for database operations) Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;Environment variables\u0026rdquo; Add: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager) PG_DATABASE = smoking_cessation API_REGION = ap-southeast-1 Click \u0026ldquo;Save\u0026rdquo; Bước 5: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Admin coaches request:\u0026#39;, JSON.stringify(event, null, 2)); try { const httpMethod = event.httpMethod; const path = event.path; const body = event.body ? JSON.parse(event.body) : {}; console.log(`${httpMethod} ${path}`); // TODO: Implement database operations // GET /admin/coaches - List all coaches // POST /admin/coaches - Create new coach // PUT /admin/coaches/{id} - Update coach // DELETE /admin/coaches/{id} - Delete coach // Include RBAC check (admin only) return { statusCode: 200, body: JSON.stringify({ message: \u0026#39;Coaches function placeholder\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPhần 4: Create Image Upload Lambda (ap-southeast-1) Bước 1: Create Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-image-upload Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;General configuration\u0026rdquo; Memory: 256 MB Timeout: 60 seconds (vì file upload có thể mất thời gian) Click \u0026ldquo;Save\u0026rdquo; Bước 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;Environment variables\u0026rdquo; Add: S3_BUCKET = smoking-cessation-images S3_REGION = ap-southeast-1 MAX_FILE_SIZE = 10485760 Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Image upload request:\u0026#39;, JSON.stringify(event, null, 2)); try { const userId = event.requestContext.authorizer.claims.sub; const fileBuffer = Buffer.from(event.body, \u0026#39;base64\u0026#39;); const fileName = event.headers[\u0026#39;x-filename\u0026#39;] || `image-${Date.now()}.jpg`; console.log(`Uploading ${fileName} for user ${userId}`); // TODO: Implement S3 upload // Validate file size (max 10MB) // Upload to S3 with user prefix // Generate pre-signed URL // Store reference in database const s3Url = `https://${process.env.S3_BUCKET}.s3.${process.env.S3_REGION}.amazonaws.com/${userId}/${fileName}`; return { statusCode: 200, body: JSON.stringify({ url: s3Url }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPhần 5: Create WebSocket Authorizer Lambda (ap-southeast-1) Bước 1: Create Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-websocket-authorizer Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;General configuration\u0026rdquo; Memory: 256 MB Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Bước 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;Environment variables\u0026rdquo; Add: COGNITO_USER_POOL_ID = (from Module 3) COGNITO_CLIENT_ID = (from Module 3) JWT_SECRET = (will be set via Secrets Manager) Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;WebSocket authorization event:\u0026#39;, JSON.stringify(event, null, 2)); try { const token = event.authorizationToken; if (!token) { throw new Error(\u0026#39;No authorization token\u0026#39;); } console.log(\u0026#39;Validating WebSocket token\u0026#39;); // TODO: Implement JWT token validation // Validate token signature // Check token expiration // Extract user ID from token // Placeholder authorization response return { principalId: \u0026#39;user-id-placeholder\u0026#39;, policyDocument: { Version: \u0026#39;2012-10-17\u0026#39;, Statement: [ { Action: \u0026#39;execute-api:Invoke\u0026#39;, Effect: \u0026#39;Allow\u0026#39;, Resource: event.methodArn } ] } }; } catch (error) { console.error(\u0026#39;Authorization failed:\u0026#39;, error); throw new Error(\u0026#39;Unauthorized\u0026#39;); } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPhần 6: Create Payment Function (ap-southeast-1) Bước 1: Create Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-payment Runtime: nodejs24.x (latest version) Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Bước 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;General configuration\u0026rdquo; Memory: 512 MB (payment processing needs resources) Timeout: 60 seconds Click \u0026ldquo;Save\u0026rdquo; Bước 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; ở \u0026ldquo;Environment variables\u0026rdquo; Add: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager) PG_DATABASE = smoking_cessation STRIPE_API_KEY = (will be set via Secrets Manager) STRIPE_WEBHOOK_SECRET = (will be set via Secrets Manager) PAYMENT_TABLE = payments Click \u0026ldquo;Save\u0026rdquo; Bước 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Payment event:\u0026#39;, JSON.stringify(event, null, 2)); try { const { userId, amount, paymentMethod, description } = JSON.parse(event.body); console.log(`Processing payment for user ${userId}: $${amount}`); // TODO: Implement payment processing // Validate amount // Process payment via Stripe/Payment gateway // Store payment record in database // Send confirmation email // Handle webhooks return { statusCode: 200, body: JSON.stringify({ success: true, transactionId: `txn-${Date.now()}`, message: \u0026#39;Payment processed successfully\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Payment error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo;\nPhần 7: Create Secrets Manager for Database Credentials Bước 1: Truy cập Secrets Manager Tìm kiếm \u0026ldquo;Secrets Manager\u0026rdquo; Click service Click \u0026ldquo;Store a new secret\u0026rdquo; Bước 2: Store Database Password Secret type: \u0026ldquo;Other type of secret\u0026rdquo; Key/value pairs: Key: db-password Value: \u0026lt;your-postgres-password\u0026gt; Click \u0026ldquo;Next\u0026rdquo; Secret name: smoking-cessation/db-password Click \u0026ldquo;Store secret\u0026rdquo; Bước 3: Store Payment Credentials (Optional) Click \u0026ldquo;Store a new secret\u0026rdquo; Secret type: \u0026ldquo;Other type of secret\u0026rdquo; Key/value pairs: Key: stripe-api-key Value: \u0026lt;your-stripe-key\u0026gt; Secret name: smoking-cessation/stripe-api-key Click \u0026ldquo;Store secret\u0026rdquo; Bước 4: Update Lambda IAM Role Lambda needs permission to read secrets:\nGo to IAM console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Select \u0026ldquo;JSON\u0026rdquo; tab Paste: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:secretsmanager:*:*:secret:smoking-cessation/*\u0026#34; ] } ] } Click \u0026ldquo;Review policy\u0026rdquo; Policy name: lambda-secrets-access Click \u0026ldquo;Create policy\u0026rdquo; Phần 8: Configure Cognito Post-Confirmation Trigger Bước 1: Go to Cognito User Pool Switch region to us-east-1 Tìm kiếm \u0026ldquo;Cognito\u0026rdquo; Click Cognito service Click \u0026ldquo;User pools\u0026rdquo; Click vào user pool: smoking-cessation-users (tạo ở Module 3) Bước 2: Add Lambda Trigger Left menu: Click \u0026ldquo;User lifecycle\u0026rdquo; Click \u0026ldquo;Post confirmation\u0026rdquo; Click \u0026ldquo;Add Lambda trigger\u0026rdquo; Lambda function: smoking-cessation-cognito-post-confirmation Click \u0026ldquo;Save\u0026rdquo; Bước 3: Verify Trigger Refresh page Verify trigger shows: Trigger: Post confirmation Function: smoking-cessation-cognito-post-confirmation (us-east-1) Status: Active Phần 9: Grant Cognito Permission to Invoke Lambda Cognito cần permission để gọi Lambda function:\nBước 1: Add Resource-Based Policy Switch to us-east-1 region Go to Lambda console Click function: smoking-cessation-cognito-post-confirmation Scroll xuống \u0026ldquo;Resource-based policy statements\u0026rdquo; Click \u0026ldquo;Add permissions\u0026rdquo; Statement ID: AllowCognitoInvoke Principal: cognito-idp.amazonaws.com Action: lambda:InvokeFunction Source account: Source ARN: arn:aws:cognito-idp:us-east-1:\u0026lt;account-id\u0026gt;:userpool/\u0026lt;user-pool-id\u0026gt; Click \u0026ldquo;Save\u0026rdquo; Phần 10: Test Lambda Functions Bước 1: Test Cognito Post-Confirmation Trigger Go to Lambda console (us-east-1) Click function: smoking-cessation-cognito-post-confirmation Click \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;userAttributes\u0026#34;: { \u0026#34;sub\u0026#34;: \u0026#34;12345678-1234-1234-1234-123456789012\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Test User\u0026#34; } }, \u0026#34;response\u0026#34;: {} } Click \u0026ldquo;Test\u0026rdquo; Verify: ✅ Execution result: Succeeded ✅ CloudWatch logs show console.log output Bước 2: Test Admin Coaches Function Switch to ap-southeast-1 Click function: smoking-cessation-admin-manage-coaches Click \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;httpMethod\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/admin/coaches\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;Authorization\u0026#34;: \u0026#34;Bearer test-token\u0026#34; }, \u0026#34;body\u0026#34;: null } Click \u0026ldquo;Test\u0026rdquo; Verify status code 200 in response Bước 3: Test Image Upload Function Click function: smoking-cessation-image-upload Click \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;httpMethod\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/upload\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;x-filename\u0026#34;: \u0026#34;test-image.jpg\u0026#34; }, \u0026#34;body\u0026#34;: \u0026#34;base64-encoded-image-data\u0026#34;, \u0026#34;requestContext\u0026#34;: { \u0026#34;authorizer\u0026#34;: { \u0026#34;claims\u0026#34;: { \u0026#34;sub\u0026#34;: \u0026#34;user-123\u0026#34; } } } } Click \u0026ldquo;Test\u0026rdquo; Verify response contains S3 URL Bước 4: View CloudWatch Logs Click \u0026ldquo;Monitor\u0026rdquo; tab của bất kỳ function nào Click \u0026ldquo;View logs in CloudWatch\u0026rdquo; Select most recent log stream Verify logs show: Input event Console.log statements Execution time Phần 11: Create CloudWatch Alarms Bước 1: Create Error Alarm Tìm kiếm \u0026ldquo;CloudWatch\u0026rdquo; Click \u0026ldquo;CloudWatch\u0026rdquo; service Left menu: \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;All alarms\u0026rdquo; Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Select Lambda Dimension: Function name Statistic: Sum Function: smoking-cessation-admin-manage-coaches Metric: Errors Threshold: \u0026gt; 5 in 1 minute Click \u0026ldquo;Next\u0026rdquo; Action: Create SNS topic Topic name: smoking-cessation-lambda-errors Email endpoint: your-email@example.com Click \u0026ldquo;Create alarm\u0026rdquo; Check email để verify SNS subscription Bước 2: Create Duration Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Select Lambda → Durations Function: smoking-cessation-admin-manage-coaches Statistic: Average Threshold: \u0026gt; 20 seconds (warning if approaching 30s timeout) Click \u0026ldquo;Next\u0026rdquo; Action: Use existing SNS topic smoking-cessation-lambda-errors Click \u0026ldquo;Create alarm\u0026rdquo; Bước 3: Create Throttle Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Lambda → Throttles Function: All functions Threshold: \u0026gt; 0 Click \u0026ldquo;Next\u0026rdquo; Action: Notify via SNS Click \u0026ldquo;Create alarm\u0026rdquo; Phần 12: Enable X-Ray Tracing (Optional) Bước 1: Update IAM Role Go to IAM console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Attach policies directly\u0026rdquo; Search: AWSXRayWriteAccess Check ✅ Click \u0026ldquo;Attach policies\u0026rdquo; Bước 2: Enable X-Ray on Functions For each Lambda function:\nClick function Click \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;Monitoring and operations tools\u0026rdquo; Under \u0026ldquo;X-Ray\u0026rdquo;: Check ✅ \u0026ldquo;Active tracing\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Environment Variables Summary Cognito Post-Confirmation Function (us-east-1) PG_HOST=172.0.8.55 PG_USER=postgres PG_PASSWORD=(from Secrets Manager) PG_DATABASE=smoking_cessation PG_PORT=5432 COGNITO_USER_POOL_ID=(from Module 3) Admin Coaches \u0026amp; Payment Functions (ap-southeast-1) PG_HOST=172.0.8.55 PG_USER=postgres PG_PASSWORD=(from Secrets Manager) PG_DATABASE=smoking_cessation API_REGION=ap-southeast-1 STRIPE_API_KEY=(from Secrets Manager) STRIPE_WEBHOOK_SECRET=(from Secrets Manager) Image Upload Function (ap-southeast-1) S3_BUCKET=smoking-cessation-images S3_REGION=ap-southeast-1 MAX_FILE_SIZE=10485760 WebSocket Authorizer (ap-southeast-1) COGNITO_USER_POOL_ID=(from Module 3) COGNITO_CLIENT_ID=(from Module 3) JWT_SECRET=(from Secrets Manager) Checklist IAM role smoking-cessation-lambda-role created Cognito Post-Confirmation function created (us-east-1) Admin Coaches function created (ap-southeast-1) Image Upload function created (ap-southeast-1) WebSocket Authorizer function created (ap-southeast-1) Payment function created (ap-southeast-1) All functions have correct runtime \u0026amp; memory Environment variables configured for all functions Secrets Manager setup (db-password, stripe-api-key) Cognito trigger configured (post-confirmation) Lambda resource-based policy added for Cognito All functions tested successfully CloudWatch alarms created (errors, duration, throttles) X-Ray tracing enabled (optional) CloudWatch logs reviewed Sẵn sàng cho Module 5 (Setup API Gateway) Troubleshooting Function Execution Failed Issue: \u0026ldquo;An error occurred while getting the logs from CloudWatch\u0026rdquo;\nSolution:\nCheck IAM role has AWSLambdaBasicExecutionRole Wait 1-2 minutes for logs to appear Check function code for syntax errors Cognito Trigger Not Working Issue: \u0026ldquo;User created but Lambda function didn\u0026rsquo;t execute\u0026rdquo;\nSolution:\nVerify trigger is enabled in Cognito console Check Lambda resource-based policy exists Review CloudWatch logs for errors Check IAM role permissions Timeout Errors Issue: \u0026ldquo;Task timed out after 30 seconds\u0026rdquo;\nSolution:\nIncrease timeout to 60 seconds Check database connectivity (VPC configuration in Module 8) Add console logs to identify slow operations Consider increasing memory (also increases CPU) Permission Denied Issue: \u0026ldquo;User is not authorized to perform: secretsmanager:GetSecretValue\u0026rdquo;\nSolution:\nAdd secrets manager policy to Lambda role Verify policy resource ARN matches secret name Check secret exists in correct region Cold Start Issues Issue: \u0026ldquo;High duration on first invocation\u0026rdquo;\nSolution:\nIncrease memory allocation (256 → 512 MB) Consider provisioned concurrency for frequently used functions Optimize code dependencies Next Steps Implement actual code for each Lambda function (provided separately) Setup database connections to EC2 instances (Module 6) Create API Gateway routes (Module 5) Test end-to-end flow Optimize based on CloudWatch metrics Kết Quả Đạt Được Sau Module 4, bạn sẽ có:\n✅ 5 Lambda functions created và deployed ✅ IAM role với appropriate permissions ✅ Environment variables configured ✅ Secrets Manager setup cho sensitive data ✅ Cognito post-confirmation trigger configured ✅ Resource-based policies for Cognito invocation ✅ CloudWatch alarms setup ✅ X-Ray tracing enabled (optional) ✅ All functions tested và verified ✅ Sẵn sàng cho Module 5 (Create API Gateway) "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.5-event5/","title":"AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS","tags":[],"description":"","content":"AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS - Ngày: Thứ Bảy, 15/11/2025\n- Thời gian: 8:00 AM – 11:30 AM\n- Địa điểm: Bitexco Financial Tower, Quận 1, TP. Hồ Chí Minh\n- Trạng thái: Past Event (Sự kiện đã kết thúc)\nTổng quan sự kiện AWS Cloud Mastery Series #1 là chương trình chuyên sâu dành cho những người quan tâm đến AI/ML và Generative AI trên AWS, tập trung vào các công cụ, dịch vụ và phương pháp triển khai thực tế.\nSự kiện giúp người tham dự nắm rõ hệ sinh thái AI/ML của AWS, cũng như cách ứng dụng GenAI để xây dựng các giải pháp hiện đại trong doanh nghiệp.\nNội dung chính của sự kiện gồm:\n1. Welcome \u0026amp; Introduction (8:30 – 9:00 AM) Check-in \u0026amp; networking Giới thiệu chương trình và mục tiêu học tập Hoạt động ice-breaker Tổng quan thị trường AI/ML tại Việt Nam 2. AWS AI/ML Services Overview (9:00 – 10:30 AM) Amazon SageMaker – Nền tảng ML end-to-end:\nChuẩn bị \u0026amp; gán nhãn dữ liệu Huấn luyện, tối ưu \u0026amp; triển khai mô hình MLOps: CI/CD cho ML, monitoring, lineage tracking Live Demo: Hướng dẫn sử dụng SageMaker Studio 3. Coffee Break (10:30 – 10:45 AM) 4. Generative AI with Amazon Bedrock (10:45 AM – 12:00 PM) Các nội dung chuyên sâu:\nFoundation Models: Claude, Llama, Titan — so sánh \u0026amp; hướng dẫn chọn mô hình Prompt Engineering: phương pháp, CoT, Few-shot learning RAG (Retrieval-Augmented Generation): kiến trúc, vector store \u0026amp; knowledge base Bedrock Agents: workflow nhiều bước \u0026amp; tích hợp công cụ Guardrails: bảo vệ, kiểm soát nội dung \u0026amp; an toàn AI Live Demo: Xây dựng chatbot Generative AI với Bedrock 5. 12:00 PM – Lunch Break (Tự túc) Key Takeaways \u0026amp; Learnings Sự kết hợp giữa SageMaker và Bedrock là nền tảng mạnh mẽ để triển khai end-to-end AI/ML + GenAI. MLOps là bước then chốt để đưa mô hình vào vận hành thực tế. RAG giúp mô hình GenAI sử dụng kiến thức riêng của doanh nghiệp một cách an toàn và hiệu quả. Prompt Engineering quyết định chất lượng output của mô hình GenAI. Bedrock Agents cho phép tự động hóa các workflow AI phức tạp. Ứng dụng vào công việc Tối ưu workflow AI nội bộ: Áp dụng SageMaker vào pipeline training/deployment mô hình hiện có. Triển khai GenAI Assistant: Xây dựng chatbot nội bộ dựa trên Bedrock + RAG để hỗ trợ tài liệu, quy trình. Áp dụng MLOps: Tự động hóa việc đánh giá mô hình, tracking lineage \u0026amp; monitoring. Tăng tốc phát triển: Sử dụng Prompt Engineering chuẩn để cải thiện chất lượng kết quả AI. Nâng cao bảo mật AI: Tích hợp Bedrock Guardrails nhằm giới hạn nội dung và tăng an toàn. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-setup-api-gateway/","title":"5.5 Setup API Gateway","tags":[],"description":"","content":"Module 5: Create API Gateway REST APIs Mục tiêu Module Tạo 2 REST APIs từ đầu Tạo resources \u0026amp; methods Integrate với Lambda functions Cấu hình authentication \u0026amp; authorization Setup CORS \u0026amp; rate limiting Deploy \u0026amp; test APIs Duration: 3-4 giờ\nAPI Gateway Overview 2 REST APIs sẽ được tạo:\nAPI Name Region Purpose Resources Methods smoking-cessation-user-api ap-southeast-1 User management, Admin operations /admin/coaches, /api/user-info, /upload GET, POST, PUT, DELETE smoking-cessation-chat-api ap-southeast-1 Chat \u0026amp; WebSocket /chat/rooms, /chat/messages, /ws GET, POST, WebSocket Phần 1: Create First REST API (User Management) Bước 1: Truy cập API Gateway Console Login vào AWS Console Tìm kiếm \u0026ldquo;API Gateway\u0026rdquo; Click \u0026ldquo;API Gateway\u0026rdquo; service Chọn region: ap-southeast-1 Click \u0026ldquo;Create API\u0026rdquo; Bước 2: Choose API Type Chọn \u0026ldquo;REST API\u0026rdquo; Click \u0026ldquo;Build\u0026rdquo; Bước 3: Configure API Details API name: smoking-cessation-user-api Description: REST API for user management and admin operations Endpoint type: Regional Click \u0026ldquo;Create API\u0026rdquo; ⏳ Chờ API được tạo (khoảng 1-2 phút)\nBước 4: View API Dashboard Sau khi API tạo xong, bạn sẽ thấy:\nResources tree (currently only \u0026ldquo;/\u0026rdquo; root) Methods available for root Integration settings Phần 2: Create /admin Resource \u0026amp; /admin/coaches Sub-resource Bước 1: Create /admin Resource Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: admin Resource path: /admin ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 2: Create /admin/coaches Sub-resource Click vào /admin resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: coaches Resource path: coaches (automatically becomes /admin/coaches) ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 3: Create GET Method for /admin/coaches Click vào /admin/coaches resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;GET\u0026rdquo; Click checkmark to confirm Bước 4: Configure GET Method Integration Integration type: Lambda Function Lambda Region: ap-southeast-1 Lambda Function: smoking-cessation-admin-manage-coaches ✅ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Confirm the permission popup Bước 5: Create POST Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;POST\u0026rdquo; Same integration as GET: Integration type: Lambda Function Lambda Function: smoking-cessation-admin-manage-coaches ✅ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Bước 6: Create PUT Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;PUT\u0026rdquo; Same Lambda integration Click \u0026ldquo;Save\u0026rdquo; Bước 7: Create DELETE Method for /admin/coaches Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;DELETE\u0026rdquo; Same Lambda integration Click \u0026ldquo;Save\u0026rdquo; Result: /admin/coaches now has GET, POST, PUT, DELETE methods\nPhần 3: Create /api/user-info Resource \u0026amp; Sub-resources Bước 1: Create /api Resource Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: api Resource path: /api ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 2: Create /api/user-info Resource Click vào /api resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: user-info Resource path: user-info ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 3: Create Methods for /api/user-info Create GET, POST, PUT, DELETE methods (same as /admin/coaches):\nFor each method: Click \u0026ldquo;Create Method\u0026rdquo; Select method type Integration: smoking-cessation-admin-manage-coaches Lambda ✅ Lambda Proxy integration Save Bước 4: Create /{id} Resource (Path Parameter) Click vào /api/user-info Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: {id} Resource path: {id} Click \u0026ldquo;Create Resource\u0026rdquo; Bước 5: Create GET Method for /api/user-info/{id} Click vào /{id} resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;GET\u0026rdquo; Integration: smoking-cessation-admin-manage-coaches Lambda Save Bước 6: Create /by-user-id Resource Click vào /api/user-info (parent) Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: by-user-id Resource path: by-user-id Click \u0026ldquo;Create Resource\u0026rdquo; Add GET method with Lambda integration Bước 7: Create /empty Resource Click vào /api/user-info (parent) Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: empty Resource path: empty Click \u0026ldquo;Create Resource\u0026rdquo; Add GET method with Lambda integration Result: /api/user-info resource tree created with all sub-resources\nPhần 4: Create /upload Resource Bước 1: Create /upload Resource Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: upload Resource path: /upload ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Bước 2: Create POST Method Click vào /upload resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;POST\u0026rdquo; Integration type: Lambda Function Lambda Function: smoking-cessation-image-upload ✅ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Phần 5: Configure Authentication \u0026amp; Authorization Bước 1: Create Cognito Authorizer Left menu: Click \u0026ldquo;Authorizers\u0026rdquo; Click \u0026ldquo;Create Authorizer\u0026rdquo; Authorizer name: cognito-user-pool-authorizer Type: Cognito Cognito User Pool: smoking-cessation-users (tạo ở Module 3) Token source: Authorization Click \u0026ldquo;Create authorizer\u0026rdquo; Bước 2: Test Authorizer (Optional) Token: (enter a valid JWT token from your Cognito user pool) Click \u0026ldquo;Test authorizer\u0026rdquo; Verify response shows user claims Bước 3: Add Authorization to Methods For critical endpoints (e.g., /admin/coaches):\nClick vào /admin/coaches resource Click \u0026ldquo;GET\u0026rdquo; method Click \u0026ldquo;Method Request\u0026rdquo; Authorization: Select cognito-user-pool-authorizer Click checkmark to save Repeat for POST, PUT, DELETE methods Phần 6: Setup Request Validators Bước 1: Create Request Validator Left menu: Click \u0026ldquo;Request Validators\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Name: validate-body-and-params ✅ \u0026ldquo;Validate request body\u0026rdquo; ✅ \u0026ldquo;Validate query string parameters and headers\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Bước 2: Apply Validator to POST Methods Click vào /admin/coaches → \u0026ldquo;POST\u0026rdquo; method Click \u0026ldquo;Method Request\u0026rdquo; Request Validator: Select validate-body-and-params Save Phần 7: Setup CORS Bước 1: Enable CORS for All Resources Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Enable CORS\u0026rdquo; Review default settings Click \u0026ldquo;Enable CORS and replace existing CORS headers\u0026rdquo; Bước 2: Configure CORS Headers CORS headers automatically configured:\nAccess-Control-Allow-Headers: Content-Type, X-Amz-Date, Authorization, X-Api-Key, X-Amz-Security-Token Access-Control-Allow-Methods: GET, POST, PUT, DELETE, OPTIONS Access-Control-Allow-Origin: * (for dev, restrict in production) Phần 8: Create Second API - Chat API (WebSocket) Bước 1: Create WebSocket API Click \u0026ldquo;Create API\u0026rdquo; Select \u0026ldquo;WebSocket API\u0026rdquo; Click \u0026ldquo;Build\u0026rdquo; Bước 2: Configure WebSocket API API name: smoking-cessation-chat-api Description: WebSocket API for chat functionality Route Selection Expression: $request.body.action Click \u0026ldquo;Create API\u0026rdquo; ⏳ Chờ API được tạo\nBước 3: Create Routes Create default routes:\n$default route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer $connect route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer $disconnect route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer Phần 9: Deploy APIs Bước 1: Create Deployment Stage For User API:\nClick \u0026ldquo;Deploy API\u0026rdquo; Stage name: prod Stage description: Production environment Click \u0026ldquo;Deploy\u0026rdquo; Bước 2: Note API Endpoint After deployment, you\u0026rsquo;ll see:\nInvoke URL: https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod Save this URL Bước 3: Deploy Chat API Go to Chat API Click \u0026ldquo;Deploy API\u0026rdquo; Stage name: prod Click \u0026ldquo;Deploy\u0026rdquo; Note the WebSocket Invoke URL Phần 10: Test REST API Endpoints Bước 1: Test GET /admin/coaches In API Gateway console:\nSelect User API Click /admin/coaches → \u0026ldquo;GET\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: GET\nPath: /admin/coaches\nHeaders:\nAuthorization: Bearer {your-cognito-token} Click \u0026ldquo;Test\u0026rdquo;\nExpected result:\nStatus: 200 Body: JSON response from Lambda Bước 2: Test POST /admin/coaches Click /admin/coaches → \u0026ldquo;POST\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: POST Headers: Authorization: Bearer {your-cognito-token} Content-Type: application/json Body: { \u0026#34;name\u0026#34;: \u0026#34;Coach Name\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;coach@example.com\u0026#34;, \u0026#34;specialization\u0026#34;: \u0026#34;Smoking Cessation\u0026#34; } Click \u0026ldquo;Test\u0026rdquo; Expected: Status 200 with created coach data Bước 3: Test /upload Endpoint Click /upload → \u0026ldquo;POST\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: POST Headers: Authorization: Bearer {your-cognito-token} Content-Type: multipart/form-data Click \u0026ldquo;Test\u0026rdquo; Expected: Status 200 with S3 URL Bước 4: Test with cURL (Optional) # Get list of coaches curl -X GET \\ https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/admin/coaches \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; # Create new coach curl -X POST \\ https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/admin/coaches \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;Coach John\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john@example.com\u0026#34;, \u0026#34;specialization\u0026#34;: \u0026#34;Smoking Cessation\u0026#34; }\u0026#39; Phần 11: Setup CloudWatch Logging Bước 1: Enable Full Request/Response Logging Click \u0026ldquo;Settings\u0026rdquo; (left menu) CloudWatch log role ARN: Click \u0026ldquo;Edit\u0026rdquo; Select or create IAM role for API Gateway logging Role should have logs:CreateLogGroup, logs:CreateLogStream, logs:PutLogEvents permissions Click \u0026ldquo;Save changes\u0026rdquo; Bước 2: Set Log Level Go to \u0026ldquo;Stages\u0026rdquo; → \u0026ldquo;prod\u0026rdquo; Click \u0026ldquo;Logs\u0026rdquo; ✅ \u0026ldquo;Enable CloudWatch Logs\u0026rdquo; Log level: INFO (or DEBUG for troubleshooting) Data trace enabled: ✅ Full request/response data: ✅ Click \u0026ldquo;Save changes\u0026rdquo; Bước 3: View Logs Tìm kiếm \u0026ldquo;CloudWatch\u0026rdquo; Click \u0026ldquo;CloudWatch\u0026rdquo; service Left menu: \u0026ldquo;Logs\u0026rdquo; → \u0026ldquo;Log groups\u0026rdquo; Search for API-Gateway-Execution-Logs_{api-id} View recent requests Phần 12: Setup Rate Limiting (Usage Plans) Bước 1: Create API Key Left menu: Click \u0026ldquo;API Keys\u0026rdquo; Click \u0026ldquo;Create API Key\u0026rdquo; Name: mobile-app-key Description: API key for mobile app Click \u0026ldquo;Create API Key\u0026rdquo; Copy and save the key Bước 2: Create Usage Plan Left menu: Click \u0026ldquo;Usage Plans\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Name: free-tier-plan Description: Free tier plan with rate limiting Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Throttling \u0026amp; Quota Rate: 100 requests per second Burst: 200 requests Quota: 1,000,000 requests per month Click \u0026ldquo;Next\u0026rdquo; Bước 4: Associate API to Plan Associated API Stages: Select User API Select stage: prod Click \u0026ldquo;Next\u0026rdquo; Bước 5: Associate API Key to Plan API Keys: Search and select mobile-app-key Click \u0026ldquo;Finish\u0026rdquo; Phần 13: Setup Resource-Based Policy (Optional) To restrict API access to specific IAM users/roles:\nBước 1: Add Resource Policy Left menu: Click \u0026ldquo;Resource Policy\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;execute-api:Invoke\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;execute-api:/*\u0026#34; } ] } Click \u0026ldquo;Save\u0026rdquo; Phần 14: Enable API Caching (Optional) Bước 1: Enable Cache for GET Endpoints Go to stage: \u0026ldquo;prod\u0026rdquo; Click \u0026ldquo;Settings\u0026rdquo; Cache cluster enabled: ✅ Cache cluster size: 0.5 (smallest) Click \u0026ldquo;Save changes\u0026rdquo; Bước 2: Configure Cache per Method Click vào /admin/coaches → \u0026ldquo;GET\u0026rdquo; Click \u0026ldquo;Integration Response\u0026rdquo; Expand \u0026ldquo;200\u0026rdquo; response Cache settings: ✅ \u0026ldquo;Enable method caching\u0026rdquo; Cache time to live (TTL): 300 seconds (5 minutes) Click checkmark Environment Variables Summary Save these URLs after API deployment:\n# User Management API USER_API_ENDPOINT=https://{api-id-1}.execute-api.ap-southeast-1.amazonaws.com/prod USER_API_ID={api-id-1} # Chat API (WebSocket) CHAT_API_ENDPOINT=wss://{api-id-2}.execute-api.ap-southeast-1.amazonaws.com/prod CHAT_API_ID={api-id-2} # Authorizer COGNITO_AUTHORIZER_ID=cognito-user-pool-authorizer # Rate Limiting API_KEY={your-api-key} Checklist User API (smoking-cessation-user-api) created /admin/coaches resource with GET, POST, PUT, DELETE methods created /api/user-info resource with sub-resources created /upload resource with POST method created Chat API (smoking-cessation-chat-api) created Cognito authorizer configured CORS enabled for all resources Request validators configured Both APIs deployed to prod stage CloudWatch logging enabled Rate limiting with Usage Plans configured All endpoints tested successfully API endpoints saved to environment variables Sẵn sàng cho Module 6 (Create EC2 Instances \u0026amp; Databases) Troubleshooting CORS Errors in Browser Issue: \u0026ldquo;Access to XMLHttpRequest blocked by CORS policy\u0026rdquo;\nSolution:\nVerify CORS is enabled for resource Check Access-Control-Allow-Origin header For development, use * wildcard For production, restrict to specific domain 403 Unauthorized Errors Issue: \u0026ldquo;User is not authorized to perform: execute-api:Invoke\u0026rdquo;\nSolution:\nVerify JWT token is valid Check authorizer is configured on method Verify user has required role in Cognito Review API resource policy Lambda Function Not Found Issue: \u0026ldquo;Invalid Lambda function ARN specified\u0026rdquo;\nSolution:\nVerify Lambda function exists in same region Check Lambda function name spelling Verify IAM role has Lambda invoke permissions Check CloudWatch logs for integration errors Rate Limiting Not Working Issue: \u0026ldquo;Requests not throttled according to plan\u0026rdquo;\nSolution:\nVerify API key is passed in request Check Usage Plan is associated with stage Verify API key is associated with Usage Plan Wait for throttling to take effect (may take a few minutes) High Latency Issue: \u0026ldquo;API requests taking too long\u0026rdquo;\nSolution:\nEnable caching for GET requests Increase Lambda memory (Module 4) Check database connection from Lambda (Module 6) Monitor CloudWatch metrics Next Steps Implement API Gateway request/response transformations (optional) Setup WAF (Web Application Firewall) for security (optional) Configure CloudFront for API caching (Module 7) Setup API documentation (optional) Test end-to-end with frontend application Kết Quả Đạt Được Sau Module 5, bạn sẽ có:\n✅ 2 REST APIs created (User API \u0026amp; Chat API) ✅ All resources \u0026amp; methods configured ✅ Lambda integrations setup ✅ Cognito authorization configured ✅ CORS enabled for all endpoints ✅ Request validators configured ✅ Both APIs deployed to prod stage ✅ CloudWatch logging enabled ✅ Rate limiting configured ✅ All endpoints tested \u0026amp; verified ✅ API endpoints documented ✅ Sẵn sàng cho Module 6 (Create EC2 Instances \u0026amp; Databases) "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 5 Tiếp tục phối hợp với các thành viên First Cloud Journey trong quá trình phát triển dự án. Củng cố kiến thức AWS nền tảng đồng thời triển khai các luồng UI (admin/staff) và chuẩn bị bàn giao cho Back-End. Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference 2 - Hoàn thiện kế hoạch cuối tuần: bổ sung mục sản phẩm ở phần cuối trang; thiết kế giao diện Figma cho admin và staff.\n- Đăng ký làm việc tại văn phòng chưa được duyệt trong ngày → tiếp tục xử lý các phần Front-End. 06/10/2025 10/10/2025 — 3 - Phối hợp xử lý luồng đăng nhập và bố cục trang cho admin/staff; hỗ trợ đồng đội bằng cách sửa các lỗi UI.\n- Hoàn thành kiểm thử đăng nhập và tinh chỉnh lại giao diện admin/staff. 06/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Làm việc với Back-End để thống nhất các dịch vụ AWS sẽ sử dụng cho dự án.\n- Rà soát và bàn giao giữa các thành viên nhằm đảm bảo không bị trùng hoặc thiếu task; xác định các tác vụ UI tiếp theo. 06/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Chuẩn bị hình ảnh sản phẩm và dữ liệu demo trong thời gian chờ API/Database từ BE.\n- Kiểm thử lại luồng đăng nhập; hoàn thiện giao diện dành cho admin và staff. 06/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Theo dõi và hoàn tất các nhiệm vụ được leader giao.\n- Thực hiện thêm yêu cầu dịch bài blog sang tệp .docx (nội dung không có mã nguồn). 06/10/2025 10/10/2025 — Kết quả đạt được trong tuần Hoàn thiện mục sản phẩm ở footer và bộ giao diện Figma cho admin/staff; tiếp tục phát triển FE trong thời gian chờ đăng ký onsite. Xây dựng và kiểm thử luồng login, xử lý các lỗi cản trở tiến độ của nhóm; hoàn chỉnh UI admin/staff. Thống nhất với Back-End về các lựa chọn AWS cho dự án; xác định rõ kế hoạch cho giai đoạn tiếp theo. Chuẩn bị đầy đủ tài sản (hình ảnh, dữ liệu mẫu) phục vụ việc tích hợp API/Database. Hỗ trợ nhóm với các nhiệm vụ follow-up và yêu cầu dịch tài liệu. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"WORKSHOP XÂY DỰNG HỆ THỐNG SMOKING-CESSATION TRÊN AWS TỪ A → Z Workshop này hướng dẫn triển khai toàn bộ hệ thống thực tế bao gồm: Backend (Lambda + API Gateway), Databases (PostgreSQL + MongoDB), Authentication (Cognito), Infrastructure (VPC, EC2, Security), Frontend hosting (S3 + CloudFront), Monitoring (CloudWatch), và Cleanup.\nMỗi module tương ứng với một phần kiến trúc quan trọng trong hệ thống.\n🎯 Mục tiêu tổng quan Sau toàn bộ workshop, bạn sẽ nắm được:\nXây dựng hệ thống microservices trên AWS Quản lý user authentication bằng Cognito Tạo \u0026amp; vận hành Lambda serverless backend Publish API bằng API Gateway Tạo database server trên EC2 Cấu hình VPC, subnet, NAT Gateway, Security Groups Host frontend bằng S3 + CloudFront Theo dõi \u0026amp; giám sát bằng CloudWatch Tối ưu chi phí \u0026amp; dọn dẹp tài nguyên 🧩 Kiến trúc tổng quan hệ thống Full architecture bao gồm:\n8 Lambda Functions 2 REST APIs (User API + Chat API) 2 Databases trên EC2 (PostgreSQL + MongoDB) S3 + CloudFront cho frontend Cognito User Pool để đăng ký / đăng nhập VPC hoàn chỉnh với NAT, IGW, NLB CloudWatch Monitoring + Alarms Secrets Manager cho sensitive data 📚 Nội dung Workshop (10 Modules) Mỗi module đều có hướng dẫn step-by-step kèm hình minh họa.\n1️⃣ Giới thiệu Workshop Phác thảo mục tiêu dự án, kiến trúc tổng quan và các thành phần AWS sẽ sử dụng.\n2️⃣ Điều kiện tiên quyết Chuẩn bị môi trường AWS, IAM user, VS Code, SSH key, CLI tools, cấu trúc thư mục dự án.\n3️⃣ Cấu hình Cognito Tạo User Pool, App Client, Password Policy, Post-confirmation Trigger, Email Verification.\n4️⃣ Cấu hình Lambda Functions Tạo 5 Lambda functions cho hệ thống, gán IAM Role, thêm environment variables, kết nối Secrets Manager.\n5️⃣ Cấu hình API Gateway Tạo 2 REST APIs, mapping với Lambda, bật CORS, request validation, throttling, test API end-to-end.\n6️⃣ Cấu hình RDS \u0026amp; Database EC2 Tạo 2 EC2 database servers, cài PostgreSQL + MongoDB, tạo user, schema, SSH hardening, backup scripts.\n7️⃣ Cấu hình S3 + CloudFront Tạo S3 hosting cho frontend React, cấu hình OAC, tạo CloudFront distribution, SSL, caching, invalidation.\n8️⃣ Cấu hình VPC \u0026amp; Security Khởi tạo VPC, subnets, route tables, NAT Gateway, IGW, SGs, NLB cho WebSocket, GuardDuty + Flow Logs.\n9️⃣ Monitoring \u0026amp; Logging Tạo CloudWatch dashboards, alarms, SNS notifications, CloudTrail, X-Ray distributed tracing.\n🔟 Cleanup \u0026amp; Cost Optimization Kiểm tra tài nguyên còn dùng, phân tích chi phí, backup databases, xóa API, EC2, Lambda, S3, CloudFront.\n✔ Kết luận Workshop này giúp bạn xây dựng một hệ thống hoàn chỉnh, bảo mật, tối ưu chi phí theo đúng chuẩn AWS Production.\nBạn đã sẵn sàng bắt đầu với Module 5.1 — Introduction.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.6-event6/","title":"AWS Cloud Mastery Series #1","tags":[],"description":"","content":"Bào thu hoạch: “BUILDING AGENTIC AI - Context Optimization with Amazon Bedrock” Mục tiêu Sự kiện Cung cấp phần giới thiệu rõ ràng về Agentic AI và sự chuyển dịch sang các hệ thống AI tự động Trình bày Amazon Bedrock AgentCore cùng hệ sinh thái agentic mở rộng của AWS Minh họa các ví dụ thực tế về thiết kế Agentic Workflow trên AWS Làm nổi bật cách tiếp cận orchestration của CloudThinker và các phương pháp tối ưu hóa ngữ cảnh Cung cấp trải nghiệm thực hành xây dựng ứng dụng dựa trên agent bằng AWS Bedrock Tạo cơ hội kết nối với các chuyên gia trong cộng đồng AI và điện toán đám mây Diễn giả Nguyễn Gia Hưng – Head of Solutions Architect, AWS Kiên Nguyễn – Solutions Architect, AWS Việt Phạm – Founder \u0026amp; CEO, Diaflow Thắng Tôn – Co-founder \u0026amp; COO, CloudThinker Henry Bùi – Head of Engineering, CloudThinker Kha Văn – Community Leader, AWS Những Điểm Nổi Bật Sự Phát Triển của Agentic AI ML Truyền thống / AI Cổ điển\nNhiệm vụ được định nghĩa hẹp, khả năng giới hạn Phụ thuộc mạnh vào dữ liệu có cấu trúc và xử lý tiền đề Khó mở rộng hoặc thích nghi với các trường hợp sử dụng mới Agentic AI Hiện Đại\nĐược vận hành bởi Foundation Models với khả năng suy luận đa bước Tự động phân rã nhiệm vụ và sử dụng công cụ Tích hợp API, thực thi workflow và truy cập tri thức Trở nên linh hoạt và sẵn sàng cho môi trường sản xuất khi kết hợp với AWS Thách Thức Khi Triển Khai Agentic AI Các vấn đề hiệu năng như độ trễ, suy luận song song, thông lượng Mở rộng cho multi-agent và xử lý ngữ cảnh phức tạp Yêu cầu bảo mật như kiểm soát dữ liệu, luồng định danh, phân quyền truy cập Nhu cầu governance như logging, khả năng truy vết, giới hạn workflow Danh Mục Agentic AI của AWS Amazon Bedrock AgentCore cho identity, memory, runtime, truy cập tools và workflows Agent Gateway cho tích hợp công cụ và API thống nhất Hỗ trợ nhiều mô hình như Anthropic, Meta Llama, Amazon Titan và nhiều hơn nữa Thiết kế hướng doanh nghiệp với guardrails, observability và khả năng mở rộng Amazon Bedrock AgentCore Runtime để điều phối các nhiệm vụ đa bước Memory cho ngữ cảnh ngắn hạn và dài hạn Identity Flow để quản lý quyền và bảo mật Agent Gateway để kết nối tới công cụ, API và hệ thống doanh nghiệp Code Interpreter cho môi trường thực thi mã an toàn Browser Tool để thu thập thông tin từ nguồn bên ngoài Các tính năng quan sát gồm logs, traces và metrics Xây Dựng Agentic Workflow trên AWS (Use Case từ Diaflow) Phối hợp giữa nhiều agent Truy xuất ngữ cảnh và function calling Tích hợp agent với hệ thống dữ liệu doanh nghiệp Thực thi logic kinh doanh bằng Bedrock và công cụ Diaflow Chiến lược thiết kế thực tế phù hợp với startup và SME Orchestration \u0026amp; Tối Ưu Ngữ Cảnh của CloudThinker Các mô hình điều phối cấp cao cho hệ thống agent Lọc ngữ cảnh để cải thiện hiệu suất mô hình Workflow thích ứng thay đổi dựa trên thông tin từ agent Kỹ thuật đánh giá và tăng độ tin cậy trong suy luận Tích hợp workflow CloudThinker với Amazon Bedrock AgentCore CloudThinker Hack: Phiên Thực Hành Thiết lập ban đầu Bedrock agents Xây dựng workflow agent đơn giản Thêm công cụ bên ngoài vào pipeline Khắc phục lỗi và tối ưu hành vi agent Triển khai bản proof-of-concept hoàn chỉnh Những Điểm Rút Ra Quan Trọng Tư Duy Agentic AI AI đang chuyển từ phản hồi thụ động sang hành động tự chủ Agent hiệu quả cần kết hợp memory, tools, identity và orchestration Foundation Models + điều phối workflow = thế hệ ứng dụng AI tiếp theo AWS hiện là một trong những môi trường sẵn sàng sản xuất mạnh mẽ nhất cho agentic AI Hiểu Biết Kỹ Thuật Vì sao tối ưu hóa ngữ cảnh quan trọng Cách công cụ và quản lý định danh ảnh hưởng đến độ tin cậy Cách AgentCore đơn giản hóa reasoning đa bước Vai trò của các mô hình orchestrator thực tế Phương pháp kết nối mô hình với API, tầng logic và nguồn dữ liệu Kỹ Năng Phát Triển Thực Tế Thiết kế workflow AI hoàn chỉnh từ đầu đến cuối Tích hợp công cụ bên ngoài vào pipeline agent Điều phối đa agent hiệu quả Quản lý độ trễ, khả năng mở rộng và bảo mật Triển khai agent với đầy đủ guardrails và hệ thống giám sát Ứng Dụng Vào Công Việc Người tham dự có thể áp dụng trực tiếp:\nXây dựng assistant, quy trình tự động hóa hoặc copilots nội bộ Kết nối mô hình Bedrock với nền tảng doanh nghiệp Phát triển workflow đa bước có cấu trúc với AgentCore Tạo prototype nhanh mà không cần hạ tầng DevOps phức tạp Ứng dụng phương pháp orchestration của CloudThinker để tăng hiệu suất Áp dụng mô hình thiết kế agentic cho cả startup và doanh nghiệp lớn Trải Nghiệm Sự Kiện Workshop “Agentic Build AI – Optimization with Amazon Bedrock” đã mang đến góc nhìn toàn diện về phát triển Agentic AI hiện đại.\nKiến Thức Từ Chuyên Gia Các diễn giả từ AWS, CloudThinker và Diaflow chia sẻ trải nghiệm triển khai thực tế Hướng dẫn rõ ràng về cách mở rộng và vận hành giải pháp GenAI Ví dụ cụ thể về tự động hóa quy trình doanh nghiệp bằng Agentic AI Trải Nghiệm Thực Hành Xây dựng workflow agent hoàn chỉnh trong workshop Hiểu rõ cách memory, identity và tool tương tác Trải nghiệm thực tế với API và các thành phần orchestration của Bedrock Cơ Hội Kết Nối Gặp gỡ kiến trúc sư AWS, kỹ sư, founder và các thành viên cộng đồng Tìm hiểu các hướng phát triển sự nghiệp và thảo luận về sản phẩm AI Trao đổi ý tưởng về hệ thống AI cloud-native Bài Học Rút Ra Agentic AI vượt xa chatbot và ứng dụng LLM truyền thống Triển khai thực tế yêu cầu identity, observability và khả năng mở rộng Bedrock và CloudThinker cung cấp lộ trình mạnh mẽ từ prototype đến sản xuất Dự án thực tế mang lại giá trị rõ ràng hơn so với các bài tập học thuật rời rạc Một số hình ảnh sự kiện Hình 1 Hình 2 Hình 3 Tóm lại, workshop đã mang đến sự kết hợp hài hòa giữa kiến thức chiến lược và kỹ năng thực hành. Người tham gia rời sự kiện với khả năng thiết kế workflow, tinh chỉnh ngữ cảnh, tích hợp công cụ và xây dựng hệ thống agentic mở rộng, an toàn trên AWS.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-setup-rds-database/","title":"5.6 Setup RDS Database","tags":[],"description":"","content":"Module 6: Create EC2 Instances \u0026amp; Setup Databases Mục tiêu Module Tạo 4 EC2 instances từ đầu Setup PostgreSQL trên DB-PG instance Setup MongoDB trên DB-Mongo instance Cấu hình security groups Tạo databases \u0026amp; users Test connectivity giữa instances Setup monitoring \u0026amp; backups Duration: 5-6 giờ\nEC2 Instances Overview 4 instances sẽ được tạo ở ap-southeast-1 (t4g.small, ARM-based, cost-effective):\nInstance Name Type Purpose Database Port smoking-db-pg t4g.small PostgreSQL Server smoking_cessation 5432 smoking-db-mongo t4g.small MongoDB Server smoking_cessation 27017 smoking-app-user t4g.small User Cessation App (PostgreSQL) 8000 smoking-app-social t4g.small Social Media App (MongoDB) 8000 Phần 1: Create Security Groups Bước 1: Create Database Security Group EC2 Console Left menu: \u0026ldquo;Security Groups\u0026rdquo; Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-db-sg Description: Security group for database servers VPC: Default VPC (or your VPC) Click \u0026ldquo;Create security group\u0026rdquo; Bước 2: Add Inbound Rules for DB-SG Click vào security group vừa tạo \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add these rules: Type: PostgreSQL (5432) Source: Custom → 172.0.0.0/16 (internal VPC CIDR) Type: Custom TCP 27017 (MongoDB) Source: 172.0.0.0/16 Click \u0026ldquo;Save rules\u0026rdquo; Bước 3: Create Application Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-app-sg Description: Security group for application servers Click \u0026ldquo;Create security group\u0026rdquo; Bước 4: Add Inbound Rules for App-SG Click vào security group vừa tạo \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: SSH (22) Source: My IP (hoặc 0.0.0.0/0 nếu không có fixed IP) Type: Custom TCP 8000 (application) Source: 0.0.0.0/0 (or restrict to NLB later) Click \u0026ldquo;Save rules\u0026rdquo; Bước 5: Add Outbound Rules \u0026ldquo;Outbound rules\u0026rdquo; → \u0026ldquo;Edit outbound rules\u0026rdquo; Verify: All traffic to smoking-db-sg (for database access) All traffic to internet (for package downloads) Default rule should allow this Click \u0026ldquo;Save rules\u0026rdquo; Phần 2: Create EC2 Instances Bước 1: Launch First Instance (PostgreSQL) EC2 Console Click \u0026ldquo;Launch Instances\u0026rdquo; Name: smoking-db-pg AMI: Amazon Linux 2023 (free tier eligible) Instance type: t4g.small Keypair: Create new or select existing Key pair name: smoking-cessation-key Click \u0026ldquo;Create key pair\u0026rdquo; Download \u0026amp; save securely Click \u0026ldquo;Next\u0026rdquo; Bước 2: Configure Network VPC: Default VPC (or your VPC) Subnet: Any (or specific subnet in us-southeast-1a) Auto-assign public IP: Disable (private subnet) Security group: smoking-db-sg Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Storage Size: 30 GB (enough for databases) Volume type: gp3 (general purpose, cost-effective) Delete on termination: ✅ Click \u0026ldquo;Next\u0026rdquo; Bước 4: Add Tags Tag key: Name Tag value: smoking-db-pg Click \u0026ldquo;Launch instance\u0026rdquo; ⏳ Chờ instance được tạo (2-3 phút)\nBước 5: Note Private IP Address Wait for instance status \u0026ldquo;running\u0026rdquo; Copy Private IPv4 address (e.g., 172.0.8.55) Save for later: PG_HOST=172.0.8.55 Bước 6: Create MongoDB Instance (Same Steps) Click \u0026ldquo;Launch Instances\u0026rdquo; Name: smoking-db-mongo Same configuration as PostgreSQL Security group: smoking-db-sg Launch instance Note IP address: MONGO_HOST=\u0026lt;ip\u0026gt; Bước 7: Create Application Instances Launch instance: smoking-app-user\nSecurity group: smoking-app-sg Note IP: APP_USER_HOST=\u0026lt;ip\u0026gt; Launch instance: smoking-app-social\nSecurity group: smoking-app-sg Note IP: APP_SOCIAL_HOST=\u0026lt;ip\u0026gt; All 4 instances should now be running.\nPhần 3: Setup PostgreSQL on DB-PG Instance Bước 1: Connect to Instance Using AWS Session Manager (recommended) or SSH:\n# Via SSH (if you have keypair) ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;PRIVATE_IP\u0026gt; # Or use Session Manager in EC2 Console # Click instance → Connect → Session Manager → Connect Bước 2: Update System sudo yum update -y sudo yum upgrade -y Bước 3: Install PostgreSQL # Add PostgreSQL repository sudo tee /etc/yum.repos.d/pgdg.repo \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [pgdg15] name=PostgreSQL 15 for RHEL/CentOS 9 - x86_64 baseurl=https://download.postgresql.org/pub/repos/yum/15/rhel/rhel-9-x86_64 enabled=1 gpgcheck=1 gpgkey=https://download.postgresql.org/pub/repos/yum/RPM-GPG-KEY-PGDG EOF # Install PostgreSQL sudo yum install -y postgresql15-server postgresql15-contrib Bước 4: Initialize Database Cluster # Initialize cluster sudo /usr/pgsql-15/bin/initdb -D /var/lib/pgsql/15/data # Create system user if needed sudo useradd postgres || true # Change permissions sudo chown -R postgres:postgres /var/lib/pgsql/15/data Bước 5: Start PostgreSQL Service # Enable service to start on boot sudo systemctl enable postgresql-15 # Start service sudo systemctl start postgresql-15 # Verify status sudo systemctl status postgresql-15 Bước 6: Configure PostgreSQL for Network Access # Edit config file sudo nano /var/lib/pgsql/15/data/postgresql.conf # Find and change these lines: # listen_addresses = \u0026#39;localhost\u0026#39; → listen_addresses = \u0026#39;*\u0026#39; # port = 5432 → keep as is # Save: Ctrl+O, Enter, Ctrl+X Bước 7: Configure Client Authentication # Edit pg_hba.conf sudo nano /var/lib/pgsql/15/data/pg_hba.conf # Add this line at the end (before any reject lines): # host all all 172.0.0.0/16 md5 # This allows connections from VPC CIDR 172.0.0.0/16 Bước 8: Restart PostgreSQL sudo systemctl restart postgresql-15 sudo systemctl status postgresql-15 Bước 9: Create smoking_cessation Database # Switch to postgres user sudo su - postgres # Connect to psql psql # Create database CREATE DATABASE smoking_cessation; # Create application user CREATE USER app_user WITH PASSWORD \u0026#39;YourSecurePassword123!\u0026#39;; # Grant privileges GRANT ALL PRIVILEGES ON DATABASE smoking_cessation TO app_user; # Connect to database \\c smoking_cessation # Grant schema privileges GRANT ALL ON SCHEMA public TO app_user; GRANT ALL ON ALL TABLES IN SCHEMA public TO app_user; GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO app_user; # Verify \\du # List users \\l # List databases # Exit \\q exit Bước 10: Verify PostgreSQL is Listening # Check if listening on port 5432 sudo netstat -tlnp | grep 5432 # Or use ss command sudo ss -tlnp | grep 5432 # Output should show: LISTEN ... 0.0.0.0:5432 or :::5432 Phần 4: Setup MongoDB on DB-Mongo Instance Bước 1: Connect to Instance ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;MONGO_PRIVATE_IP\u0026gt; # Or use Session Manager Bước 2: Update System sudo yum update -y sudo yum upgrade -y Bước 3: Install MongoDB # Create MongoDB repository sudo tee /etc/yum.repos.d/mongodb-org.repo \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [mongodb-org-7.0] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/amazon/2023/mongodb-org/7.0/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-7.0.asc EOF # Install MongoDB sudo yum install -y mongodb-org Bước 4: Configure MongoDB for Network Access # Edit MongoDB config sudo nano /etc/mongod.conf # Find these sections and modify: # network: # port: 27017 # bindIp: localhost → Change to bindIp: 0.0.0.0 # Save: Ctrl+O, Enter, Ctrl+X Bước 5: Start MongoDB Service # Enable service to start on boot sudo systemctl enable mongod # Start service sudo systemctl start mongod # Verify status sudo systemctl status mongod Bước 6: Create MongoDB Database \u0026amp; User # Connect to MongoDB mongosh # Switch to admin database use admin # Create admin user db.createUser({ user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;YourAdminPassword123!\u0026#34;, roles: [\u0026#34;root\u0026#34;] }) # Exit mongosh exit # Restart with authentication sudo nano /etc/mongod.conf # Find security section and uncomment: # security: # authorization: enabled # Save and restart sudo systemctl restart mongod Bước 7: Create Application Database \u0026amp; User # Connect with authentication mongosh -u admin -p YourAdminPassword123! # Switch to smoking_cessation database use smoking_cessation # Create application user db.createUser({ user: \u0026#34;app_user\u0026#34;, pwd: \u0026#34;AppPassword123!\u0026#34;, roles: [{role: \u0026#34;readWrite\u0026#34;, db: \u0026#34;smoking_cessation\u0026#34;}] }) # Verify user created show users # Exit exit Bước 8: Verify MongoDB is Listening # Check if listening on port 27017 sudo netstat -tlnp | grep 27017 # Or sudo ss -tlnp | grep 27017 # Output should show LISTEN on port 27017 Phần 5: Test Database Connectivity Bước 1: Test PostgreSQL from App Instance Connect to application instance:\nssh -i smoking-cessation-key.pem ec2-user@\u0026lt;APP_USER_HOST\u0026gt; # Install PostgreSQL client sudo yum install -y postgresql15 # Test connection to PostgreSQL psql -h \u0026lt;PG_HOST_IP\u0026gt; -U app_user -d smoking_cessation -c \u0026#34;SELECT 1\u0026#34; # Expected output: Should show \u0026#34;1\u0026#34; (success) Bước 2: Test MongoDB from App Instance # Install MongoDB tools sudo yum install -y mongodb-mongosh # Test connection to MongoDB mongosh --host \u0026lt;MONGO_HOST_IP\u0026gt;:27017 --username app_user --password AppPassword123! --authenticationDatabase smoking_cessation --eval \u0026#34;db.adminCommand(\u0026#39;ping\u0026#39;)\u0026#34; # Expected output: { ok: 1 } Bước 3: Test Inter-Instance Ping # From any instance, test network connectivity ping -c 3 \u0026lt;TARGET_IP\u0026gt; # Expected: Low latency (\u0026lt; 5ms in same VPC) Phần 6: Create Database Tables (PostgreSQL) Bước 1: Connect to Database From app instance or via psql:\n# Connect to smoking_cessation database psql -h \u0026lt;PG_HOST_IP\u0026gt; -U app_user -d smoking_cessation Bước 2: Create Tables -- Create users table CREATE TABLE users ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), cognito_id VARCHAR(255) UNIQUE NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, name VARCHAR(255) NOT NULL, role VARCHAR(50) DEFAULT \u0026#39;user\u0026#39;, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create coaches table CREATE TABLE coaches ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id UUID REFERENCES users(id) ON DELETE CASCADE, specialization VARCHAR(255), bio TEXT, hourly_rate DECIMAL(10, 2), created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create coaching_sessions table CREATE TABLE coaching_sessions ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id UUID REFERENCES users(id) ON DELETE CASCADE, coach_id UUID REFERENCES coaches(id) ON DELETE SET NULL, status VARCHAR(50) DEFAULT \u0026#39;active\u0026#39;, started_at TIMESTAMP, ended_at TIMESTAMP, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create indexes for performance CREATE INDEX idx_users_cognito_id ON users(cognito_id); CREATE INDEX idx_users_email ON users(email); CREATE INDEX idx_coaches_user_id ON coaches(user_id); CREATE INDEX idx_sessions_user_id ON coaching_sessions(user_id); CREATE INDEX idx_sessions_coach_id ON coaching_sessions(coach_id); -- Grant permissions to app_user GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO app_user; GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO app_user; -- Verify tables \\dt Bước 3: Exit psql \\q Phần 7: Setup Application Servers (EC2 Instances) Bước 1: Connect to Application Instance ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;APP_USER_HOST\u0026gt; Bước 2: Install Node.js \u0026amp; npm # Update system sudo yum update -y # Install Node.js (Amazon Linux version) curl -fsSL https://rpm.nodesource.com/setup_20.x | sudo bash - sudo yum install -y nodejs # Verify installation node --version npm --version Bước 3: Create Application Directory # Create app directory sudo mkdir -p /opt/smoking-cessation sudo chown -R ec2-user:ec2-user /opt/smoking-cessation # Change to directory cd /opt/smoking-cessation # Create basic package.json cat \u0026gt; package.json \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; { \u0026#34;name\u0026#34;: \u0026#34;smoking-cessation-app\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Smoking cessation user app\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;server.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node server.js\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;nodemon server.js\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;^4.18.2\u0026#34;, \u0026#34;pg\u0026#34;: \u0026#34;^8.10.0\u0026#34; } } EOF # Install dependencies npm install Bước 4: Create Basic Express Server # Create server.js cat \u0026gt; server.js \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; const express = require(\u0026#39;express\u0026#39;); const { Pool } = require(\u0026#39;pg\u0026#39;); const app = express(); const port = 8000; // Database connection pool const pool = new Pool({ user: \u0026#39;app_user\u0026#39;, password: process.env.DB_PASSWORD || \u0026#39;AppPassword123!\u0026#39;, host: process.env.DB_HOST || \u0026#39;localhost\u0026#39;, port: 5432, database: \u0026#39;smoking_cessation\u0026#39; }); app.use(express.json()); // Health check endpoint app.get(\u0026#39;/health\u0026#39;, (req, res) =\u0026gt; { res.json({ status: \u0026#39;ok\u0026#39;, service: \u0026#39;user-app\u0026#39; }); }); // Test database connection app.get(\u0026#39;/db-test\u0026#39;, async (req, res) =\u0026gt; { try { const result = await pool.query(\u0026#39;SELECT NOW()\u0026#39;); res.json({ message: \u0026#39;Database connected\u0026#39;, time: result.rows[0] }); } catch (error) { res.status(500).json({ error: error.message }); } }); app.listen(port, () =\u0026gt; { console.log(`App listening on port ${port}`); }); EOF Bước 5: Test Application # Start server node server.js # In another terminal, test endpoints curl http://localhost:8000/health curl http://localhost:8000/db-test # Ctrl+C to stop Bước 6: Create Systemd Service (Optional) # Create service file sudo tee /etc/systemd/system/smoking-app.service \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [Unit] Description=Smoking Cessation Application After=network.target [Service] Type=simple User=ec2-user WorkingDirectory=/opt/smoking-cessation ExecStart=/usr/bin/node server.js Restart=on-failure RestartSec=10 [Install] WantedBy=multi-user.target EOF # Enable and start service sudo systemctl daemon-reload sudo systemctl enable smoking-app sudo systemctl start smoking-app sudo systemctl status smoking-app Phần 8: Setup Monitoring \u0026amp; CloudWatch Bước 1: Enable Detailed Monitoring EC2 Console Select each instance Right-click → \u0026ldquo;Monitoring and troubleshooting\u0026rdquo; Click \u0026ldquo;Enable detailed monitoring\u0026rdquo; This provides 1-minute metrics instead of default 5-minute.\nBước 2: Create CloudWatch Alarms For high CPU on database instances:\nCloudWatch Console \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;Create alarm\u0026rdquo; Metric: Namespace: AWS/EC2 Metric: CPUUtilization Dimension: Instance ID (select DB-PG) Conditions: Statistic: Average Period: 5 minutes Threshold: \u0026gt; 80% Notification: Create SNS topic for alerts Click \u0026ldquo;Create alarm\u0026rdquo; Repeat for all instances.\nBước 3: Create Dashboard CloudWatch → Dashboards \u0026ldquo;Create dashboard\u0026rdquo; Name: smoking-cessation-infrastructure Add widgets: EC2 CPU Utilization (all instances) Network In/Out Disk usage (if CloudWatch agent installed) Click \u0026ldquo;Create dashboard\u0026rdquo; Phần 9: Setup Database Backups Bước 1: Create Backup Directory On each database instance:\n# Create backup directory sudo mkdir -p /backups sudo chown -R postgres:postgres /backups # For PostgreSQL Bước 2: PostgreSQL Automated Backup # Connect as ec2-user ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;PG_HOST\u0026gt; # Create backup script cat \u0026gt; ~/backup-pg.sh \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; #!/bin/bash BACKUP_DIR=\u0026#34;/backups\u0026#34; TIMESTAMP=$(date +%Y%m%d_%H%M%S) BACKUP_FILE=\u0026#34;$BACKUP_DIR/smoking_cessation_$TIMESTAMP.sql\u0026#34; sudo -u postgres pg_dump -d smoking_cessation -h localhost \u0026gt; \u0026#34;$BACKUP_FILE\u0026#34; # Keep only last 7 days of backups find $BACKUP_DIR -name \u0026#34;smoking_cessation_*.sql\u0026#34; -mtime +7 -delete echo \u0026#34;Backup completed: $BACKUP_FILE\u0026#34; EOF # Make executable chmod +x ~/backup-pg.sh # Test backup ./backup-pg.sh # Add to crontab for daily backups at 3 AM crontab -e # Add: 0 3 * * * /home/ec2-user/backup-pg.sh \u0026gt;\u0026gt; /var/log/postgres-backup.log 2\u0026gt;\u0026amp;1 Bước 3: MongoDB Automated Backup # Connect as ec2-user ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;MONGO_HOST\u0026gt; # Create backup script cat \u0026gt; ~/backup-mongo.sh \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; #!/bin/bash BACKUP_DIR=\u0026#34;/backups\u0026#34; TIMESTAMP=$(date +%Y%m%d_%H%M%S) BACKUP_PATH=\u0026#34;$BACKUP_DIR/smoking_cessation_$TIMESTAMP\u0026#34; mongodump --username=admin --password=\u0026#34;YourAdminPassword123!\u0026#34; --db smoking_cessation --out \u0026#34;$BACKUP_PATH\u0026#34; # Keep only last 7 days find $BACKUP_DIR -maxdepth 1 -type d -mtime +7 -exec rm -rf {} \\; echo \u0026#34;MongoDB backup completed: $BACKUP_PATH\u0026#34; EOF # Make executable chmod +x ~/backup-mongo.sh # Test backup ./backup-mongo.sh # Add to crontab for daily backups at 4 AM crontab -e # Add: 0 4 * * * /home/ec2-user/backup-mongo.sh \u0026gt;\u0026gt; /var/log/mongo-backup.log 2\u0026gt;\u0026amp;1 Bước 4: Upload Backups to S3 (Optional) To backup off-instance (safer):\n# Configure AWS CLI on instance (requires IAM role) aws configure # Modify backup scripts to upload to S3: # aws s3 cp $BACKUP_FILE s3://smoking-cessation-backups/ Environment Variables Summary Save these for Lambda functions \u0026amp; applications:\n# PostgreSQL PG_HOST=\u0026lt;DB-PG_PRIVATE_IP\u0026gt; PG_USER=app_user PG_PASSWORD=AppPassword123! PG_DATABASE=smoking_cessation PG_PORT=5432 # MongoDB MONGO_HOST=\u0026lt;DB-Mongo_PRIVATE_IP\u0026gt; MONGO_USERNAME=app_user MONGO_PASSWORD=AppPassword123! MONGO_DATABASE=smoking_cessation MONGO_PORT=27017 MONGO_URI=mongodb://app_user:AppPassword123!@\u0026lt;MONGO_HOST\u0026gt;:27017/smoking_cessation # Application Instances APP_USER_HOST=\u0026lt;APP_USER_PRIVATE_IP\u0026gt; APP_SOCIAL_HOST=\u0026lt;APP_SOCIAL_PRIVATE_IP\u0026gt; Checklist 4 EC2 instances launched (DB-PG, DB-Mongo, App-User, App-Social) Security groups created with proper inbound/outbound rules PostgreSQL installed, configured, and accessible MongoDB installed, configured, and accessible smoking_cessation database created in both databases Application users created with proper permissions Database tables created (users, coaches, sessions) Application instances can connect to databases Inter-instance connectivity tested (ping, port access) Node.js \u0026amp; npm installed on app instances Express server created and tested CloudWatch detailed monitoring enabled CloudWatch alarms configured for high CPU CloudWatch dashboard created Database backup scripts created and tested Backup scripts added to crontab All database credentials saved securely Sẵn sàng cho Module 7 (Create S3 \u0026amp; CloudFront) Troubleshooting Cannot Connect to PostgreSQL Issue: Connection refused on port 5432\nSolution:\n# Check PostgreSQL is running sudo systemctl status postgresql-15 # Check listening on port 5432 sudo netstat -tlnp | grep 5432 # Check security group rules allow 5432 # From app instance, verify: telnet \u0026lt;PG_HOST\u0026gt; 5432 # Check pg_hba.conf allows VPC CIDR sudo nano /var/lib/pgsql/15/data/pg_hba.conf Cannot Connect to MongoDB Issue: Connection refused on port 27017\nSolution:\n# Check MongoDB is running sudo systemctl status mongod # Check port listening sudo netstat -tlnp | grep 27017 # Check mongod.conf bindIp is correct sudo nano /etc/mongod.conf # Verify authentication enabled correctly mongosh -u admin -p \u0026lt;password\u0026gt; Network Connectivity Issues Issue: Instances cannot ping each other\nSolution:\nVerify all instances are in same VPC Check security group rules allow traffic between groups Check Network ACLs don\u0026rsquo;t block traffic Verify instances have route table entries High CPU on Database Instance Issue: CPU Utilization \u0026gt; 80%\nSolution:\n# Check top processes top -b -n 1 | head -20 # For PostgreSQL, check long-running queries: psql -h localhost -U postgres -d smoking_cessation SELECT pid, usename, query, query_start FROM pg_stat_activity WHERE query != \u0026#39;autovacuum\u0026#39;; # Consider: Scale up instance type, optimize queries, or add replication Cost Analysis Current costs (4 × t4g.small at $0.0252/hour):\nCompute: ~$30/month (4 instances × 730 hours) Storage: ~$10/month (4 × 30GB EBS volumes) Data transfer: ~$5/month Total: ~$45/month Optimization options:\nUse Reserved Instances for 30% savings (~$31/month) Right-size if low usage (t4g.micro: ~$10/month) Consolidate to 2 instances if possible Next Steps Configure auto-scaling for application instances (optional) Setup read replicas for PostgreSQL (optional) Enable database replication for high availability (optional) Configure point-in-time recovery (PITR) for databases (optional) Setup monitoring alerts (Module 9) Kết Quả Đạt Được Sau Module 6, bạn sẽ có:\n✅ 4 EC2 instances created \u0026amp; running ✅ Security groups configured with proper rules ✅ PostgreSQL server setup \u0026amp; database created ✅ MongoDB server setup \u0026amp; database created ✅ Application users created in both databases ✅ Database tables created \u0026amp; indexed ✅ Application server configuration completed ✅ Inter-instance connectivity tested ✅ CloudWatch monitoring enabled ✅ CloudWatch alarms configured ✅ Database backup scripts setup ✅ All databases operational \u0026amp; accessible ✅ Sẵn sàng cho Module 7 (Create S3 \u0026amp; CloudFront) "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại AWS từ ngày 08/09/2025 đến 28/11/2025, em đã có cơ hội tiếp cận môi trường làm việc thực tế, được học hỏi và vận dụng những kiến thức đã được trang bị trên giảng đường. Em đồng thời tham gia vào dự án Insight HR, qua đó rèn luyện thêm các kỹ năng lập trình, giao tiếp nhóm và kỹ năng báo cáo tiến độ.\nTrong quá trình làm việc, em luôn cố gắng hoàn thành nhiệm vụ đúng hạn, tuân thủ quy trình của đơn vị, và chủ động phối hợp với các anh/chị trong nhóm để nâng cao hiệu quả chung.\nĐể có cái nhìn khách quan hơn về quá trình thực tập, em muốn tự đánh giá bản thân dựa trên các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Những điểm cần cải thiện Trong quá trình thực tập, bên cạnh những kỹ năng đã đạt được, em cũng nhận thấy một số điểm bản thân cần cải thiện để phát triển tốt hơn trong môi trường làm việc chuyên nghiệp:\nKhả năng học hỏi:\nMặc dù em tiếp thu kiến thức khá nhanh, nhưng đối với các chủ đề nâng cao như kiến trúc AWS phức tạp hoặc các dịch vụ đòi hỏi tư duy hệ thống, em cần cải thiện tốc độ nắm bắt và chủ động nghiên cứu sâu hơn.\nTính chủ động:\nEm đôi khi vẫn chờ chỉ dẫn từ mentor trước khi bắt đầu nhiệm vụ mới. Trong thời gian tới, em cần chủ động hơn trong việc tìm hiểu tài liệu, tự đề xuất hướng giải quyết và thử nghiệm trước khi xin hỗ trợ.\nTinh thần cầu tiến:\nEm tiếp nhận góp ý tốt, tuy nhiên cần hình thành thói quen tự đánh giá định kỳ để nhận diện điểm yếu và lên kế hoạch cải thiện dài hạn, đặc biệt trong các mảng em muốn phát triển như serverless, kiến trúc cloud và DevOps.\nGiao tiếp:\nEm cần cải thiện kỹ năng trình bày và diễn đạt trong các buổi họp nhóm , giúp thông tin rõ ràng, ngắn gọn và tự tin hơn. Điều này sẽ hỗ trợ tốt cho quá trình làm việc nhóm và báo cáo tiến độ.\nKỹ năng giải quyết vấn đề:\nKhi làm việc với API Gateway, Lambda hoặc DynamoDB, đôi lúc em mất khá nhiều thời gian để tìm nguyên nhân lỗi. Em cần rèn luyện khả năng đọc log, phân tích vấn đề theo từng lớp và áp dụng phương pháp debug hiệu quả hơn.\nNhững điểm trên cũng chính là mục tiêu phát triển của em trong thời gian sắp tới để hoàn thiện bản thân và đáp ứng tốt công việc thực tế.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Mục tiêu tuần 6 Lên kế hoạch ôn tập và chuẩn bị tài liệu cho kỳ thi giữa kỳ. Phác thảo kiến trúc dự án và gửi bản nháp cho mentor xem xét. Các công việc đã thực hiện trong tuần Day Task Start Date Completion Date Reference 2 - Xây dựng kế hoạch ôn thi; tổng hợp danh sách câu hỏi và nội dung trọng tâm cần xem lại.\n- Đọc kỹ tài liệu mentor cung cấp và điều chỉnh hướng ôn tập cho phù hợp với phạm vi đề thi. 13/10/2025 15/10/2025 https://www.notion.so/Nguy-n-Duy-Hi-u-26b17fef5a7781bf8f71e6846c27ad86 3 - Tiếp tục ôn luyện; dành toàn bộ ngày để xem lại các bài lab và các phần kiến thức thực hành. 13/10/2025 15/10/2025 Same as above 4 - Tìm thêm bài tập và câu hỏi theo dạng giữa kỳ; song song đó xử lý các đầu việc còn lại của dự án. 13/10/2025 15/10/2025 Same as above 5 - Làm việc với các thành viên để xây dựng kiến trúc AWS cho dự án; áp dụng các nguyên tắc thiết kế chuẩn AWS vào bản nháp.\n- Cùng rà soát lại sơ đồ, điều chỉnh các thành phần và chuẩn bị bản gửi mentor phản hồi. 16/10/2025 18/10/2025 https://skillbuilder.aws/ 6 - Nhận phản hồi: kiến trúc hiện tại bị từ chối do sơ đồ chưa đúng chuẩn, dùng icon chưa phù hợp và chi phí dự kiến quá cao.\n- Tổ chức cuộc họp tiếp theo để thu hẹp phạm vi, đề ra hướng thiết kế lại hợp lý hơn và tối ưu chi phí. 16/10/2025 18/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được trong tuần Hoàn thiện kế hoạch ôn thi và định hướng lại nội dung cần tập trung dựa theo hướng dẫn của mentor. Ôn lại các bài lab quan trọng nhằm củng cố kỹ năng thực hành trước kỳ thi. Thu thập thêm tài liệu luyện tập và vẫn đảm bảo tiến độ các task của dự án. Cùng team xây dựng bản kiến trúc AWS ban đầu và ghi nhận đầy đủ phản hồi từ mentor. Nhận diện các vấn đề trong thiết kế (chuẩn sơ đồ, icon, chi phí) → lên kế hoạch chỉnh sửa và tối ưu kiến trúc. "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.7-setup-s3-cloudfront/","title":"5.7 Setup S3 + CloudFront","tags":[],"description":"","content":"Module 7: Create S3 Buckets \u0026amp; CloudFront Distribution Mục tiêu Module Tạo S3 bucket cho frontend Cấu hình bucket properties \u0026amp; policies Tạo CloudFront distribution Setup Origin Access Control (OAC) Configure caching \u0026amp; security Deploy frontend application Test access \u0026amp; cache invalidation Duration: 3-4 giờ\nS3 \u0026amp; CloudFront Overview 2 S3 buckets + 1 CloudFront distribution sẽ được tạo:\nComponent Name Region Purpose S3 Bucket 1 smoking-cessation-frontend us-east-1 Frontend React app hosting S3 Bucket 2 smoking-cessation-backups ap-southeast-1 Database backups \u0026amp; logs CloudFront CF Distribution Global CDN for frontend (edge caching) Phần 1: Create Frontend S3 Bucket Bước 1: Truy cập S3 Console Login vào AWS Console Tìm kiếm \u0026ldquo;S3\u0026rdquo; Click \u0026ldquo;S3\u0026rdquo; service Click \u0026ldquo;Create bucket\u0026rdquo; Bước 2: Configure Bucket Details Bucket name: smoking-cessation-frontend Must be globally unique Use lowercase, hyphens only Region: us-east-1 (required for CloudFront SSL) Object Ownership: ACLs disabled (recommended) Click \u0026ldquo;Create bucket\u0026rdquo; ⏳ Chờ bucket được tạo (vài giây)\nBước 3: Configure Versioning Click vào bucket smoking-cessation-frontend Click \u0026ldquo;Properties\u0026rdquo; tab Scroll down to \u0026ldquo;Versioning\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Check \u0026ldquo;Enable\u0026rdquo; versioning Click \u0026ldquo;Save changes\u0026rdquo; This allows rollback if needed.\nBước 4: Configure Server Access Logging Still in Properties tab Scroll to \u0026ldquo;Server access logging\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Enable logging: ✅ Target bucket: Create new logging bucket Name: smoking-cessation-logs Click \u0026ldquo;Save changes\u0026rdquo; Bước 5: Enable Static Website Hosting Properties tab Scroll to \u0026ldquo;Static website hosting\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Static website hosting: Enable Index document: index.html Error document: index.html (for SPA routing) Click \u0026ldquo;Save changes\u0026rdquo; Bước 6: Block Public Access Click \u0026ldquo;Permissions\u0026rdquo; tab Scroll to \u0026ldquo;Block public access\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; ✅ All 4 options enabled (keep S3 private, CloudFront accesses via OAC) Click \u0026ldquo;Save changes\u0026rdquo; This ensures only CloudFront can access the bucket.\nPhần 2: Create Bucket Policy for CloudFront Access Bước 1: Create Origin Access Control (OAC) CloudFront Console Left menu: \u0026ldquo;Origin access control\u0026rdquo; Click \u0026ldquo;Create origin access control\u0026rdquo; Name: smoking-cessation-oac Origin type: S3 Signing behavior: Sign requests Click \u0026ldquo;Create\u0026rdquo; ⏳ Chờ OAC được tạo\nNote the OAC ID shown (e.g., E7DE5EADPNE96) - you\u0026rsquo;ll need this for the S3 bucket policy.\nBước 2: Create Bucket Policy Go to S3 bucket: smoking-cessation-frontend Click \u0026ldquo;Permissions\u0026rdquo; tab Scroll to \u0026ldquo;Bucket policy\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste this policy (replace OAC_ID with your OAC ID): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontOAC\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::smoking-cessation-frontend/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;DISTRIBUTION_ID\u0026gt;\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo; Note: You\u0026rsquo;ll update the distribution ID after creating CloudFront distribution.\nPhần 3: Create Backups S3 Bucket Bước 1: Create Second Bucket S3 Console Click \u0026ldquo;Create bucket\u0026rdquo; Bucket name: smoking-cessation-backups Region: ap-southeast-1 (same as databases) Click \u0026ldquo;Create bucket\u0026rdquo; Bước 2: Configure Backup Bucket Click into bucket Properties tab Versioning: Enable (to keep backup history) Encryption: Use server-side encryption Type: AES-256 Click \u0026ldquo;Save changes\u0026rdquo; Bước 3: Create Lifecycle Policy (Optional) To archive old backups after 30 days:\nManagement tab Click \u0026ldquo;Create lifecycle rule\u0026rdquo; Rule name: archive-old-backups Scope: Apply to all objects Transitions: Transition to Glacier: 30 days Expiration: Delete after 90 days Click \u0026ldquo;Create rule\u0026rdquo; Phần 4: Create CloudFront Distribution Bước 1: Go to CloudFront Console Tìm kiếm \u0026ldquo;CloudFront\u0026rdquo; Click \u0026ldquo;CloudFront\u0026rdquo; service Click \u0026ldquo;Create distribution\u0026rdquo; Bước 2: Configure Origin Origin domain: Select smoking-cessation-frontend.s3.us-east-1.amazonaws.com S3 access: Enable Origin Access Control (OAC) Select: smoking-cessation-oac (created in Phần 2) HTTP version: HTTP/2 and HTTP/1.1 Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Default Cache Behavior Viewer protocol policy: Redirect HTTP to HTTPS Allowed HTTP methods: GET, HEAD, OPTIONS Cache policy: CachingOptimized (recommended) TTL: 86400 seconds (1 day) for HTML TTL: 31536000 seconds (1 year) for assets (js, css) Compress objects automatically: ✅ Click \u0026ldquo;Next\u0026rdquo; Bước 4: Configure Distribution Settings Enabled: ✅ Default root object: index.html Standard logging: Disabled (use CloudWatch instead) IPv6: ✅ Enabled Comment: Smoking Cessation Frontend CDN Click \u0026ldquo;Create distribution\u0026rdquo; ⏳ Chờ distribution được tạo \u0026amp; deployed (5-10 phút)\nDeployment status will show \u0026ldquo;In Progress\u0026rdquo; → \u0026ldquo;Deployed\u0026rdquo;\nBước 5: Note CloudFront Details After deployment, note:\nDistribution ID: (e.g., E1NREZDKTJH6Y9) Domain name: (e.g., d2yo2hr161ib8h.cloudfront.net) CNAME: (if custom domain configured) Phần 5: Update S3 Bucket Policy with Distribution ID Bước 1: Get Distribution ARN CloudFront console Select your distribution Copy Distribution ID Bước 2: Update Bucket Policy Go to S3 bucket: smoking-cessation-frontend Permissions → Bucket policy Update the policy with your Distribution ID: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontOAC\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::smoking-cessation-frontend/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;YOUR_DISTRIBUTION_ID\u0026gt;\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo; Phần 6: Configure Custom Domain (Optional) Bước 1: Request ACM Certificate Important: ACM certificate must be in us-east-1 region for CloudFront!\nSwitch region to us-east-1 (top right) Tìm kiếm \u0026ldquo;ACM\u0026rdquo; Click \u0026ldquo;Certificate Manager\u0026rdquo; Click \u0026ldquo;Request certificate\u0026rdquo; Certificate type: Public certificate Domain names: yourdomain.com *.yourdomain.com Validation method: DNS Click \u0026ldquo;Request\u0026rdquo; ⏳ Chờ certificate được issued\nYou\u0026rsquo;ll need to validate via DNS CNAME records.\nBước 2: Validate Certificate (DNS Method) Go back to ACM certificates Click on your certificate Click \u0026ldquo;Create records in Route 53\u0026rdquo; (if using Route 53) Or manually add CNAME records to your DNS provider Bước 3: Add Custom Domain to CloudFront Once certificate is validated:\nGo to CloudFront distribution Click \u0026ldquo;Edit\u0026rdquo; Alternate domain names (CNAMEs): yourdomain.com www.yourdomain.com Custom SSL certificate: Select your ACM certificate Click \u0026ldquo;Save changes\u0026rdquo; Bước 4: Update DNS Records Route 53 or external DNS provider Create CNAME records: yourdomain.com → d2yo2hr161ib8h.cloudfront.net www.yourdomain.com → d2yo2hr161ib8h.cloudfront.net Wait for DNS propagation (up to 24 hours) Phần 7: Configure CORS for S3 (If Needed) Bước 1: Enable CORS S3 bucket: smoking-cessation-frontend Permissions tab Scroll to \u0026ldquo;CORS\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste CORS configuration: [ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;Authorization\u0026#34;, \u0026#34;Content-Length\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;https://yourdomain.com\u0026#34;, \u0026#34;https://www.yourdomain.com\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;ETag\u0026#34; ], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] Click \u0026ldquo;Save changes\u0026rdquo; Phần 8: Build \u0026amp; Deploy Frontend Bước 1: Build React Application On your local machine:\n# Navigate to frontend directory cd /path/to/frontend # Install dependencies npm install # Build production npm run build # Output in dist/ or build/ folder Bước 2: Upload to S3 Option A: Using AWS CLI\n# Configure AWS credentials aws configure # Sync build folder to S3 aws s3 sync dist/ s3://smoking-cessation-frontend/ --delete # Set index.html to not cache aws s3 cp s3://smoking-cessation-frontend/index.html s3://smoking-cessation-frontend/index.html \\ --metadata-directive REPLACE \\ --cache-control \u0026#34;max-age=0, no-cache, no-store, must-revalidate\u0026#34; Option B: Using S3 Console\nS3 bucket: smoking-cessation-frontend Click \u0026ldquo;Upload\u0026rdquo; Select all files from dist/ folder Click \u0026ldquo;Upload\u0026rdquo; Bước 3: Verify Files Uploaded S3 bucket content Should see: index.html assets/ *.js, *.css files Other static files Phần 9: Test Frontend Access Bước 1: Test CloudFront URL Open browser Navigate to https://\u0026lt;your-cloudfront-domain\u0026gt;.cloudfront.net Should see your React application loading Bước 2: Test Custom Domain (If Configured) Navigate to https://yourdomain.com Verify page loads properly Check browser console for no errors Bước 3: Test SPA Routing Navigate to an invalid path (e.g., /invalid) Should show 404 from your React app (not AWS 404) This confirms index.html error document is working Bước 4: Check HTTPS Certificate Click lock icon in browser Verify certificate is valid Hostname matches your domain Phần 10: Setup Cache Invalidation Bước 1: Create Invalidation via Console When you deploy new code:\nCloudFront distribution \u0026ldquo;Invalidations\u0026rdquo; tab Click \u0026ldquo;Create invalidation\u0026rdquo; Object paths: /* /index.html Click \u0026ldquo;Create invalidation\u0026rdquo; ⏳ Chờ invalidation hoàn thành (2-3 phút)\nBước 2: Automate Invalidation (Optional) Create a deployment script:\n#!/bin/bash # deploy.sh # Build npm run build # Upload to S3 aws s3 sync dist/ s3://smoking-cessation-frontend/ --delete # Invalidate CloudFront aws cloudfront create-invalidation \\ --distribution-id E1NREZDKTJH6Y9 \\ --paths \u0026#34;/*\u0026#34; echo \u0026#34;Deployment complete!\u0026#34; Make executable:\nchmod +x deploy.sh # Run deployment ./deploy.sh Phần 11: Configure Security Headers Bước 1: Add Response Headers via CloudFront CloudFront distribution \u0026ldquo;Behaviors\u0026rdquo; tab Click default behavior Edit → \u0026ldquo;Response headers policy\u0026rdquo; Select or create custom policy: X-Frame-Options: DENY X-Content-Type-Options: nosniff X-XSS-Protection: 1; mode=block Strict-Transport-Security: max-age=31536000; includeSubDomains Content-Security-Policy: default-src \u0026lsquo;self\u0026rsquo; Click \u0026ldquo;Save changes\u0026rdquo; Bước 2: Add Cache Key Policy For optimal caching:\nBehaviors tab Click default behavior Edit → \u0026ldquo;Cache key and origin requests\u0026rdquo; Cache policy: CachingOptimized Origin request policy: All ViewerExcept CloudFront-Authorization Click \u0026ldquo;Save changes\u0026rdquo; Phần 12: Setup Monitoring \u0026amp; Logging Bước 1: Enable CloudFront Metrics CloudFront distribution \u0026ldquo;Monitoring\u0026rdquo; tab View metrics: Requests (total per time period) Data transferred (GB) Cache hit rate (%) 4xx/5xx error rate Default metrics available (no extra cost) Bước 2: Create CloudWatch Alarms For 4xx errors:\nCloudWatch console \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;Create alarm\u0026rdquo; Metric: Namespace: CloudFront Metric: 4xxErrorRate Distribution: Your distribution Conditions: Statistic: Average Period: 5 minutes Threshold: \u0026gt; 5% Notification: Create SNS topic Topic name: smoking-cessation-alerts Email: your@email.com Click \u0026ldquo;Create alarm\u0026rdquo; Verify SNS subscription via email Bước 3: Create CloudFront Dashboard CloudWatch → Dashboards \u0026ldquo;Create dashboard\u0026rdquo; Name: smoking-cessation-cdn Add widgets: CloudFront requests Bytes transferred Cache hit rate Error rates (4xx/5xx) Save dashboard Environment Variables \u0026amp; URLs Save these URLs:\n# Frontend URLs FRONTEND_CLOUDFRONT_URL=https://d2yo2hr161ib8h.cloudfront.net FRONTEND_CUSTOM_DOMAIN=https://yourdomain.com FRONTEND_BUCKET=smoking-cessation-frontend FRONTEND_DISTRIBUTION_ID=E1NREZDKTJH6Y9 # Backup S3 BACKUPS_BUCKET=smoking-cessation-backups Checklist Frontend S3 bucket created (smoking-cessation-frontend) Versioning enabled on frontend bucket Static website hosting enabled Public access blocked Backup S3 bucket created (smoking-cessation-backups) Lifecycle policy configured for backups Origin Access Control (OAC) created CloudFront distribution created S3 bucket policy configured with Distribution ID Frontend built \u0026amp; uploaded to S3 CloudFront URL accessible via HTTPS Custom domain configured (optional) ACM certificate issued \u0026amp; validated CORS configured if needed Security headers configured Cache invalidation tested CloudWatch monitoring enabled CloudWatch alarms created CloudWatch dashboard created Sẵn sàng cho Module 8 (Create VPC \u0026amp; Security) Troubleshooting CloudFront Shows 403 Forbidden Issue: Getting 403 error when accessing via CloudFront\nSolution:\nVerify S3 bucket policy is correct with Distribution ID Verify OAC is properly configured Check CloudFront distribution status (must be \u0026ldquo;Deployed\u0026rdquo;) Wait 5 minutes for changes to propagate Try cache invalidation: /* Files Return 404 from S3 Issue: Some files return 404 when accessed directly\nSolution:\nEnsure all files were uploaded to S3 Check file permissions (should be private) Verify index.html exists For SPA, ensure error document is index.html SPA Routes Don\u0026rsquo;t Work Issue: Navigating to /dashboard returns 404\nSolution:\nVerify error document is set to index.html This allows React Router to handle routing Invalidate CloudFront cache: /* Browser cache: Hard refresh (Ctrl+Shift+R or Cmd+Shift+R) Slow Content Delivery Issue: Pages loading slowly\nSolution:\nEnable compression in CloudFront (gzip, brotli) Check cache policy TTL Verify assets are in /assets folder Monitor CloudFront metrics for cache hit ratio Consider adding more edge locations (available in pricing) DNS Resolution Issues Issue: Custom domain not resolving\nSolution:\nVerify DNS records created in Route 53 Check CNAME points to CloudFront domain Verify ACM certificate is issued \u0026amp; validated Wait for DNS TTL propagation (up to 24 hours) Use nslookup yourdomain.com to test Cost Analysis Monthly costs estimate:\nS3 storage: ~$0.50 (100GB frontend + backups) S3 data transfer: ~$2 (to CloudFront) CloudFront: ~$2-5 (based on traffic) Cache invalidation: ~$0.10 (20 invalidations) Total: ~$5-8/month (very economical!) Cost optimization:\nUse CloudFront TTL effectively (less invalidations) Compress objects in S3 Use S3 lifecycle policies for backups Next Steps Integrate frontend with API Gateway endpoints (Module 5) Setup authentication flow with Cognito (Module 3) Configure error boundaries in React Setup analytics (Google Analytics optional) Monitor CloudFront performance metrics Kết Quả Đạt Được Sau Module 7, bạn sẽ có:\n✅ Frontend S3 bucket created \u0026amp; configured ✅ Backup S3 bucket created with lifecycle policy ✅ Origin Access Control configured ✅ CloudFront distribution deployed globally ✅ HTTPS/SSL certificates configured ✅ Custom domain configured (optional) ✅ Frontend application deployed \u0026amp; accessible ✅ Cache invalidation setup ✅ Security headers configured ✅ CORS configuration applied ✅ CloudWatch monitoring \u0026amp; alarms configured ✅ CDN optimized for performance ✅ Sẵn sàng cho Module 8 (Create VPC \u0026amp; Security) "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/7-feedback/","title":"Chia sẻ &amp; Đóng góp Ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nKhông gian làm việc tại FCJ tạo cảm giác thân thiện và rất dễ hòa nhập. Các anh chị trong công ty luôn hỗ trợ nhiệt tình mỗi khi mình gặp khó khăn, kể cả ngoài giờ làm. Bàn làm việc và khu vực văn phòng được bố trí ngăn nắp, đầy đủ các tiện ích như ổ điện , máy lạnh ,máy chiếu.. 2. Sự hỗ trợ từ mentor / team admin\nMentor hướng dẫn rõ ràng, giải thích chi tiết các vấn đề kỹ thuật và khuyến khích mình tự tìm hiểu trước khi đưa ra lời giải. Điều này giúp mình rèn luyện khả năng tự học . Team admin hỗ trợ nhanh trong các thủ tục, tài liệu và luôn tạo điều kiện thuận lợi cho thực tập sinh.\n3. Mức độ phù hợp giữa công việc và chuyên ngành\nNhững nhiệm vụ mình đảm nhận phù hợp với kiến thức đã học tại trường và đồng thời mở rộng thêm nhiều kỹ năng mới như cloud computing, serverless và kiến trúc hệ thống. Nhờ vậy, mình vừa có thể củng cố kiến thức nền tảng, vừa tích lũy thêm kinh nghiệm thực tế.\n4. Cơ hội học hỏi và phát triển\nTrong suốt kỳ thực tập, mình có cơ hội rèn luyện nhiều kỹ năng quan trọng: sử dụng các dịch vụ AWS, làm việc nhóm, trao đổi kỹ thuật và báo cáo tiến độ, các buổi event chia sẽ các kiến thức vô cùng bổ ích. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình có định hướng rõ hơn trong việc phát triển sự nghiệp sau này.\n5. Văn hóa và tinh thần đồng đội\nTrong thời gian thực tập, điều khiến mình ấn tượng nhất là văn hóa hỗ trợ lẫn nhau của FCJ. Mọi người luôn sẵn sàng chia sẻ kinh nghiệm, góp ý chân thành và đồng hành cùng nhau khi xử lý công việc khó. Không có khoảng cách giữa thực tập sinh và nhân viên chính thức; ai cũng được lắng nghe và tôn trọng như nhau. Khi dự án bước vào giai đoạn gấp rút, cả team phối hợp nhịp nhàng, chia sẻ công việc và động viên nhau để hoàn thành mục tiêu chung. Nhờ vậy, mình cảm thấy rất thoải mái khi làm việc và thực sự xem đội nhóm như một tập thể mà mình thuộc về. 6. Chính sách dành cho thực tập sinh\nCông ty có lịch làm việc linh hoạt, giúp mình dễ dàng cân bằng giữa việc học và công việc.Ngoài ra trong các buổi tham dự sự kiện luôn có quà dành cho sinh viên tham gia giúp tạo không gian gần gũi vừa được học vừa được thưởng.\nĐề xuất \u0026amp; Mong muốn Điểm mình hài lòng nhất là chính sách làm việc linh hoạt, cho phép thực tập sinh tự lựa chọn ngày lên văn phòng. Điều này mang lại sự thoải mái và giúp mình dễ dàng duy trì hiệu quả học tập lẫn công việc.\nĐây là một môi trường rất phù hợp cho sinh viên ngành CNTT. Vì vậy, mình hoàn toàn sẵn lòng giới thiệu AWS/FCJ cho bạn bè để có cơ hội trải nghiệm và học hỏi thêm những kiến thức thực tế về cloud computing mà chương trình học ở trường chưa đề cập sâu.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.8-setup-vpc-security/","title":"Setup VPC &amp; Security","tags":[],"description":"","content":"Module 8: Create VPC, Subnets, Security Groups \u0026amp; NLB Mục tiêu Module Tạo VPC mới từ đầu Tạo public \u0026amp; private subnets Cấu hình Internet Gateway \u0026amp; NAT Gateway Tạo 3 Security Groups Tạo Network Load Balancer (NLB) cho WebSocket Cấu hình IAM policies Setup VPC Flow Logs \u0026amp; security monitoring Duration: 4-5 giờ\nVPC \u0026amp; Network Overview VPC architecture sẽ được tạo ở ap-southeast-1:\nVPC: smoking-cessation-vpc (172.0.0.0/16) ├── Public Subnets (Internet-facing) │ ├── ap-southeast-1a: 172.0.0.0/24 │ └── ap-southeast-1b: 172.0.1.0/24 ├── Private Subnets (Database \u0026amp; Lambda) │ ├── ap-southeast-1a: 172.0.10.0/24 │ ├── ap-southeast-1b: 172.0.11.0/24 │ └── ap-southeast-1c: 172.0.12.0/24 ├── Internet Gateway: smoking-igw ├── NAT Gateway: smoking-nat (in public subnet) ├── NLB: smoking-nlb (WebSocket endpoint) └── 3 Security Groups: ├── smoking-nlb-sg (NLB) ├── smoking-app-sg (EC2 Applications) └── smoking-db-sg (EC2 Databases) Phần 1: Create VPC Bước 1: Truy cập VPC Console Login vào AWS Console Tìm kiếm \u0026ldquo;VPC\u0026rdquo; Click \u0026ldquo;VPC\u0026rdquo; service Chọn region: ap-southeast-1 Click \u0026ldquo;Create VPC\u0026rdquo; Bước 2: Configure VPC Details Name tag: smoking-cessation-vpc IPv4 CIDR block: 172.0.0.0/16 Đủ lớn cho tất cả subnets (65,536 addresses) IPv6 CIDR block: Leave empty Tenancy: Default Click \u0026ldquo;Create VPC\u0026rdquo; ⏳ Chờ VPC được tạo (vài giây)\nBước 3: Note VPC Details Sau khi tạo, note:\nVPC ID: (e.g., vpc-049ff1c1372e1f3b8) VPC CIDR: 172.0.0.0/16 Phần 2: Create Internet Gateway Bước 1: Create IGW VPC Console Left menu: \u0026ldquo;Internet Gateways\u0026rdquo; Click \u0026ldquo;Create Internet gateway\u0026rdquo; Name: smoking-igw Click \u0026ldquo;Create internet gateway\u0026rdquo; ⏳ Chờ IGW được tạo\nBước 2: Attach IGW to VPC Click vào IGW vừa tạo Click \u0026ldquo;Attach to VPC\u0026rdquo; Select VPC: smoking-cessation-vpc Click \u0026ldquo;Attach internet gateway\u0026rdquo; Phần 3: Create Subnets Bước 1: Create Public Subnet 1a VPC Console Left menu: \u0026ldquo;Subnets\u0026rdquo; Click \u0026ldquo;Create subnet\u0026rdquo; VPC ID: smoking-cessation-vpc Subnet name: smoking-public-1a Availability Zone: ap-southeast-1a IPv4 CIDR block: 172.0.0.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Bước 2: Create Public Subnet 1b Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-public-1b Availability Zone: ap-southeast-1b IPv4 CIDR block: 172.0.1.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Bước 3: Create Private Subnet 1a Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1a Availability Zone: ap-southeast-1a IPv4 CIDR block: 172.0.10.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Bước 4: Create Private Subnet 1b Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1b Availability Zone: ap-southeast-1b IPv4 CIDR block: 172.0.11.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Bước 5: Create Private Subnet 1c Click \u0026ldquo;Create subnet\u0026rdquo; Subnet name: smoking-private-1c Availability Zone: ap-southeast-1c IPv4 CIDR block: 172.0.12.0/24 Click \u0026ldquo;Create subnet\u0026rdquo; Result: 5 subnets created (2 public + 3 private)\nPhần 4: Create \u0026amp; Configure Route Tables Bước 1: Create Public Route Table Left menu: \u0026ldquo;Route tables\u0026rdquo; Click \u0026ldquo;Create route table\u0026rdquo; Name: smoking-public-rt VPC: smoking-cessation-vpc Click \u0026ldquo;Create route table\u0026rdquo; Bước 2: Add Internet Gateway Route to Public RT Click vào public route table \u0026ldquo;Routes\u0026rdquo; tab → \u0026ldquo;Edit routes\u0026rdquo; Click \u0026ldquo;Add route\u0026rdquo; Destination: 0.0.0.0/0 Target: Internet Gateway → smoking-igw Click \u0026ldquo;Save routes\u0026rdquo; Bước 3: Associate Public RT with Public Subnets \u0026ldquo;Subnet associations\u0026rdquo; tab → \u0026ldquo;Edit subnet associations\u0026rdquo; Select: smoking-public-1a smoking-public-1b Click \u0026ldquo;Save associations\u0026rdquo; Bước 4: Create Private Route Table Click \u0026ldquo;Create route table\u0026rdquo; Name: smoking-private-rt VPC: smoking-cessation-vpc Click \u0026ldquo;Create route table\u0026rdquo; Bước 5: Associate Private RT with Private Subnets Click vào private route table \u0026ldquo;Subnet associations\u0026rdquo; → \u0026ldquo;Edit subnet associations\u0026rdquo; Select: smoking-private-1a smoking-private-1b smoking-private-1c Click \u0026ldquo;Save associations\u0026rdquo; Note: Private subnets route traffic via NAT Gateway (will configure after NAT is created)\nPhần 5: Create NAT Gateway Bước 1: Create Elastic IP for NAT Left menu: \u0026ldquo;Elastic IPs\u0026rdquo; Click \u0026ldquo;Allocate Elastic IP address\u0026rdquo; Region: ap-southeast-1 Click \u0026ldquo;Allocate\u0026rdquo; Note the Elastic IP address Bước 2: Create NAT Gateway Left menu: \u0026ldquo;NAT Gateways\u0026rdquo; Click \u0026ldquo;Create NAT gateway\u0026rdquo; Name: smoking-nat Subnet: smoking-public-1a (place in public subnet) Elastic IP allocation ID: Select the IP created in Bước 1 Click \u0026ldquo;Create NAT gateway\u0026rdquo; ⏳ Chờ NAT Gateway được tạo (1-2 phút)\nBước 3: Add NAT Gateway Route to Private RT Go to \u0026ldquo;Route tables\u0026rdquo; Click private route table: smoking-private-rt \u0026ldquo;Routes\u0026rdquo; tab → \u0026ldquo;Edit routes\u0026rdquo; Click \u0026ldquo;Add route\u0026rdquo; Destination: 0.0.0.0/0 Target: NAT Gateway → smoking-nat Click \u0026ldquo;Save routes\u0026rdquo; Now private subnets can reach internet via NAT Gateway.\nPhần 6: Create Security Groups Bước 1: Create NLB Security Group Left menu: \u0026ldquo;Security Groups\u0026rdquo; Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-nlb-sg Description: Security group for Network Load Balancer VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: Click vào SG vừa tạo \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: HTTPS (443) Source: 0.0.0.0/0 (allow all for WebSocket) Type: HTTP (80) Source: 0.0.0.0/0 (for redirect to HTTPS) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Default allows all traffic ✅ Bước 2: Create Application Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-app-sg Description: Security group for application servers VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: Custom TCP 8000 Source: smoking-nlb-sg (allow from NLB) Type: Custom TCP 22 (SSH) Source: My IP or 0.0.0.0/0 (for admin access) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Allow all traffic to private subnets \u0026amp; databases Bước 3: Create Database Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-db-sg Description: Security group for database servers VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: PostgreSQL (5432) Source: smoking-app-sg (allow from app servers) Type: Custom TCP 27017 (MongoDB) Source: smoking-app-sg (allow from app servers) Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Default allows all ✅ Result: 3 security groups created with proper rules\nPhần 7: Create Network Load Balancer Bước 1: Go to Load Balancers Left menu: \u0026ldquo;Load Balancers\u0026rdquo; (under EC2) Click \u0026ldquo;Create load balancer\u0026rdquo; Select Network Load Balancer Click \u0026ldquo;Create\u0026rdquo; Bước 2: Configure NLB Basic Settings Name: smoking-nlb Scheme: Internet-facing (accessible from internet) IP address type: IPv4 VPC: smoking-cessation-vpc Subnets: - Select both public subnets: smoking-public-1a, smoking-public-1b Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure Security Groups Security groups: Select smoking-nlb-sg Click \u0026ldquo;Next\u0026rdquo; Bước 4: Configure Listeners and Routing Protocol: TCP Port: 443 (HTTPS for WebSocket) Default action: Forward to target group Click \u0026ldquo;Create target group\u0026rdquo; Create Target Group: Name: smoking-ws-targets Protocol: TCP Port: 8000 (where apps listen) VPC: smoking-cessation-vpc Health check: - Protocol: TCP - Port: 8000 - Interval: 30 seconds - Healthy threshold: 2 Click \u0026ldquo;Create\u0026rdquo; Bước 5: Register Targets After target group created, add targets: - Application instances (smoking-app-user, smoking-app-social) - Port: 8000 Click \u0026ldquo;Register targets\u0026rdquo; Bước 6: Review \u0026amp; Create Review all settings Click \u0026ldquo;Create load balancer\u0026rdquo; ⏳ Chờ NLB được tạo \u0026amp; deployed (3-5 phút)\nNote the NLB DNS name: (e.g., smoking-nlb-123456.elb.ap-southeast-1.amazonaws.com)\nPhần 8: Configure NLB with HTTPS/TLS (Optional) Bước 1: Request ACM Certificate Tìm kiếm \u0026ldquo;ACM\u0026rdquo; (Certificate Manager) Click \u0026ldquo;Request certificate\u0026rdquo; Domain names: yourdomain.com (if custom domain) Or use NLB DNS name Validation method: DNS Click \u0026ldquo;Request\u0026rdquo; Bước 2: Create HTTPS Listener Go to NLB \u0026ldquo;Listeners\u0026rdquo; tab → \u0026ldquo;Add listener\u0026rdquo; Protocol: TLS Port: 443 Default action: Forward to target group smoking-ws-targets SSL certificate: Select ACM certificate Click \u0026ldquo;Add\u0026rdquo; Bước 3: Create HTTP → HTTPS Redirect (Optional) Add another listener: Protocol: TCP Port: 80 Default action: Redirect to port 443 (HTTPS) Phần 9: Configure IAM Policies for Lambda VPC Access Bước 1: Update Lambda Execution Role Lambda functions kết nối database cần IAM permissions:\nGo to IAM Console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Select \u0026ldquo;JSON\u0026rdquo; tab Paste policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:DescribeNetworkInterfaces\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:AssignPrivateIpAddresses\u0026#34;, \u0026#34;ec2:UnassignPrivateIpAddresses\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-southeast-1:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:ap-southeast-1:*:secret:smoking-cessation/*\u0026#34; } ] } Click \u0026ldquo;Review policy\u0026rdquo; Policy name: lambda-vpc-policy Click \u0026ldquo;Create policy\u0026rdquo; Bước 2: Configure Lambda Functions for VPC For each Lambda function that accesses databases:\nGo to Lambda Console Click function name Click \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;VPC\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; VPC: smoking-cessation-vpc Subnets: Select private subnets smoking-private-1a smoking-private-1b Security groups: smoking-app-sg Click \u0026ldquo;Save\u0026rdquo; This allows Lambda to access EC2 database instances.\nPhần 10: Setup VPC Flow Logs Bước 1: Enable VPC Flow Logs Go to VPC Console Click \u0026ldquo;VPCs\u0026rdquo; Select smoking-cessation-vpc Click \u0026ldquo;Flow logs\u0026rdquo; tab Click \u0026ldquo;Create flow log\u0026rdquo; Bước 2: Configure Flow Logs Name: smoking-vpc-flow-logs Traffic type: All (capture all traffic) Log destination: CloudWatch Logs Log group name: /aws/vpc/smoking-cessation-vpc IAM role: Create new role Role name: vpc-flow-logs-role Click \u0026ldquo;Create flow log\u0026rdquo; ⏳ Chờ flow logs được enabled\nNow all VPC traffic will be logged to CloudWatch!\nPhần 11: Enable GuardDuty (Threat Detection) Bước 1: Enable GuardDuty Tìm kiếm \u0026ldquo;GuardDuty\u0026rdquo; Click \u0026ldquo;GuardDuty\u0026rdquo; service Click \u0026ldquo;Enable GuardDuty\u0026rdquo; Read and confirm disclaimer Click \u0026ldquo;Enable GuardDuty\u0026rdquo; ⏳ Chờ GuardDuty được enabled (vài phút)\nGuardDuty will analyze VPC Flow Logs for threats.\nPhần 12: Test Network Connectivity Bước 1: Test Public Subnet Connectivity From an EC2 instance in public subnet:\n# Test internet connectivity ping 8.8.8.8 # Check routing table route -n # Should see: # Destination Gateway # 172.0.0.0/16 0.0.0.0 (local) # 0.0.0.0/0 Internet Gateway Bước 2: Test Private Subnet Connectivity From an EC2 instance in private subnet:\n# Test NAT Gateway (internet via NAT) curl https://ip.nslookup.com # Test database connectivity psql -h \u0026lt;DB_IP\u0026gt; -U postgres -d smoking_cessation # Test MongoDB mongosh --host \u0026lt;MONGO_IP\u0026gt;:27017 Bước 3: Test Security Group Rules # From app server, test database access nc -zv \u0026lt;POSTGRES_IP\u0026gt; 5432 # Should be successful nc -zv \u0026lt;MONGO_IP\u0026gt; 27017 # Should be successful # From internet, try SSH to app server ssh -i key.pem ec2-user@\u0026lt;NLB_DNS\u0026gt; # May timeout (not open for SSH) Environment Variables \u0026amp; Networking Info Save these for future use:\n# VPC VPC_ID=vpc-046dc916dde2fb93f VPC_CIDR=172.0.0.0/16 # Subnets PUBLIC_SUBNET_1A=subnet-xxx PUBLIC_SUBNET_1B=subnet-xxx PRIVATE_SUBNET_1A=subnet-xxx PRIVATE_SUBNET_1B=subnet-xxx PRIVATE_SUBNET_1C=subnet-xxx # Gateways IGW_ID=igw-xxx NAT_EIP=\u0026lt;elastic-ip\u0026gt; NAT_GW_ID=nat-xxx # Security Groups NLB_SG_ID=sg-xxx APP_SG_ID=sg-xxx DB_SG_ID=sg-xxx # Load Balancer NLB_DNS=smoking-nlb-123456.elb.ap-southeast-1.amazonaws.com NLB_ARN=arn:aws:elasticloadbalancing:ap-southeast-1:xxx Checklist VPC created (smoking-cessation-vpc) 5 subnets created (2 public + 3 private) Internet Gateway created \u0026amp; attached Public route table created \u0026amp; configured NAT Gateway created Private route table created \u0026amp; configured with NAT 3 Security Groups created (NLB, App, DB) Security Group rules configured Network Load Balancer created Target group configured with health checks Application targets registered with NLB HTTPS/TLS listener configured (optional) Lambda functions configured for VPC access Lambda IAM policy updated VPC Flow Logs enabled GuardDuty enabled Network connectivity tested Database access from apps verified Sẵn sàng cho Module 9 (CloudWatch Monitoring) Troubleshooting Instances Cannot Access Internet Issue: Private subnet instance cannot reach internet\nSolution:\nVerify NAT Gateway is running (not failed) Check private route table has NAT route: 0.0.0.0/0 → NAT Gateway Verify Elastic IP is allocated Check security group outbound rules Lambda Cannot Connect to Database Issue: Lambda timeout when connecting to database\nSolution:\nVerify Lambda is in VPC with private subnets Check database security group allows inbound from app SG Verify database instances have correct SG Test from EC2 instance first to isolate issue Check database is actually running NLB Health Checks Failing Issue: Target instances marked unhealthy\nSolution:\nVerify target group health check port: 8000 Verify application listening on port 8000 Check security group (NLB-SG → App-SG) allows traffic SSH to instance and test: curl http://localhost:8000/health Check application logs for errors Cost Analysis VPC costs (mostly free, some charges):\nVPC: Free Subnets: Free IGW: Free NAT Gateway: ~$32/month (data processing charge) NLB: ~$16/month (hourly) + $0.006 per LCU VPC Flow Logs: ~$5/month (CloudWatch Logs storage) Total: ~$50-60/month Next Steps Connect EC2 instances to NLB targets Setup auto-scaling groups (optional) Configure CloudFront to front NLB (optional) Setup WAF for NLB (optional) Monitor with CloudWatch (Module 9) Kết Quả Đạt Được Sau Module 8, bạn sẽ có:\n✅ VPC created với CIDR 172.0.0.0/16 ✅ 5 subnets (2 public + 3 private) ✅ Internet Gateway attached ✅ NAT Gateway for private subnet internet access ✅ Public \u0026amp; private route tables configured ✅ 3 Security Groups with proper rules ✅ Network Load Balancer operational ✅ Lambda functions integrated with VPC ✅ VPC Flow Logs capturing all traffic ✅ GuardDuty monitoring for threats ✅ Network security fully configured ✅ Sẵn sàng cho Module 9 (CloudWatch Monitoring \u0026amp; Alarms) "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.9-monitoring-logging/","title":"Monitoring &amp; Logging","tags":[],"description":"","content":"Module 9: Setup CloudWatch Monitoring, Logging \u0026amp; Alerts Mục tiêu Module Tạo CloudWatch Log Groups cho tất cả services Tạo CloudWatch Dashboard để theo dõi metrics Tạo CloudWatch Alarms với SNS notifications Enable CloudTrail cho audit logging Enable X-Ray distributed tracing Setup Cost Monitoring \u0026amp; Budget Alerts Tạo CloudWatch Synthetics (health checks) Document incident response runbooks Duration: 3-4 giờ\nMonitoring \u0026amp; Observability Architecture Infrastructure monitoring sẽ cover:\nCloudWatch Monitoring: ├── Logs (CloudWatch Logs) │ ├── /aws/lambda/functions │ ├── /aws/apigateway/apis │ ├── /aws/ec2/databases │ ├── /aws/vpc/flow-logs │ └── /aws/s3/access-logs ├── Metrics \u0026amp; Dashboards │ ├── EC2 (CPU, Network, Disk) │ ├── Lambda (Invocations, Errors, Duration) │ ├── API Gateway (Requests, Errors, Latency) │ ├── CloudFront (Requests, Cache Hit Rate) │ └── NLB (Connections, Target Health) ├── Alarms (SNS Notifications) │ ├── High error rates │ ├── High latency │ ├── Resource exhaustion │ └── Cost anomalies └── Audit Trail ├── CloudTrail (API calls) └── X-Ray (Request tracing) Phần 1: Create CloudWatch Log Groups Bước 1: Create Lambda Log Groups CloudWatch Console Left menu: \u0026ldquo;Logs\u0026rdquo; → \u0026ldquo;Log groups\u0026rdquo; Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/lambda/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; ⏳ Chờ log group được tạo\nNote: Lambda functions automatically create their own log streams, but creating parent log group allows custom configuration\nBước 2: Create API Gateway Log Groups Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/apigateway/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; Bước 3: Create EC2 Databases Log Groups Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/ec2/databases Click \u0026ldquo;Create log group\u0026rdquo; Bước 4: Create VPC Flow Logs Group Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/vpc/flow-logs Click \u0026ldquo;Create log group\u0026rdquo; Bước 5: Create CloudFront Log Groups (Optional) Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/cloudfront/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; Result: 5 log groups created for centralized logging\nBước 6: Configure Log Retention Policies For each log group:\nClick on log group name Actions → \u0026ldquo;Edit retention settings\u0026rdquo; Retention: 30 days Balances cost vs. historical data Click \u0026ldquo;Save\u0026rdquo; This prevents logs from consuming unlimited storage.\nPhần 2: Create CloudWatch Dashboard Bước 1: Create Dashboard CloudWatch Console Left menu: \u0026ldquo;Dashboards\u0026rdquo; Click \u0026ldquo;Create dashboard\u0026rdquo; Dashboard name: smoking-cessation-monitoring Click \u0026ldquo;Create dashboard\u0026rdquo; ⏳ Chờ dashboard được tạo\nBước 2: Add Lambda Metrics Widget Click \u0026ldquo;Add widget\u0026rdquo; Choose Line chart Metric selection: Namespace: AWS/Lambda Metric: Invocations Statistics: Sum Add multiple metrics: Invocations Duration (Average) Errors (Sum) Throttles (Sum) Widget name: Lambda Performance Click \u0026ldquo;Create widget\u0026rdquo; Bước 3: Add API Gateway Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/ApiGateway Metrics: Count (total requests) 4XXError 5XXError Latency (p99) Widget name: API Gateway Metrics Click \u0026ldquo;Create widget\u0026rdquo; Bước 4: Add EC2 Database Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/EC2 Filter by instances: DB-PG, DB-Mongo Metrics: CPUUtilization NetworkPacketsIn NetworkPacketsOut DiskReadBytes Widget name: Database Performance Click \u0026ldquo;Create widget\u0026rdquo; Bước 5: Add CloudFront Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Number widget Metric selection: Namespace: AWS/CloudFront Metrics: Requests (Sum) BytesDownloaded CacheHitRate 4xxErrorRate 5xxErrorRate Widget name: CDN Performance Click \u0026ldquo;Create widget\u0026rdquo; Bước 6: Add NLB Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/NetworkELB Metrics: ActiveFlowCount HealthyHostCount UnHealthyHostCount ProcessedBytes Widget name: Load Balancer Health Click \u0026ldquo;Create widget\u0026rdquo; Bước 7: Configure Dashboard Settings Dashboard settings (gear icon) Auto-refresh: 1 minute Save dashboard Now you have a real-time monitoring dashboard!\nPhần 3: Create SNS Topic for Notifications Bước 1: Create SNS Topic Tìm kiếm \u0026ldquo;SNS\u0026rdquo; Click \u0026ldquo;SNS\u0026rdquo; service Left menu: \u0026ldquo;Topics\u0026rdquo; Click \u0026ldquo;Create topic\u0026rdquo; Type: Standard Name: smoking-cessation-alerts Click \u0026ldquo;Create topic\u0026rdquo; ⏳ Chờ topic được tạo\nBước 2: Create Email Subscription Click vào topic vừa tạo \u0026ldquo;Subscriptions\u0026rdquo; tab → \u0026ldquo;Create subscription\u0026rdquo; Protocol: Email Endpoint: your-email@example.com Click \u0026ldquo;Create subscription\u0026rdquo; ⏳ Chờ email confirmation\nCheck your email inbox and click the confirmation link!\nBước 3: Create SMS Subscription (Optional) Click \u0026ldquo;Create subscription\u0026rdquo; Protocol: SMS Endpoint: +1234567890 (your phone number) Click \u0026ldquo;Create subscription\u0026rdquo; Now you\u0026rsquo;ll get SMS alerts for critical issues!\nPhần 4: Create CloudWatch Alarms Bước 1: Create Lambda Error Alarm CloudWatch → Alarms → \u0026ldquo;Create alarm\u0026rdquo; Select metric: Namespace: AWS/Lambda Metric: Errors Statistics: Sum Conditions: Threshold: \u0026gt; 5 errors Period: 5 minutes Evaluation periods: 1 Click \u0026ldquo;Next\u0026rdquo; Notification: Select SNS topic smoking-cessation-alerts Alarm name: smoking-lambda-errors Alarm description: Alert when Lambda errors exceed threshold Click \u0026ldquo;Create alarm\u0026rdquo; Bước 3: Create EC2 Database CPU Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Select metric: Namespace: AWS/EC2 Metric: CPUUtilization Instance: DB-PG Conditions: Threshold: \u0026gt; 80% Period: 5 minutes Evaluation periods: 2 Click \u0026ldquo;Next\u0026rdquo; Notification: smoking-cessation-alerts Alarm name: smoking-db-pg-high-cpu Click \u0026ldquo;Create alarm\u0026rdquo; Bước 4: Create Similar Alarms for Other Services Repeat for:\nDB-Mongo CPU \u0026gt; 80% Application servers CPU \u0026gt; 75% CloudFront 4xx errors \u0026gt; 5% CloudFront 5xx errors \u0026gt; 1% NLB unhealthy targets \u0026gt; 0 Bước 5: Create Composite Alarm (Optional) Combine multiple alarms into one:\nClick \u0026ldquo;Create alarm\u0026rdquo; Alarm type: Composite alarm Alarm rule: (smoking-lambda-errors OR smoking-apigateway-errors OR smoking-db-pg-high-cpu OR smoking-db-mongo-high-cpu) This triggers if ANY service has issues Click \u0026ldquo;Create alarm\u0026rdquo; Result: Comprehensive alerting system active!\nPhần 5: Enable CloudTrail Audit Logging Bước 1: Create CloudTrail Tìm kiếm \u0026ldquo;CloudTrail\u0026rdquo; Click \u0026ldquo;CloudTrail\u0026rdquo; service Click \u0026ldquo;Create trail\u0026rdquo; Trail name: smoking-cessation-audit Enable for all AWS regions: ✅ (recommended) Click \u0026ldquo;Next\u0026rdquo; Bước 2: Configure S3 for CloudTrail Logs S3 bucket: Create new bucket: ✅ Bucket name: smoking-cessation-cloudtrail-logs S3 key prefix (optional): cloudtrail-logs/ Click \u0026ldquo;Next\u0026rdquo; Bước 3: Configure CloudTrail Events Management events: ✅ All (captures API calls) Data events: (Optional - more expensive) Insights: ✅ CloudTrail Insights (detects unusual activity) Click \u0026ldquo;Next\u0026rdquo; Bước 4: Review \u0026amp; Create Review all settings Click \u0026ldquo;Create trail\u0026rdquo; ⏳ Chờ trail được tạo\nBước 5: Start Logging Trail created → click \u0026ldquo;Start logging\u0026rdquo; Trail status changes to \u0026ldquo;Logging\u0026rdquo; Now all API calls are being audited!\nBước 6: View CloudTrail Events CloudTrail → Event history Filter by: Event name: (e.g., PutFunction for Lambda code updates) Resource type: (e.g., AWS::Lambda::Function) Time range: Last 24 hours View event details (JSON format) This helps with:\nSecurity audits Compliance investigations Troubleshooting IAM issues Cost allocation Phần 6: Enable X-Ray Distributed Tracing Bước 1: Create X-Ray Sampling Rule Tìm kiếm \u0026ldquo;X-Ray\u0026rdquo; Click \u0026ldquo;X-Ray\u0026rdquo; service Left menu: \u0026ldquo;Sampling rules\u0026rdquo; Click \u0026ldquo;Create sampling rule\u0026rdquo; Rule name: smoking-cessation-sampling Priority: 1000 (lower = higher priority) Reservoir: 1 (always sample at least 1 per second) Fixed rate: 0.1 (10% of requests) Click \u0026ldquo;Create sampling rule\u0026rdquo; This controls how many traces are recorded (reducing cost).\nBước 2: Enable X-Ray for Lambda Functions For each Lambda function:\nLambda Console Click function name Configuration tab Click \u0026ldquo;General configuration\u0026rdquo; → Edit Under \u0026ldquo;Monitoring tools\u0026rdquo;: ✅ Check \u0026ldquo;Active tracing\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Repeat for all 5 Lambda functions.\nBước 3: Enable X-Ray for API Gateway API Gateway Console Select API: smoking-cessation-user-api Logging → Settings ✅ Check \u0026ldquo;X-Ray request tracing enabled\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Repeat for chat API Bước 4: Update Lambda IAM Role for X-Ray IAM Console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Add permissions → Attach policies directly Search: AWSXRayWriteAccess Check ✅ Click \u0026ldquo;Attach policies\u0026rdquo; Now Lambda can write X-Ray traces!\nBước 5: View Service Map X-Ray Console Left menu: \u0026ldquo;Service map\u0026rdquo; You\u0026rsquo;ll see a map showing: API Gateway → Lambda → EC2 (databases) Lambda → S3 Lambda → CloudFront Data flow between services As requests flow through the system, traces are recorded!\nBước 6: Analyze Traces X-Ray → Traces Click on a trace to view: Service timeline Latency breakdown per service Errors and exceptions Database query details Use this to identify performance bottlenecks Phần 7: Setup Cost Monitoring Bước 1: Create AWS Budget Billing Console Left menu: \u0026ldquo;Budgets\u0026rdquo; Click \u0026ldquo;Create budget\u0026rdquo; Budget type: Cost budget Period: Monthly Amount: $500/month Alerts: When actual \u0026gt; 80% ($400): Email When forecasted \u0026gt; 100% ($500): Email Click \u0026ldquo;Create budget\u0026rdquo; This prevents surprise bills!\nBước 2: Setup Cost Anomaly Detection Cost Management Console Left menu: \u0026ldquo;Anomaly Detection\u0026rdquo; Click \u0026ldquo;Create detector\u0026rdquo; Name: smoking-cessation-cost-anomaly Monitor: All AWS Services Frequency: Daily Alert frequency: Instant SNS topic: smoking-cessation-alerts Click \u0026ldquo;Create detector\u0026rdquo; Now you\u0026rsquo;ll be alerted if costs spike unexpectedly!\nBước 3: Use Cost Explorer Cost Explorer View costs by: Service: See which services cost the most Region: Compare regions Time: Identify trends Filter: Linked account Cost category Granularity: Daily or Monthly Common cost optimization findings:\nNAT Gateway data processing \u0026gt; 50% of bill EC2 instances running 24/7 \u0026gt; 30% of bill CloudFront data transfer \u0026gt; 10% of bill Phần 8: Create CloudWatch Synthetics (Health Checks) Bước 1: Create API Canary CloudWatch Console Left menu: \u0026ldquo;Synthetics\u0026rdquo; → \u0026ldquo;Canaries\u0026rdquo; Click \u0026ldquo;Create canary\u0026rdquo; Canary type: API canary Name: smoking-api-health-check Endpoint: Your API Gateway URL https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/health Method: GET Schedule: 5 minutes Click \u0026ldquo;Next\u0026rdquo; Bước 2: Configure Success Criteria Status codes: 200 Response time: \u0026lt; 1000ms Click \u0026ldquo;Next\u0026rdquo; Bước 3: Set S3 Storage S3 location: Create new bucket or select existing Bucket name: smoking-canary-results Click \u0026ldquo;Create canary\u0026rdquo; ⏳ Chờ canary được tạo\nBước 4: Monitor Canary Results Synthetics → Canaries Click smoking-api-health-check View: Success rate Latency graphs Failed requests If failures: Create CloudWatch alarm This continuously tests API availability!\nPhần 9: Create Incident Response Runbooks Bước 1: Document High Error Rate Response Create a file or document:\nINCIDENT: High Lambda Error Rate (\u0026gt; 5 errors/5min) Detection: CloudWatch Alarm \u0026#34;smoking-lambda-errors\u0026#34; triggered Immediate Actions: 1. Check CloudWatch Logs: - Go to CloudWatch → Logs → Log groups - Select `/aws/lambda/smoking-cessation` - Search for \u0026#34;error\u0026#34; or \u0026#34;Error\u0026#34; - Note error message \u0026amp; frequency 2. Identify Affected Function: - From alarm, determine which function - Check recent CloudTrail logs - Verify no recent code deployments 3. Database Connectivity Check: - If DB error: - EC2 → Instances - Check DB-PG and DB-Mongo status - Check security groups allow traffic - If not DB: Check Lambda timeout configuration 4. Escalation: - If not resolved in 15 min: Page on-call engineer - If data loss risk: Initiate disaster recovery Resolution: - Rollback recent deployments if applicable - Scale up database resources if overloaded - Increase Lambda memory if timeout issues - Update database connection pooling Post-Incident: - Document root cause - Update monitoring to catch earlier - Schedule post-mortem meeting Bước 2: Create High API Latency Runbook INCIDENT: High API Latency (\u0026gt; 1000ms p99) Actions: 1. Check X-Ray service map to identify slow service 2. If Lambda slow: - Increase memory (more CPU) - Check CloudWatch Logs for errors 3. If database slow: - Monitor EC2 instance CPU/Memory - Check slow query logs 4. If API Gateway slow: - Check request volume - Verify cache hit rate (CloudFront) 5. Resolution: - Scale resources up - Optimize queries/code - Add caching layer Bước 3: Create Database Disk Full Runbook INCIDENT: Database Disk Full (\u0026gt; 90%) Actions: 1. SSH to DB instance (EC2) 2. Check disk usage: df -h /var 3. Clean up: - Remove old logs: find /var/log -mtime +30 -delete - Archive old data from PostgreSQL - Delete old MongoDB collections 4. If still full: - Add EBS volume or expand existing - Migrate to larger instance type 5. Configure auto-cleanup for future Environment Variables \u0026amp; Monitoring Info Save for reference:\n# CloudWatch DASHBOARD_NAME=smoking-cessation-monitoring LOG_GROUP_LAMBDA=/aws/lambda/smoking-cessation LOG_GROUP_APIGATEWAY=/aws/apigateway/smoking-cessation LOG_GROUP_VPC=/aws/vpc/flow-logs LOG_RETENTION=30 # days # Alarms \u0026amp; Notifications SNS_TOPIC_ARN=arn:aws:sns:ap-southeast-1:xxx:smoking-cessation-alerts ALARM_LAMBDA_ERRORS=smoking-lambda-errors ALARM_APIGATEWAY_ERRORS=smoking-apigateway-errors ALARM_DB_CPU_HIGH=smoking-db-cpu-high # Audit \u0026amp; Tracing CLOUDTRAIL_BUCKET=smoking-cessation-cloudtrail-logs XRAY_SAMPLING_RATE=0.1 SYNTHETICS_BUCKET=smoking-canary-results # Budget MONTHLY_BUDGET=$500 ALERT_THRESHOLD=80% # $400 Checklist CloudWatch Log Groups created for all services Log retention set to 30 days CloudWatch Dashboard created with key metrics SNS topic created for notifications Email subscription verified CloudWatch Alarms created: Lambda errors API Gateway errors EC2 database high CPU CloudFront errors NLB health CloudTrail enabled \u0026amp; logging CloudTrail S3 bucket created X-Ray sampling rule configured X-Ray enabled on Lambda functions X-Ray enabled on API Gateway Lambda IAM role has X-Ray permissions AWS Budget configured ($500/month) Cost Anomaly Detection enabled CloudWatch Synthetics canary created Incident response runbooks documented Team trained on monitoring tools WORKSHOP COMPLETE ✅ Monitoring Best Practices Alert Fatigue Prevention Set thresholds based on historical baselines Use composite alarms for multiple conditions Implement alert deduplication Log Management Set appropriate retention (30 days = balance) Use filters to reduce noise Archive to S3 Glacier for long-term storage Cost Optimization Review CloudWatch costs monthly Use Log Insights selectively Archive old logs to S3 Security Enable CloudTrail multi-region Review CloudTrail logs weekly Monitor for suspicious IAM activity Cost Analysis Monitoring costs (estimated monthly):\nCloudWatch Logs: ~$20 (log ingestion + storage) CloudWatch Alarms: ~$5 (10 alarms × $0.50) CloudTrail: ~$3 (multi-region trail) X-Ray: ~$2 (10% sampling rate) Cost Explorer: Free Synthetics: ~$1 (1 canary every 5 min) Total: ~$31/month Next Steps Monitor dashboard daily during initial rollout Adjust alarm thresholds based on actual metrics Review CloudTrail logs for security Optimize costs based on Cost Explorer findings Plan disaster recovery based on CloudTrail audit trail Schedule monthly post-mortems for any incidents Kết Quả Đạt Được Sau Module 9, bạn sẽ có:\n✅ CloudWatch Log Groups for all services ✅ Centralized logging with 30-day retention ✅ Real-time monitoring dashboard ✅ Automated SNS alerts for critical issues ✅ Email/SMS notifications working ✅ CloudWatch Alarms monitoring performance ✅ CloudTrail enabled for compliance auditing ✅ X-Ray distributed tracing for debugging ✅ Service map showing architecture ✅ Cost monitoring \u0026amp; budgets configured ✅ CloudWatch Synthetics for continuous health checks ✅ Incident response runbooks documented ✅ Complete observability of infrastructure ✅ 🎉 AWS WORKSHOP 100% COMPLETE 🎉 Workshop Summary You have successfully built a complete AWS infrastructure for the Smoking Cessation Platform:\nModules Completed (9 Total): Module 1-2: Prerequisites \u0026amp; AWS Account Setup ✅ Module 3: Cognito Authentication ✅ Module 4: Lambda Functions ✅ Module 5: API Gateway REST APIs ✅ Module 6: EC2 Instances \u0026amp; Databases ✅ Module 7: S3 Frontend \u0026amp; CloudFront CDN ✅ Module 8: VPC, Security, Load Balancing ✅ Module 9: Monitoring, Logging \u0026amp; Alerts ✅ Architecture Highlights: ✅ Secure authentication (Cognito) ✅ Serverless compute (Lambda) ✅ RESTful APIs (API Gateway) ✅ Hybrid databases (PostgreSQL + MongoDB on EC2) ✅ Global content delivery (CloudFront) ✅ High-availability networking (VPC, NLB) ✅ Comprehensive monitoring (CloudWatch, X-Ray) ✅ Complete audit trail (CloudTrail) Estimated Monthly Cost: $320-350 EC2 (4 instances): $120 Lambda: $10 API Gateway: $5 S3 + CloudFront: $10 NAT Gateway: $32 NLB: $16 CloudWatch/Logs: $30 Other services: $30 Your infrastructure is production-ready! 🚀\n"},{"uri":"https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.10-cleanup/","title":"Cleanup &amp; Cost Optimization","tags":[],"description":"","content":"Module 10: Cleanup \u0026amp; Cost Optimization Mục tiêu Module Identify unused/underutilized resources Delete test resources Optimize costs Archive important data Backup before deletion Documentation \u0026amp; lessons learned Phần 1: Resource Inventory \u0026amp; Assessment Current AWS Resources List tất cả resources từ AWS Console:\nLambda Functions:\nGo to Lambda console List functions in each region (us-east-1, ap-southeast-1) Note: Function names, creation dates, memory allocation API Gateways:\nGo to API Gateway console List all REST APIs in ap-southeast-1 Note: API names, deployment status EC2 Database Instances:\nGo to EC2 console List all instances in ap-southeast-1 Filter for database instances (DB-PG, DB-Mongo) Note: Instance IDs, instance types, IPs, creation dates S3 Buckets:\nGo to S3 console List all buckets Note: Bucket names, creation dates, storage used CloudFront Distributions:\nGo to CloudFront console List all distributions Note: Domain names, distribution IDs VPC Resources:\nGo to VPC console List all VPCs in ap-southeast-1 Note: VPC IDs, CIDR ranges Create inventory spreadsheet:\nResource name \u0026amp; type Region Creation date Current usage Estimated monthly cost Phần 2: Identify Unused Resources Check Resource Usage Lambda Functions To check Lambda invocations:\nGo to CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;Lambda\u0026rdquo; Select each function Choose metric: \u0026ldquo;Invocations\u0026rdquo; Set time range: Last 7 days Check if Sum = 0 (unused function) If no invocations in last 7 days = unused function (consider deletion)\nAPI Gateways To check API request count:\nGo to CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;API Gateway\u0026rdquo; Select your API Choose metric: \u0026ldquo;Count\u0026rdquo; Set time range: Last 30 days Check if Sum = 0 (unused API) S3 Buckets To check bucket sizes:\nGo to S3 console Click on each bucket Go to \u0026ldquo;Storage\u0026rdquo; tab See \u0026ldquo;Storage used\u0026rdquo; value Review storage class (Standard, Infrequent Access, Glacier) Consider moving old objects to cheaper storage classes S3 storage class pricing:\nStandard: $0.023/GB/month Infrequent Access: $0.0125/GB/month Glacier: $0.004/GB/month CloudFront To check cache hit ratio:\nGo to CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;CloudFront\u0026rdquo; Select your distribution Choose metric: \u0026ldquo;CacheHitRate\u0026rdquo; Set time range: Last 30 days If cache hit ratio \u0026lt; 50%, may need optimization EC2 Database Instances To check CPU \u0026amp; memory usage:\nGo to CloudWatch console Click \u0026ldquo;Metrics\u0026rdquo; → \u0026ldquo;EC2\u0026rdquo; Select your database instance (DB-PG or DB-Mongo) Choose metric: \u0026ldquo;CPUUtilization\u0026rdquo; Set time range: Last 30 days Check Average and Maximum values If CPU \u0026lt; 10% consistently: May downsize instance type (saves money on EC2)\nPhần 3: Cost Optimization Strategies 1. Right-Sizing EC2 Database Instances Current: t4g.small EC2 instances (PostgreSQL + MongoDB) Cost: ~$30-40/month per instance\nOptions:\nt4g.nano: ~$3-5/month (for test/dev) t4g.micro: ~$8-10/month (for light production) t4g.small: Keep as-is (recommended for production) Check: EC2 CPU \u0026lt; 10% on average → downsize to save money\n2. Reserve Capacity (if stable usage) For production, consider AWS EC2 Reserved Instances:\n1-year: ~30% discount 3-year: ~50% discount To purchase reserved EC2 instances:\nGo to EC2 console Click \u0026ldquo;Reserved Instances\u0026rdquo; (left menu) Click \u0026ldquo;Purchase Reserved Instances\u0026rdquo; Configure: Instance type: t4g.small Term length: 1-year or 3-year Click \u0026ldquo;Purchase\u0026rdquo; 3. Optimize Data Transfer Costs:\nS3 to CloudFront: Free S3 to Internet: $0.09/GB S3 to Lambda (same region): Free Recommendation: Keep CloudFront caching enabled\n4. Lambda Optimization Current: 256 MB average Cost: ~$0.0000002 per invocation\nIf high invocation rate:\nUse Lambda provisioned concurrency: Higher cost but predictable Monitor: Check if memory increase helps reduce duration (saves cost) 5. Database Optimization Recommendations:\nEnable automated backup (already done) Setup read replicas if scaling reads (cost: ~50% of main instance) Archive old logs (CloudWatch retention: 30 days by default) 6. CloudFront Optimization If cache hit ratio \u0026lt; 50%:\nIncrease TTL for static assets Add more cache behaviors Use cache policies with parameters Phần 4: Backup \u0026amp; Archive Bước 1: Backup EC2 Databases To backup PostgreSQL and MongoDB on EC2:\nPostgreSQL (DB-PG: 172.0.8.55):\nSSH into the EC2 instance Create backup: pg_dump smokingcessation \u0026gt; backup_$(date +%Y%m%d).sql Compress: gzip backup_*.sql MongoDB (DB-Mongo: 172.0.8.124):\nSSH into the EC2 instance Create backup: mongodump --db smokingcessation --out backup_$(date +%Y%m%d) Compress: tar czf backup_*.tar backup_* Bước 2: Upload Database Backups to S3 To export database backups for archival:\nSSH into database EC2 instance Upload to S3: Via AWS CLI (if configured): aws s3 sync /backups s3://smoking-cessation-backups/ Or manually download and upload via S3 console Bước 3: Archive S3 Data For old data (\u0026gt; 90 days), setup lifecycle policies:\nGo to S3 console Click on bucket name (e.g., \u0026ldquo;leaflungs-images\u0026rdquo;) Go to \u0026ldquo;Management\u0026rdquo; tab Click \u0026ldquo;Create lifecycle rule\u0026rdquo; Configure: Name: \u0026ldquo;archive-old-data\u0026rdquo; Filter: Prefix \u0026ldquo;chat/\u0026rdquo; Transitions: Move to Glacier after 90 days Expiration: Delete after 365 days Click \u0026ldquo;Create rule\u0026rdquo; Phần 5: Test Resource Cleanup (Non-Production) Bước 1: Delete Test Lambda Functions If any test functions exist:\nGo to Lambda console Click on test function name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete\u0026rdquo; Type function name to confirm Click \u0026ldquo;Delete\u0026rdquo; Bước 2: Delete Unused API Gateway If multiple APIs for testing:\nGo to API Gateway console Click on API name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete API\u0026rdquo; Confirm deletion Bước 3: Delete Empty S3 Buckets To delete a bucket:\nGo to S3 console Click on bucket name Click \u0026ldquo;Empty\u0026rdquo; to remove all objects Confirm emptying Once empty, click \u0026ldquo;Delete\u0026rdquo; button Type bucket name to confirm Click \u0026ldquo;Delete bucket\u0026rdquo; Bước 4: Delete Unused CloudFront Distributions To delete a CloudFront distribution:\nGo to CloudFront console Click on distribution Click \u0026ldquo;Disable\u0026rdquo; (if enabled) Wait 15 minutes for propagation Once status shows \u0026ldquo;Disabled\u0026rdquo;, click \u0026ldquo;Delete\u0026rdquo; Confirm deletion Phần 6: Delete Production Resources (if shutting down) WARNING: This is destructive and cannot be undone!\nBackup Checklist Before Deletion PostgreSQL data backed up (pg_dump) MongoDB data backed up (mongodump) Database backups uploaded to S3 S3 data backed up externally (if needed) CloudTrail logs reviewed \u0026amp; archived Code backed up to GitHub DNS records updated (if redirecting) Team notified Bước 1: Delete EC2 Database Instances To delete database EC2 instances:\nGo to EC2 console Click \u0026ldquo;Instances\u0026rdquo; Select database instance (DB-PG or DB-Mongo) Click \u0026ldquo;Instance State\u0026rdquo; → \u0026ldquo;Terminate\u0026rdquo; Confirm termination Wait for instance to terminate Verify EBS volumes are deleted (optional: create snapshots first if needed) Repeat for second database instance Bước 2: Delete Lambda Functions To delete each Lambda function:\nGo to Lambda console Click on function name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete\u0026rdquo; Type function name to confirm Click \u0026ldquo;Delete\u0026rdquo; Repeat for each function Bước 3: Delete API Gateways To delete each API Gateway:\nGo to API Gateway console Click on API name (e.g., \u0026ldquo;LeafLungs-UserInfo-API\u0026rdquo;) Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete API\u0026rdquo; Confirm deletion Repeat for second API (leaflungs-chat-api) Bước 4: Delete Cognito User Pool To delete Cognito User Pool:\nGo to Cognito console Click \u0026ldquo;User pools\u0026rdquo; Click on your user pool Click \u0026ldquo;Delete user pool\u0026rdquo; (bottom right) Type the user pool name to confirm Click \u0026ldquo;Delete\u0026rdquo; Bước 5: Delete S3 Buckets (and contents) To delete each S3 bucket:\nGo to S3 console For each bucket (leaflungs-frontend-new, leaflungs-images, leaflungs-images-sg): Click on bucket name Click \u0026ldquo;Empty\u0026rdquo; to remove all objects Confirm emptying Once empty, click \u0026ldquo;Delete\u0026rdquo; button Type bucket name to confirm Click \u0026ldquo;Delete bucket\u0026rdquo; Bước 6: Delete CloudFront Distribution To delete CloudFront distribution:\nGo to CloudFront console Click on distribution (if not already disabled) If enabled, click \u0026ldquo;Disable\u0026rdquo; first Wait 15 minutes for propagation Once status shows \u0026ldquo;Disabled\u0026rdquo;, click \u0026ldquo;Delete\u0026rdquo; Confirm deletion Phần 7: Cost Analysis \u0026amp; Reporting Monthly Cost Breakdown Typical costs for this architecture:\nService Usage Cost Lambda 100K invocations/month ~$2 API Gateway 10M requests/month ~$50 EC2 (2x DB instances) 2 x t4g.small for PostgreSQL + MongoDB ~$60-70 EC2 (2x App instances) 2 x t4g.small for applications ~$60-70 S3 100 GB storage ~$2 CloudFront 1 TB/month transfer ~$85 Cognito 1K users ~$0 (free tier) NAT Gateway 10 GB transfer ~$5 Total ~$300-350/month Cost optimization opportunities:\nUse t4g.nano/micro for light databases: Saves ~$20-30/month Cache more aggressively: Saves ~$30/month Reserved EC2 instances: Saves ~$60-80/month Total savings: ~$110-140/month (35-40% reduction) AWS Cost Explorer AWS Console → Billing → Cost Explorer View costs by: Service Linked account Region Usage type Set up cost anomaly detection Review trends Phần 8: Documentation \u0026amp; Lessons Learned Create Post-Mortem Document # Workshop Completion Report ## Architecture Summary - Services deployed: Lambda, API Gateway, EC2 (PostgreSQL + MongoDB), S3, CloudFront, Cognito, NLB - Regions: us-east-1 (Cognito), ap-southeast-1 (main) - Total users: 1000+ - Monthly costs: $300-350 ## Key Learnings 1. Regional considerations - Cognito must be in us-east-1 for CloudFront - Main services in ap-southeast-1 for latency 2. Security best practices implemented - VPC isolation - Security group restrictions - IAM least-privilege - Secrets Manager for credentials 3. Cost optimization - CloudFront caching important - EC2 instances can be right-sized or use Reserved Instances - Reserved instances save 30-50% 4. Monitoring critical - CloudWatch alarms prevented many issues - X-Ray helped debug performance ## Recommendations for Next Phase 1. Setup automated backups for EC2 databases (pg_dump/mongodump cronjobs) 2. Implement CI/CD for automated deployments 3. Add comprehensive test suite 4. Setup on-call rotation \u0026amp; runbooks 5. Quarterly cost reviews Checklist - Cleanup Decision Before final cleanup, verify:\nAll data backed up Snapshots created CloudTrail logs archived Code pushed to GitHub Cost analysis completed Team trained on infrastructure Documentation complete Stakeholders approved DNS cutover plan (if applicable) Rollback plan documented Final Recommendations Keep infrastructure running (you\u0026rsquo;ve built it correctly) Implement automated scaling if needed Setup CI/CD pipeline for updates Add comprehensive testing Plan quarterly cost reviews Train team on operational procedures Consider disaster recovery plan Summary \u0026amp; Next Steps Congratulations! You\u0026rsquo;ve successfully:\n✓ Verified/setup Cognito authentication ✓ Verified/setup Lambda functions ✓ Verified/setup API Gateways ✓ Verified EC2 databases (PostgreSQL + MongoDB) ✓ Verified S3 \u0026amp; CloudFront ✓ Verified VPC \u0026amp; Security ✓ Implemented monitoring \u0026amp; logging ✓ Optimized costs This infrastructure can support:\n1000+ concurrent users 100K+ requests/day Highly available (multi-AZ capable) Scalable (auto-scale Lambda, upgrade EC2 instance types) Secure (VPC isolation, encryption, IAM) Observable (comprehensive logging \u0026amp; monitoring) Kết Quả Đạt Được Sau Module 10:\nResource inventory \u0026amp; usage analyzed Cost optimization strategies identified Unused resources identified for cleanup Backup procedures implemented Cost reduction plan created (up to 36% savings possible) Post-mortem \u0026amp; lessons learned documented Recommendations for next phase Workshop complete \u0026amp; infrastructure production-ready "},{"uri":"https://thienluhoan.github.io/workshop-template/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://thienluhoan.github.io/workshop-template/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]