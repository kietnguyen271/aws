[{"uri":"https://thienluhoan.github.io/workshop-template/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Nguyễn Tuấn Kiệt\nPhone Number: 0977957462\nEmail: kietntse183979@fpt.edu.vn\nUniversity: FPT University\nMajor: Information Technology\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 28/11/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/4.1-event1/","title":"AWS Cloud Day Vietnam - AI Edition 2025","tags":[],"description":"","content":"AWS Cloud Day Vietnam - AI Edition 2025 - Date: September 18, 2025 - Location: 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nEvent Overview A pivotal gathering for Vietnam\u0026rsquo;s tech and business communities, focused on accelerating digital transformation through the convergence of Cloud Computing and Artificial Intelligence.\nKey Objectives:\nDemocratize Generative AI: Move GenAI from concept to practical, context-aware enterprise applications. Align Business \u0026amp; IT: Bridge the gap between business goals and IT, especially in Financial Services. Accelerate Modernization: Provide industry-specific roadmaps for migration and cloud-native development. Strengthen Security: Promote a \u0026ldquo;security by design\u0026rdquo; mindset across the application lifecycle. Key Takeaways \u0026amp; Learnings Data is the Differentiator: A comprehensive data strategy is a prerequisite for successful Generative AI. Modernization is a Continuous Journey: The goal is not just to migrate but to \u0026ldquo;Migrate to Operate\u0026rdquo; and innovate continuously. Business-Led Technology: Technology initiatives must be driven by clear business outcomes. Security is Everyone\u0026rsquo;s Responsibility: Security must be integrated from the first line of code. Application to Work Audit Data Readiness: Assess our current data strategy to ensure it can support future GenAI initiatives. Pilot GenAI in DevOps: Experiment with AI-driven code generation and automated testing to improve development velocity. Benchmark Modernization Efforts: Analyze case studies from Honda Vietnam (SAP migration) and Masterise Group (VMware migration) to refine our own modernization roadmaps. Implement \u0026ldquo;Security at Scale\u0026rdquo;: Integrate security tools and best practices throughout the entire development lifecycle. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.1-introduction/","title":"5.1 Introduction","tags":[],"description":"","content":"Module 1: Introduction to Smoking Cessation Platform Infrastructure Module Objectives Understand the AWS architecture of the entire system Learn the main components of the platform Understand the data flow between services Prepare for the next modules Overview of the System Architecture (Hybrid - EC2 + Lambda) AWS Architecture Diagram Architecture Type: Hybrid (EC2 + Serverless Lambda)\nDeployment Pattern: EC2 for stateful services, Lambda for event-driven tasks\n[workshop\\assets\\architecture.png]\nMain Components 1. Frontend Layer (React + Vite) Hosting: S3 + CloudFront\nFeatures:\nResponsive UI for Web \u0026amp; Mobile Real-time Chat using WebSocket User Authentication (Cognito) Progress Tracking Dashboard Coach Management Interface 2. API Gateway Layer REST API: /api/v1/* endpoints\nWebSocket: /ws endpoints for real-time chat\nResponsibilities:\nRequest routing Authentication validation Rate limiting CORS handling 3. Backend Layer (Hybrid: EC2 + Lambda) EC2 Application Servers (Always-on):\nuser-cessation service (Port 8000)\nUser profiles, progress tracking Coaching session management Statistics \u0026amp; analytics social-media service (Port 8000)\nSocial features Notifications Community management Lambda Functions (Event-driven):\nFile Upload Lambda\nHandle image/file uploads to S3 Payment Processing Lambda\nProcess payments \u0026amp; subscriptions Specific Trigger Functions\nWebhooks Scheduled tasks 4. WebSocket \u0026amp; Real-time Layer NLB (Network Load Balancer):\nHandles persistent WebSocket connections Port 443 (HTTPS) Distributes real-time chat traffic Integration with EC2 backend servers 5. Database Layer (EC2-hosted) PostgreSQL Server (DB-PG):\nUser profiles \u0026amp; authentication Progress tracking data Coaching session records Relational data MongoDB Server (DB-Mongo):\nChat message history Social media content Message metadata Flexible schema data 6. Security Layer AWS Cognito: User authentication \u0026amp; authorization IAM Roles: Service-to-service permissions VPC: Network isolation (private subnets for databases) Security Groups: Firewall rules for EC2 \u0026amp; databases SSL/TLS: Data encryption in transit \u0026amp; at rest NLB Security Group: Restricts access to WebSocket port 7. Monitoring \u0026amp; Logging CloudWatch: Logs \u0026amp; Metrics for all services CloudTrail: API audit trail EC2 Instance Monitoring: CPU, memory, disk usage Database Monitoring: Query performance, connections Alarms: Performance \u0026amp; health alerts User Journeys \u0026amp; Data Flow Journey 1: User Registration \u0026amp; Login User navigates to the registration page ↓\nFrontend sends credentials → API Gateway → Lambda (Auth Service) ↓\nLambda validates \u0026amp; creates user in PostgreSQL (EC2) ↓\nAWS Cognito creates user account ↓\nLambda returns access token \u0026amp; refresh token ↓\nFrontend stores tokens → user gains access to API\nJourney 2: Real-time Chat User A sends a message ↓\nMessage is sent → API Gateway WebSocket endpoint ↓\nLambda (Chat Service) processes the message ↓\nStore message in MongoDB (EC2) ↓\nWebSocket broadcasts message to User B (connected) ↓\nUser B receives message in real-time\nJourney 3: Progress Tracking User updates progress data (e.g., smoke-free days) ↓\nFrontend sends → API Gateway → Lambda (User Service) ↓\nLambda validates \u0026amp; updates PostgreSQL (EC2) ↓\nCoach receives notification (through WebSocket) ↓\nDashboard updates in real-time\nTechnologies \u0026amp; Services Component Service Details Frontend Hosting S3 + CloudFront Static website hosting + CDN Authentication Cognito User authentication \u0026amp; SSO API Management API Gateway REST API routing Compute (Always-on) EC2 (t4g.small) Main application servers Compute (Event-driven) Lambda Specific functions (upload, payment) Real-time NLB + WebSocket WebSocket connections \u0026amp; messaging Database (SQL) EC2 + PostgreSQL User data, relational data Database (NoSQL) EC2 + MongoDB Chat history, social data Storage S3 File uploads \u0026amp; assets Security VPC, Security Groups, IAM Network isolation \u0026amp; access control Monitoring CloudWatch Logs, metrics, alarms CDN CloudFront Content delivery network Next Modules Module 2: Prerequisites – Preparing tools \u0026amp; AWS account Module 3: Setup Cognito – User authentication Module 4: Setup Lambda – Backend functions Module 5: Setup API Gateway – API endpoints Module 6: Verify EC2 Servers \u0026amp; Databases – PostgreSQL + MongoDB on EC2 Module 7: Setup S3 + CloudFront – Frontend hosting Module 8: Setup VPC \u0026amp; Security – Network security Module 9: Monitoring \u0026amp; Logging – System observability Module 10: Cleanup – Remove resources \u0026amp; cost optimization Checklist Understand the overall AWS architecture Identify the 6 main system components Understand the 3 key user journeys Ready for Module 2 Notes The system uses Serverless Architecture — no server maintenance required All services auto-scale based on demand Pay-as-you-go pricing model Highly available \u0026amp; disaster recovery ready "},{"uri":"https://thienluhoan.github.io/workshop-template/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"AWS DevOps \u0026amp; Developer Productivity Blog\nAccelerating Development with Secure Access to Amazon Q Developer Using PingIdentity by Sid Vantair on 19 JUN 2025 in Amazon Q, AWS IAM Identity Center, Generative AI, Technical How-to — Permalink\nCustomers using Amazon Q Developer,\na programming assistant enhanced by Generative AI, often need to authenticate through existing\nIdentity Providers (IdPs) such as PingIdentity. By leveraging\nAWS IAM Identity Center,\norganizations can allow their developers to access Amazon Q Developer using their existing\nPingIdentity credentials, simplifying the authentication workflow and removing the need for separate logins.\nAmazon Q Developer can chat about your code, provide inline code completions, and generate new code.\nIt also scans your code for security vulnerabilities and performs improvements, including\nlanguage upgrades, debugging, and optimization.\nAmazon Q Developer comes in two tiers:\nFree Tier – free for personal use Pro Tier – enterprise-grade version with advanced access controls, analytics dashboard,\ncustomization capabilities, and higher usage limits Organizations enabling the Pro Tier for their developers typically authenticate through\nAWS IAM Identity Center due to its ability to federate with external identity providers.\nIn this article, we will guide you through how to configure PingIdentity as an external IdP\nfor IAM Identity Center, allowing developers to access Amazon Q Developer\nusing their existing PingIdentity credentials.\nActivities\nFigure 1 – Solution Overview\nThe business challenge The authentication process works as follows: The developer initiates a request to access Amazon Q Developer. IAM Identity Center checks the authentication status. If the user is not authenticated, they are redirected to the PingIdentity login page. The developer enters their PingIdentity credentials. PingIdentity validates the credentials and returns a SAML response. IAM Identity Center validates the SAML response. Once validated, access to Amazon Q Developer is granted. The developer can now start using Amazon Q Developer. Prerequisites An AWS account A PingIdentity environment with users and groups configured for Amazon Q Developer access IAM Identity Center Amazon Q Developer Pro Tier subscription Step-by-step guide In this section, we will walk through how to create a SAML-based connection between\nPingIdentity and IAM Identity Center, enabling seamless access to\nAmazon Q Developer using PingIdentity credentials.\nNote: You will need to switch between the PingIdentity admin console and IAM Identity Center\nduring this setup. It is recommended to keep each console open in separate tabs.\nStep 1: Enable AWS Single Sign-On in PingIdentity This step enables the AWS Single Sign-On application inside PingIdentity.\nIn the PingIdentity console, navigate to Applications tab → Application Catalog. Search for “AWS Single Sign-On” and click the + icon to start Quick Setup. Figure 2 – PingIdentity Application Catalog\nAlt Text: Screenshot of the PingIdentity Application Catalog.\nThe term “aws” is entered in the search bar, showing three results:\nAmazon Web Services – AWS, AWS Gov-Cloud, and AWS Single Sign-On.\nThe \u0026ldquo;AWS Single Sign-On\u0026rdquo; option is highlighted with a red box\nand includes a plus icon to add the application.\n3. Provide the Name, SSO Region, and SSO Tenant ID, then select Next Name – Enter an appropriate name for the connection SSO Region – Enter the correct AWS region Tenant ID – This is the Identity Store ID You can run the following CLI command to retrieve this value.\nIt is a 10-character alphanumeric string starting with the prefix “d-”:\naws sso-admin list-instances \u0026ndash;query \u0026lsquo;Instances[0].IdentityStoreId\u0026rsquo;\nOutput example: “d-XXXXXXXXXX”\n4. Navigate to PingOne Mappings and select Email Address from the dropdown list. Figure 3 – AWS Single Sign-On Attribute Mapping\nAlt Text: Screenshot of the AWS Single Sign-On configuration in PingIdentity.\nThe screen displays Step 2 of the setup process, where the SAML_SUBJECT attribute\nis mapped to the PingOne “Email Address” attribute.\nA red box highlights the mapping section in PingOne Mappings.\n5. Search for and select the group that you previously created to grant access to Amazon Q Developer, then click the “+” icon to add the group.\n6. Select Save. Figure 4 – Selecting PingIdentity Directory Groups for Amazon Q Developer Access\nAlt Text: Screenshot of Step 3 in the AWS Single Sign-On setup process\nin PingIdentity. The interface displays a group selection screen,\nwhere the “Amazon Q” group is listed. A plus icon (+) appears next to the group\nto add it, and the blue “Save” button is highlighted in the bottom-right corner.\nStep 2: Connect PingIdentity with IAM Identity Center This step involves configuring PingIdentity using credentials from the\nAWS IAM Identity Center to complete the authentication setup.\nIn the PingIdentity console, navigate to\nApplications Tab → Applications, and select the application you created in Step 1.\nSelect Enable Advanced Configuration and click Enable.\nFigure 5 – Enabling Advanced Configuration for the AWS Single Sign-On Application\nAlt Text: Screenshot of the PingIdentity Applications console showing\nthe selected AWS Single Sign-On application.\nThe overview displays key configuration sections including protocol (SAML),\nmapped attributes, selected policy, and access groups (Amazon Q).\nThe “Enable Advanced Configuration” option is highlighted near the bottom.\nScroll down and select Download Metadata.\nThis saves the metadata file to your computer; it will be used later in the configuration process.\nIn another browser tab, log in to your\nAWS IAM Identity Center console\nand select Choose your identity source.\nIn the Identity source section, select Change identity source\nfrom the Actions dropdown.\nFigure 6 – Changing the Identity Source in the IAM Identity Center Console\nAlt Text: Screenshot of the IAM Identity Center settings page,\nfocusing on the Identity source tab.\nThe page displays details such as identity source, authentication method,\nAWS access portal URL, issuer URL, and Identity Store ID.\nAn expanded Actions dropdown in the top-right corner highlights the options\n“Customize AWS access portal URL” and “Change identity source” in a red box.\nOn the next page, select External identity provider and click Next.\nIn the Service provider metadata section, copy the\nIAM Identity Center Assertion Consumer Service (ACS) URL.\nFigure 7 – Copying the IAM Identity Center ACS URL\nAlt Text: Screenshot of the “Configure external identity provider” step\nin the IAM Identity Center setup process.\nThe screen shows service provider metadata, including\nAWS access portal sign-in URL, IAM Identity Center ACS URL (highlighted in a red box),\nand the IAM Identity Center issuer URL.\nA “Download metadata file” button is displayed in the upper-right corner.\nNow, return to the PingIdentity browser tab, navigate to\nthe Configuration tab, and click the pencil icon to edit the details.\nPaste the ACS URL you copied from the IAM Identity Center console and click Save.\nFigure 8 – Configuring SAML Settings for AWS Single Sign-On in PingIdentity\nAlt Text: Two screenshots showing the configuration and editing process\nfor SAML settings in PingIdentity.\nThe first screenshot displays static configuration details including\nACS URL, signing key (“PingOne SSO Certificate for Administrators environment”),\nsigning method (“Response”), and signing algorithm.\nThe second screenshot shows the editable interface, with the ACS URL field\nhighlighted in red and dropdown menus for selecting signing key, signing method\n(Assertion, Response, or both), and the RSA_SHA256 algorithm.\nThese screens guide users through securing a proper SAML setup with AWS SSO.\nStep 3: Configure PingIdentity as an External Identity Provider (IdP) in IAM Identity Center\nThis step configures PingIdentity as an external IdP in\nIAM Identity Center, enabling federated access.\nReturn to the IAM Identity Center tab opened earlier.\nUpload the PingIdentity IdP SAML metadata file downloaded in\nStep 3 of the previous section, then click Next.\nFigure 9 – AWS IAM Identity Center Metadata\nAlt Text: Screenshot of the AWS Identity Center configuration interface\nwhere the user uploads the IdP SAML metadata XML file.\nThe metadata file is successfully selected.\nBelow it are empty fields for manually entering the IdP sign-in URL,\nIdP issuer URL, and IdP certificate.\nThe orange “Next” button is highlighted in the bottom-right corner.\nReview the list of changes. When ready, type ACCEPT, then select\nChange identity source. Step 4: Enable Provisioning and Identity-Aware Sessions in IAM Identity Center\nThis step involves enabling user provisioning and\nidentity-aware sessions in AWS IAM Identity Center\nto support dynamic access control.\nIn the\nIAM Identity Center Console,\nselect Settings from the left navigation panel.\nOn the Settings page, find and enable Automatic provisioning.\nThis immediately activates automatic provisioning in IAM Identity Center\nand displays the required information:\nSCIM endpoint Access token In the Inbound automatic provisioning dialog, copy each value.\nYou will need these for configuring provisioning in PingIdentity.\nSelect Close.\nNext, enable both identity-aware sessions and automatic provisioning.\nFigure 10 – IAM Identity Center Settings for Identity-Aware Sessions and Automatic Provisioning\nAlt Text: Two configuration options are shown: “Enable identity-aware sessions”\nand “Automatic provisioning.”\nBoth options display an Enable button on the right side highlighted in red.\nStep 5: Configure Provisioning Connections in PingIdentity This step explains how to configure Provisioning Connections in PingIdentity\nto enable automatic user and group management.\nIn the PingIdentity console, navigate to\nIntegrations → Provisioning.\nSelect the + icon → New Connection.\nUnder Connection Type, select Identity Store.\nFigure 11 – Provisioning Connection Setup in PingIdentity\nAlt Text: Screenshot of the Provisioning configuration in PingIdentity.\nThe left sidebar highlights the Provisioning tab, and the main panel shows\nthe Create a New Connection dialog with options for Identity Store\nand Gateway.\nThe Identity Store option is selected, and a plus icon at the top enables\nadding new connections.\nSelect SCIM outbound from the list and click Next.\nEnter a name for the connection and click Next.\nPaste the SCIM endpoint URL into the SCIM BASE URL field.\nUnder Authentication Method, select OAuth 2 Bearer Token.\nPaste the Access Token into the OAuth Access Token field.\nClick Test Connection to verify the setup, then select Next.\nFigure 12 – Authentication Details Configuration\nAlt Text: Screenshot of the PingIdentity interface showing the authentication\nsetup fields for SCIM Base URL, SCIM Version (2.0), OAuth 2 Bearer Token,\nand OAuth Access Token.\nThe Test Connection and Next buttons appear below.\n\u0026mdash;10. Navigate to User Filter Expression and change the value to:\nuserName Eq \u0026ldquo;%s\u0026rdquo;.\nSelect Save. (By default, the connection is created in a Disabled state.) Figure 13 – Editing the User Filter Expression for the Connection\nAlt Text: The final step of the Create a New Connection wizard in PingIdentity,\ndisplaying the configuration options for User Filter Expression, User Identifier,\nand group options.\nThe Save button is highlighted in the bottom-right corner.\nSelect the connection you just created and toggle the switch ON to activate it. Figure 14 – Activating the Connection\nAlt Text: Screenshot of the PingIdentity configuration console showing integration\nwith the IAM Identity Store, with a highlighted on/off toggle in the upper-right corner\nindicating that the connection is now activated.\nStep 6: Configure Provisioning Rules in PingIdentity This step covers defining provisioning rules in PingIdentity\nto determine how users and groups are synchronized.\nIn the PingIdentity console, navigate to Integrations → Provisioning.\nSelect the plus icon (+) → New Rule.\nEnter a Name and Description for the rule.\nSelect Create.\nSelect the plus icon (+) to choose the Connection created earlier.\nSelect Save.\nFigure 15 – Adding the IAM Identity Center Connection to the Rule\nAlt Text: Screenshot showing the final steps of linking IAM Identity Center\nto IAM Identity Store using PingIdentity.\nThe first image shows the IAM Identity Store connection listed under Available Connections\nwith a plus (+) icon to link it.\nThe second image shows the connection selected with PingOne Directory (P1) as the source\nand IAM Identity Store (SCIM) as the destination, with a highlighted Save button.\nIf you want to synchronize users from the PingIdentity directory, create a User Filter.\nTo do this, navigate to User Filter and select the pencil icon to edit.\nChoose the appropriate filter from the dropdown depending on your use case,\nthen select Save.\nIn this example, Group Name assigned for Amazon Q Developer access is selected.\nFigure 16 – User Filter in PingIdentity\nAlt Text: Screenshot of the Edit User Filter interface in IAM Identity Center.\nThe user filter is configured to provision users belonging to groups\nwith names containing “Amazon Q Developer”.\nThe condition logic is set to match if “Any” of the conditions are true.\nIf you want to synchronize a group from PingIdentity, configure Group Provisioning.\nNavigate to Group Provisioning and select the pencil icon to edit.\nSelect the appropriate group designated for Amazon Q Developer access and choose Save.\nFigure 17 – Configuring Group Provisioning in PingIdentity\nAlt Text: Screenshot of the Edit Group Provisioning interface in\nIAM Identity Center.\nThe “Amazon Q Developer” group is selected for outbound provisioning.\nThe Save button is highlighted at the bottom-left.\nNavigate to Attribute Mapping and select the pencil icon to edit the settings.\nRemove the Primary Phone attribute from the PingOne Directory.\nAdd a new attribute mapping where Username (PingOne Directory)\nmaps to displayName (IAM Identity Store).\nSelect Save.\nFigure 18 – Attribute Mapping Configuration in PingIdentity\nAlt Text: Screenshot of the Edit Attribute Mapping interface in PingIdentity.\nThe list shows mappings between PingOne Directory and IAM Identity Store attributes,\nsuch as Family Name, Given Name, Username, Email Address, and Primary Phone.\nA newly added mapping Username → displayName appears.\nThe Add and Save buttons are highlighted for guidance.\nSelect the rule you created and toggle the switch to activate the rule. This will automatically provision users/groups from PingIdentity to IAM Identity Center via SCIM.\nFigure 19 – Synchronization Status of Users and Groups via SCIM\nAlt Text: IAM Identity Center sync summary showing successful provisioning\nof users and groups.\nThe first screenshot highlights two impacted users successfully synchronized.\nThe second screenshot highlights a group successfully synchronized.\nThe sync status is shown as “ACTIVE”, confirming that the integration\nbetween PingOne and AWS IAM Identity Center is working properly.\nStep 7: Grant Access to Amazon Q Developer This step includes identifying and subscribing the groups that need\naccess to Amazon Q Developer.\nIn the\nAmazon Q Developer console,\nunder Subscriptions, add the IAM Identity Center groups\nthat require access.\nSelect Subscribe, then search for the group name.\nChoose Assign.\nFigure 20 – Amazon Q Developer Subscription Page\nAlt Text: Screenshot of the “Subscriptions” page in the Amazon Q Developer console.\nThe “Groups” tab is selected, showing “Amazon Q Developer” with subscription status Subscribed.\nThe “Amazon Q Developer” group is highlighted with a red box.\nSetting Up Amazon Q Developer with IAM Identity Center This section guides you through installing the Amazon Q Developer extension\nand configuring authentication through IAM Identity Center.\nTo install the Amazon Q Developer extension in your IDE,\nfollow the steps outlined in the\nAWS documentation.\nAfter installation, select the Amazon Q icon in your IDE.\nChoose a Sign-in option.\nSelect Use with Pro license, then choose Continue.\nSelect Continue again.\nEnter your Start URL — available from the IAM Identity Center Console.\nFigure 21 – IAM Identity Center Access Portal URL\nAlt Text: Screenshot of the IAM Identity Center settings page,\nshowing the identity source configuration.\nThe AWS access portal URL and Identity Store ID are highlighted in red.\nThe Settings tab is selected in the navigation panel.\nEnter the Region where your identity directory is hosted, then choose Continue. Select Open in the dialog to redirect to your browser. The browser will redirect to PingOne, where you enter your\nPingIdentity credentials, then select Sign On. Once authentication succeeds, choose Allow access to complete the login. Figure 22 – Setting Up Amazon Q Developer Extension in Visual Studio Code\nAlt Text: Screen recording in Visual Studio Code showing the user selecting\nthe Amazon Q icon in the sidebar.\nA login window appears, explaining that the user must authenticate\nwith PingIdentity through IAM Identity Center before accessing\nAmazon Q Developer features.\nValidate Configuration Once the previous steps are completed successfully,\nyou can begin using Amazon Q Developer’s code suggestions.\nFigure 23 – Amazon Q Developer Example\nAlt Text: Screen recording from Visual Studio Code showing\nAmazon Q Developer generating sample code in the editor.\nCleanup To avoid incurring charges after testing, complete the following cleanup steps:\n1. Remove the PingIdentity Application In the PingIdentity console, navigate to Applications. Find and delete the AWS Single Sign-On application configured for IAM Identity Center. 2. Reset IAM Identity Center Configuration In the AWS IAM Identity Center console: Navigate to Settings → Identity source. Change the identity source back to the default\nIAM Identity Center directory if PingIdentity is no longer used. 3. Revoke Subscriptions and Access In the Amazon Q Developer console: Go to Subscriptions and remove assigned groups\nsuch as Amazon Q Developer or CodeWhisperer trial. This action deactivates access and prevents future costs.\n4. Uninstall Amazon Q Developer Extension If desired, you can uninstall the Amazon Q Developer extension\nfrom Visual Studio Code to fully revert your environment. Conclusion In this article, we demonstrated how to use existing PingIdentity credentials\nto access Amazon Q Developer through integration with IAM Identity Center.\nWe provided a step-by-step guide to configure\nPingIdentity as an external identity provider (IdP) for IAM Identity Center.\nFinally, we described how to connect the\nAmazon Q Developer extension in your IDE to AWS using PingIdentity credentials,\nenabling seamless authentication and usage.\nIf you have any questions or feedback, feel free to leave a comment below.\nLearn More About AWS Services Amazon Q Developer IAM Identity Center AWS Toolkit for Visual Studio Code About the Author Sid Vantair is a Solutions Architect at AWS supporting strategic accounts.\nHe is passionate about solving complex technical challenges\nto help customers overcome barriers.\nOutside of work, he values time with his family\nand encourages a love of learning in his children.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"AWS for Industries\nEnergy Virtual Assistant: Transforming Utility Customer Service with AWS Generative AI by Darren Roback and Jeremy Cianella on 10 JUL 2025 in\nAmazon Bedrock, Amazon Bedrock Guardrails,\nAmazon CloudWatch, Amazon Connect,\nAmazon DynamoDB, Amazon Lex,\nAmazon Timestream, AWS Lambda,\nEnergy (Oil \u0026amp; Gas), Industries – Permalink\nIn the era of accelerating digital transformation, electric utility providers are facing unprecedented challenges in meeting customer expectations for fast, efficient, and accessible service.\nUtility contact centers in particular struggle to deliver efficient customer service. Traditional Interactive Voice Response (IVR) systems can handle straightforward, direct requests via keypad input or basic voice commands—such as reporting an outage or checking an account balance. However, more complex, ambiguous, and multi-turn requests often require escalation to live agents, creating bottlenecks in the support process.\nThis limitation becomes even more serious during severe weather events or large-scale outages, when call volume can spike within minutes—often overwhelming even well-staffed centers. The challenge is further compounded by the need to integrate with multiple backend systems such as Customer Information Systems (CIS), Billing Information Systems (BIS), Meter Data Management Systems (MDMS), Outage Management Systems (OMS), and various knowledge bases required to respond to customer inquiries. All of this results in longer handling times and increased customer frustration.\nModern utility contact centers must effectively manage what we refer to as the “ABCDs” of utility customer service. Each core function requires access to different systems and specialized domain expertise:\nAccount management: Opening, closing, retrieving, and updating customer account information; often requires interaction with CIS. Billing: Retrieving account balances, billing history, and processing payments — often requires interaction with BIS. Consumption: Analyzing and explaining energy consumption patterns from smart meter data — often requires interaction with MDMS. Dispatch: Creating service requests, reporting outages, checking request status, and scheduling maintenance — often requires interaction with OMS. To effectively handle these functions, customer service representatives must be highly trained and experienced. They must understand complex electricity pricing structures, interpret energy consumption data, explain billing calculations, and navigate complicated policies and procedures. This specialized knowledge takes months to develop, leading to long onboarding times for new hires and difficulty maintaining consistent service quality across all customer interactions.\nLimitations of traditional IVR systems and the operational complexity of the utility industry have opened the door for advanced AI-powered solutions. Generative AI—with its ability to understand natural language, process complex queries, and produce human-like responses—offers a promising approach to addressing these challenges.\nLarge Language Models (LLMs) enable us to build virtual assistants that more accurately understand customer intent, handle a wider range of requests without human intervention, and provide more nuanced, context-aware responses.\nTo address these challenges, we developed the Energy Virtual Assistant — an advanced approach to customer service that combines Generative AI with agentic capabilities, intelligent decision-making through chain-of-thought reasoning, and deep integration with utility systems and available enterprise data. This solution blends the power of LLMs with domain knowledge and system integration capabilities tailored to the energy industry.\nIn this article, we discuss the benefits of Generative AI in customer service, present the solution architecture, provide a step-by-step implementation guide, and share recommended next steps for deploying this solution in utility contact centers.\nBenefits of Generative AI in Customer Service Generative AI represents a major leap forward in customer service technology,\nbringing a comprehensive set of capabilities that reshape how organizations interact\nwith their customers.\nPersonalization at scale Unlike traditional systems, generative AI can produce responses that are not only\naccurate but also personalized to each customer\u0026rsquo;s communication style, preferences,\nand interaction history. This transforms ordinary customer service into a nuanced,\ndeeply personalized experience, making customers feel genuinely understood.\nEmotional intelligence and sentiment analysis With advanced sentiment analysis, generative AI can detect subtle nuances in customer\ncommunication and adjust tone and approach accordingly. Whether a customer is angry,\nconfused, or satisfied, the system can deliver empathetic and contextually appropriate\nresponses that reflect human-like understanding.\nMultilingual capabilities and cultural awareness Generative AI breaks down language barriers with strong multilingual support,\noffering near-native fluency across many languages. Beyond translation, it ensures\nculturally appropriate communication, understanding context and subtleties that\ntraditional translation tools often miss. This creates a global yet personalized\ncustomer service experience.\nUnified data integration Generative AI acts as an intelligent data orchestrator, seamlessly integrating\ninformation from organizational data silos to generate a holistic view of\u0026hellip;\nOperational efficiency and cost optimization Generative AI can significantly improve cost efficiency by reducing average handling\ntime, increasing first-contact resolution rates, fully automating frequent requests,\nand eliminating overtime labor costs due to its 24/7 availability.\nExceptional scalability Utility contact centers commonly struggle with fluctuating interaction volumes,\nespecially during emergencies like large-scale outages, storms, or wildfires.\nGenerative AI-powered contact centers can instantly scale to handle demand spikes,\nmaintaining service quality whether processing ten or ten thousand interactions\nsimultaneously. This ensures reliability in all situations.\nAlways-on availability Most importantly, generative AI enables continuous 24/7 customer support without\nthe high costs associated with traditional staffing models. Customers can access\nassistance anytime, significantly improving service accessibility and satisfaction.\nSolution Overview The Energy Virtual Assistant is designed to support common customer service\nuse cases in the utility industry, such as outage reporting, consumption analytics,\naccount information updates, and bill payment processing.\nCustomers interact with the Energy Virtual Assistant through multiple channels\n(voice or chat), powered by Generative AI to provide fast, accurate, intelligent,\nand personalized responses.\nThe assistant is built using multiple AWS services, including:\nAmazon Connect – A cloud-based contact center solution allowing organizations to deliver customer service at any scale. It supports omni-channel communication, skills-based routing, and AI-powered features such as conversational IVR. It serves as the entry point for customer voice interactions with the Energy Virtual Assistant.\nAmazon Lex – A fully managed AI service for building conversational interfaces (chatbots) using voice or text. It uses the underlying technology of Amazon Alexa and provides the natural language understanding layer for the assistant.\nAmazon Bedrock – A fully managed service providing access to high-performance foundation models (FMs) via a unified API. It enables the Generative AI capabilities of the assistant.\nAgents for Amazon Bedrock – A feature that enables users to create AI agents capable of automatically analyzing and executing complex business tasks by orchestrating FMs, knowledge bases, and APIs. The Energy Virtual Assistant is a Bedrock agent using chain-of-thought reasoning and integrating with utility systems to process customer requests.\nAWS Lambda – A serverless compute service that executes code when triggered by events. Lambda provides the compute layer for API integrations to backend utility systems.\nAmazon DynamoDB – A fully managed serverless NoSQL database used here to simulate utility backend systems such as Account, Billing, and Outage Management.\nAmazon Timestream – A fully managed time-series database used to store and analyze energy consumption data, often referred to as MDMS.\nGuardrails for Amazon Bedrock – A feature providing safety controls such as content filtering, topic blocking, keyword filtering, and redaction of sensitive information to protect interactions between customers and the foundation model.\nBefore diving into solution architecture, consider how this solution improves typical\nutility customer service scenarios.\nFor example, if a customer calls about an unusually high bill, a human agent would previously\nneed to check multiple systems: usage history, meter readings, rate structures, and even\nweather data. With our solution, the virtual assistant can automatically collect and\nanalyze all of this information and provide context-aware explanations and recommendations —\nall without human intervention.\nSolution Architecture The architecture diagram below provides an overview of the system components.\nLet\u0026rsquo;s walk through each part.\nFigure 1: Solution architecture\nEnergy customers interact with the utility provider through common requests\nvia the voice channel. Although this solution is designed for voice, it can be\nextended to support other channels in the future.\nCustomers call into Amazon Connect and are immediately placed into a\ncontact flow.\nAn Amazon Lex bot embedded in the Amazon Connect flow acts as the\nspeech-to-text interface as customers interact with the Energy Virtual Assistant.\nThe Energy Virtual Assistant is powered by an Amazon Bedrock agent that\nreceives, processes, and classifies customer requests.\nThe Amazon Bedrock agent sends customer conversation history, available\nactions, and the current request to a foundation model (FM) for processing.\nThe foundation model uses chain-of-thought reasoning to determine the\nappropriate steps to satisfy the customer request.\nAction groups represent the actions and system integrations the agent\ncan invoke to fulfill customer requests. These include:\nAccount Action Group – Opens accounts, retrieves account information,\nupdates account details, or closes accounts.\nBilling Action Group – Retrieves balances, payment histories, and\nprocesses customer payments.\nTicketing Action Group – Creates service tickets, checks ticket status,\nretrieves all tickets for a specific account, reports outages, and schedules maintenance.\nConsumption Action Group – Retrieves energy consumption data, provides\ncost estimates based on usage, and explains consumption patterns.\nDate/Time Action Group – Determines current date/time and supports\nrange-based queries needed by the FM.\nOnce required actions are completed, an Amazon Bedrock FM is used to\nprocess and prepare the final response to the customer.\nAmazon Connect Call Flow The call flow diagram below illustrates the steps performed when customers\ninteract with Amazon Connect via the voice channel. Let\u0026rsquo;s walk through each step.\nFigure 2: Amazon Connect call flow\nWhen the customer enters the Amazon Connect flow, the Enable Logging\nblock is used to turn on flow logs stored in Amazon CloudWatch.\nFlow logs assist with troubleshooting and tracking the steps taken\nduring a customer call.\nThe Set Language block configures the language and voice settings\nfor text-to-speech (TTS) used in the flow.\nThe Main Menu block plays the initial greeting and activates the\nAmazon Lex bot (with its configured intents) to begin customer interaction.\nThe intents used in this flow include:\nEnergyVirtualAgentIntent – Represents the Amazon Bedrock Energy Virtual\nAgent and handles all customer requests such as outage reporting,\nconsumption queries, account updates, and bill payments.\nThis intent includes multiple utterances to recognize a wide variety of\ncustomer statements.\nSpeakToAgentIntent – Used to transfer the customer directly to a live\nagent in the contact center.\nConfigured with utterances matching phrases commonly used when customers\nask to speak to a human.\nGoodbyeIntent – Used to end the customer interaction. Configured\nwith common farewell utterances.\nThe Set Queue block determines the queue where customers will be\nplaced if they request a live agent.\nThe Transfer to Queue block routes callers to the live agent queue.\nThe Queue at Capacity block plays a TTS message informing customers\nthat the queue is full.\nThe Goodbye Prompt block sends a farewell message via TTS.\nThe Error Prompt block notifies the customer if an issue occurs\nduring the call flow.\nPrerequisites Before you begin, ensure that your environment includes the following components:\nCreated an Amazon Connect instance\nwhich is used to support customer interactions with the Energy Virtual Assistant through the inbound voice channel.\nClaimed an Amazon Connect phone number\nwhich is associated with the flow created during deployment.\nAn Amazon Connect BasicQueue\nwhich is created by default with Amazon Connect.\nEnabled access to Claude 3.5 Haiku\nin Amazon Bedrock, serving as the foundation model (FM) for the Amazon Bedrock agent.\nWe use the Claude 3.5 inference profile in this solution, which means you must enable model access in the AWS Regions us-east-1, us-east-2, and us-west-2. Permissions to deploy the AWS CloudFormation template\nDeploying the solution The deployment process for this solution includes the following steps:\nCreate a CloudFormation stack to deploy all foundational components.\nConfigure the EnergyVirtualAgent Lex Bot intent, because as of this writing, Amazon Lex does not yet support creating intents through CloudFormation or API.\nAssociate the Amazon Connect phone number with the Amazon Connect flow.\nDuring deployment, the system automatically generates simulated customer data within the Account, Billing, and Consumption systems.\nSpecifically, the datasets created include:\nAccountData: five simulated customers, including fields such as\nAccountNumber, CustomerName, EmailAddress, MeterNumber, PhoneNumber, PremiseNumber, RateCode, and ServiceAddress.\nBillingData: twelve months of billing data for each customer, including\nBillingDate, BillingStatus, DueDate, EnergyCharge, KWhConsumption,\nServiceCharge, and TotalAmount.\nIntervalData: three months of 15-minute interval consumption data for each meter, including\nL1–L2–L3 Voltage and Current, InstantaneousPower, and Frequency.\nCreating the CloudFormation stack Before starting, clone the\nAWS Samples Energy Virtual Assistant GitHub repository\nto your local machine, as we will use the CloudFormation YAML template for the first part of the deployment process.\nFollow these steps:\nOpen the AWS CloudFormation console and select\nCreate stack \u0026gt; With new resources (standard).\nIn the Prerequisite – Prepare template section, select Choose an existing template, then choose Upload a template file.\nClick Choose file, then navigate to the \\deployment directory inside the cloned repository and upload the file cloudformation_template.yaml.\nClick Next to move to the Specify stack details screen.\nIn the Stack name field, enter EnergyVirtualAssistant.\nIn the ConnectInstanceArn field, enter the Amazon Resource Name (ARN) of your Amazon Connect instance.\nIn the ConnectQueueArn field, enter the ARN of your Amazon Connect BasicQueue.\nClick Next to move to the Configure stack options screen.\nCheck the box to allow AWS CloudFormation to create IAM resources with custom names.\nClick Next to go to the Review and create screen.\nReview all configuration settings, then click Submit to create the CloudFormation stack.\nAfter submitting, wait for the stack status to update to CREATE_COMPLETE before proceeding to the next steps.\nConfiguring the Lex Bot When the CloudFormation stack deployment is complete, you may proceed to configure the Amazon Bedrock agent intent inside the Amazon Lex bot.\nIn this step, you will use the values EnergyVirtualAgentId and\nEnergyVirtualAgentAliasId generated from the CloudFormation stack outputs.\nFollow these steps:\nOpen the Amazon Lex console and select the EnergyVirtualAgentLexBot that was created automatically.\nUnder Draft version and English (US), select Intents.\nSelect Add intent, then choose Use built-in intent.\nSelect AMAZON.BedrockAgentIntent – GenAI feature as the built-in intent type.\nIn the Intent name field, enter EnergyVirtualAgentIntent and click Add.\nIn the Description field, enter:\nIntent to handle customer energy requests.\nIn the Bedrock Agent ID field, enter the value EnergyVirtualAgentId from the CloudFormation output.\nIn the Agent Alias ID field, enter the value EnergyVirtualAgentAliasId from the CloudFormation output.\nNavigate to the \\deployment directory in the cloned repository and open the file\nagent_intent_utterances.md.\nIn the Sample utterances section, select Plain text and paste the entire contents of the utterances file.\nClick Save intent at the bottom of the screen.\nClick Build in the upper right corner to apply all changes.\nGo to the Bot versions page and select Create version.\nClick Create to generate a new bot version and wait for the process to complete.\nUnder the Deployment section, select Aliases, then choose the PROD alias.\nClick Associate version with alias, then select the new version you created.\nClick Associate to finalize the linkage.\nLinking the phone number You are now ready to associate your previously claimed\nAmazon Connect phone number with the contact flow created during the CloudFormation deployment.\nFollow these steps:\nLog in to your Amazon Connect instance and open the Phone numbers page.\nSelect your phone number from the list.\nIn the Contact flow/IVR section, enter EnergyVirtualAgentFlow into the search field.\nSelect EnergyVirtualAgentFlow and click Save to assign the contact flow to the phone number.\nTesting the solution In the repository, the test directory includes several test scenarios that you can use to interact with and validate the Energy Virtual Assistant.\nTo experience and interact with the Energy Virtual Assistant, simply call the Amazon Connect phone number that you associated with the contact flow, then ask questions to the Amazon Bedrock agent, using the simulated customer data generated during deployment.\nCustomizing the solution Readers are encouraged to customize this solution to better fit their real-world needs after cloning the repository locally.\nThe DynamoDB and Timestream tables in the backend—used as a mock representation of CRM, Billing, Outage, and MDMS systems—may differ from those in a production environment.\nFirst, determine the types of customer requests you want the system to process, then customize the backend systems accordingly to support those interactions.\nThis solution is primarily designed to illustrate the art of the possible of generative-AI-enabled assistants, while also acting as an acceleration vehicle for proof-of-concept (POC) activities.\nCleaning up resources To delete the solution and avoid additional costs associated with AWS resources used in this deployment, follow these steps:\nLog in to your Amazon Connect instance and navigate to Phone numbers.\nSelect your phone number from the list.\nIn the Contact flow/IVR section, enter EnergyVirtualAgentFlow into the search field.\nDeselect the EnergyVirtualAgentFlow contact flow and click Save to remove its association with the phone number.\nOpen the CloudFormation console in your AWS account.\nLocate the EnergyVirtualAssistant stack and select Delete.\nThis action will delete all resources deployed by the CloudFormation stack, except for the CloudWatch log groups created for the Lambda functions and the Amazon Connect instance.\nYou may choose to keep or delete these logs depending on your needs.\nSummary In this solution, we demonstrated how to build agentic solutions on\nAmazon Bedrock and how to integrate multiple AWS services to automate customer service workflows.\nImplementing generative AI in customer service offers several advantages over traditional IVR, such as:\nEliminating rigid rule-based IVR flows Providing 24/7 customer service Automatically scaling during periods of high interaction volume We encourage you to deploy, test, and customize this solution within your own environment to quickly realize the value of using generative AI to enhance customer experience and service efficiency.\nDarren Roback Darren is a Sr. Solutions Architect at Amazon Web Services (AWS), based in St. Louis, Missouri.\nHe has over 20 years of experience in the information technology (IT) industry and is passionate about Data Analytics, Generative AI, Internet of Things (IoT), and Security and Compliance.\nAt AWS, Darren works with customers in the energy and utility sectors to help address business challenges using AWS technologies.\nOutside of work, he enjoys woodworking and spending time with his family.\nJeremy Cianella Jeremy Cianella is a Sr. Solutions Architect based in Miami, Florida, supporting customers in the utility and renewable energy sectors.\nHe has over 15 years of experience in utility operations, enterprise architecture, and cloud technologies, helping customers execute digital transformation initiatives.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Building a secure serverless streaming pipeline with Amazon MSK Serverless, Amazon EMR Serverless, and IAM by Shubham Purwar, Nitin Kumar, and Prashanthi Chinthala on 02 JUN 2025 in\nAmazon Athena, Amazon EMR,\nAmazon Managed Streaming for Apache Kafka (Amazon MSK),\nAnalytics, AWS Big Data\nPermalink • Comments • Share\nThe exponential growth and massive volume of streaming data have made it an essential resource for organizations around the world.\nTo fully harness this potential, real-time analytics is critical to extract actionable insights.\nGenerated from various sources including social networks, Internet of Things (IoT) sensors, and user interactions, streaming data enables businesses to quickly respond to emerging trends and events, make informed decisions, and maintain competitive advantage.\nTypically, streaming applications use Apache Kafka for data ingestion and Apache Spark Structured Streaming for processing.\nHowever, integrating and securing these components introduces significant challenges for users.\nThe complexity of managing certificates, keystores, and TLS configurations required to connect Spark Streaming with Kafka brokers often demands deep technical expertise.\nA managed serverless framework can greatly simplify this process, eliminating the need for manual configuration and enabling seamless integration between critical components.\nTo simplify management and security in traditional streaming architectures, you can use Amazon Managed Streaming for Apache Kafka (Amazon MSK).\nThis fully managed service streamlines the ingestion and processing of data.\nAmazon MSK Serverless removes the need for cluster management and automatic scaling, while also strengthening security by integrating with AWS Identity and Access Management (IAM) for authentication and authorization.\nThis unified approach replaces the complex process of managing certificates and security keys required by TLS client authentication through AWS Certificate Manager, simplifying operations and enhancing data protection.\nFor example, when a client attempts to send data into a cluster, MSK Serverless verifies the identity and access permissions of the client through IAM.\nTo efficiently process data, you can use Amazon EMR Serverless along with a Spark application built using Spark Structured Streaming, enabling near real-time processing.\nThis configuration seamlessly handles large volumes of data from MSK Serverless, using IAM authentication to ensure high performance and strong security during processing.\nThis blog presents a comprehensive end-to-end solution for processing data from MSK Serverless using EMR Serverless Spark Streaming jobs secured with IAM authentication.\nAdditionally, it demonstrates how to query processed data using Amazon Athena, providing an integrated and streamlined data processing and analytics workflow.\nThis solution enables near real-time querying of the latest processed data from MSK Serverless and EMR Serverless through Athena, delivering instant insights and analytics.\nSolution overview The diagram below illustrates the architecture you will build in this blog.\nThe workflow consists of the following steps:\nThe architecture begins with an MSK Serverless cluster configured with IAM authentication.\nAn Amazon Elastic Compute Cloud (Amazon EC2) instance running a Python script producer.py acts as the data producer, sending sample data to a Kafka topic in the cluster.\nA Spark Streaming job reads data from the Kafka topic, stores it in Amazon Simple Storage Service (Amazon S3), and creates corresponding tables in the AWS Glue Data Catalog.\nWhile continuously consuming data from the Kafka topic, the job keeps updating new incoming data.\nWith checkpointing enabled, the job tracks processed records and can resume from the last checkpoint in case of failures, ensuring seamless data processing.\nTo analyze the data, users can leverage Athena — a serverless query service.\nAthena allows interactive SQL queries to be run directly on data stored in Amazon S3, without requiring complex infrastructure.\nPrerequisites Before starting, ensure that you have:\nAn active AWS account with billing enabled An IAM user with administrator access (AdministratorAccess policy) or specific permissions to create and manage resources such as VPC, subnet, security group, IAM roles, NAT gateway, internet gateway, EC2 client, MSK Serverless, EMR Serverless, Amazon EMR Studio, and S3 buckets Sufficient VPC capacity in your selected AWS Region Although using an IAM user with administrator access works fine,\nit is recommended that in production environments you follow the principle of least privilege — by creating custom IAM policies containing only required permissions.\nThe IAM user created for this tutorial is granted AdministratorAccess, but such elevated permissions are not strictly necessary.\nFor this blog, we will create the solution resources in the us-east-2 Region using AWS CloudFormation templates.\nIn the following sections, we guide you through configuring resources and deploying the solution.\nCreate MSK Serverless and EMR Serverless resources The vpc-msk-emr-serverless-studio.yaml stack will create the following resources:\nVPC, subnets, security groups, IAM roles, NAT gateway, internet gateway, EC2 client, MSK Serverless, EMR Serverless, EMR Studio, and S3 buckets.\nTo create the resources for this solution, follow these steps:\nLaunch the vpc-msk-emr-serverless-studio stack using the CloudFormation template.\nAmazon Web Services Sign-In\nProvide parameter values as listed in the table below:\nParameters Description Sample value EnvironmentName Environment name prefix for resources. msk-emr-serverless-pipeline InstanceType EC2 instance type for the Amazon MSK client. t2.micro LatestAmiId Latest Amazon Linux 2023 AMI ID for EC2. You may use default value. /aws/service/ami-amazon-linux-latest/al2023-ami-kernel-6.1-x86_64 VpcCIDR IP address range (CIDR notation) for the VPC. 10.192.0.0/16 Parameters Description Sample value PublicSubnet1CIDR IP range for the public subnet in the first Availability Zone. 10.192.10.0/24 PublicSubnet2CIDR IP range for the public subnet in the second Availability Zone. 10.192.11.0/24 PrivateSubnet1CIDR IP range for the private subnet in the first Availability Zone. 10.192.20.0/24 Parameters Description Sample value PrivateSubnet2CIDR IP range for the private subnet in the second Availability Zone. 10.192.21.0/24 The stack creation process may take about 10 minutes.\nAfter the stack is created, check the Outputs tab to view the stack output values.\nNext, you will configure the data ingestion process to send data into a Kafka topic from the Kafka EC2 instance.\nProduce records to Kafka topic Follow these steps to configure data ingestion:\nAccess the Amazon EC2 console and navigate to the EC2 instance created via the CloudFormation template.\nLog in to the EC2 instance using Session Manager, a feature of AWS Systems Manager.\nSelect the instance named msk-emr-serverless-blog, then choose Connect.\nCreate a Kafka topic in MSK Serverless from the EC2 instance.\na. In the export command below, replace my-endpoint with the value of MSKBootstrapServers displayed in the CloudFormation Outputs:\n$ sudo su - ec2-user $ BS=\u0026lt;your-msk-serverless-endpoint (e.g.) boot-xxxxxx.yy.kafka-serverless.us-east-2.amazonaws.com:9098\u0026gt; b. Run the following command on the EC2 instance to create a Kafka topic named sales_data_topic.\nKafka client is already installed in the directory /home/ec2-user for the ec2-user, along with the MSK IAM Authentication JAR and the client configuration file located at:\n/home/ec2-user/kafka_2.12-2.8.1/bin/client.properties The following shows the content of client.properties:\nsecurity.protocol=SASL_SSL sasl.mechanism=AWS_MSK_IAM sasl.jaas.config=software.amazon.msk.auth.iam.IAMLoginModule required; sasl.client.callback.handler.class=software.amazon.msk.auth.iam.IAMClientCallbackHandler Create topic command:\n/home/ec2-user/kafka_2.12-2.8.1/bin/kafka-topics.sh \\ --bootstrap-server $BS \\ --command-config /home/ec2-user/kafka_2.12-2.8.1/bin/client.properties \\ --create --topic sales_data_topic \\ --partitions 10 Output:\nCreated topic sales_data_topic. Run the following command to produce records into the Kafka topic using the Python script syntheticSalesDataProducer.py available in the EC2 instance.\nUpdate the Region value based on the AWS Region you are using. nohup python3 -u syntheticSalesDataProducer.py --num_records 1000 \\ --sales_data_topic sales_data_topic --bootstrap_server $BS \\ --region=us-east-2 \u0026gt; syntheticSalesDataProducer.log \u0026amp; Understanding Amazon MSK IAM authentication with EMR Serverless Amazon MSK IAM authentication enables secure authentication and authorization for Kafka clusters (MSK Serverless) using IAM roles.\nWhen integrated with EMR Serverless Spark Streaming, Amazon MSK IAM authentication allows Spark jobs to safely access Kafka topics, using IAM roles for fine-grained access control.\nThis ensures highly secure data processing and streaming.\nConfiguring IAM policy To allow EMR Serverless jobs to authenticate with the MSK Serverless cluster via IAM, you must attach Kafka-related permissions to the EMR Serverless job execution role.\nThese permissions enable the job to perform necessary operations on the Kafka cluster, Kafka topics, and consumer groups.\nThe following IAM policy must be attached to the EMR Serverless job execution role:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;kafka-cluster:Connect\u0026#34;, \u0026#34;kafka-cluster:DescribeCluster\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kafka:\u0026lt;AWS-REGION\u0026gt;:\u0026lt;ACCOUNTID\u0026gt;:cluster/\u0026lt;SERVERLESS_CLUSTER_NAME\u0026gt;/\u0026lt;ID\u0026gt;\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;kafka-cluster:CreateTopic\u0026#34;, \u0026#34;kafka-cluster:DescribeTopic\u0026#34;, \u0026#34;kafka-cluster:WriteData\u0026#34;, \u0026#34;kafka-cluster:ReadData\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kafka:\u0026lt;AWS-REGION\u0026gt;:\u0026lt;ACCOUNTID\u0026gt;:topic/\u0026lt;SERVERLESS_CLUSTER_NAME\u0026gt;/*/*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;kafka-cluster:AlterGroup\u0026#34;, \u0026#34;kafka-cluster:DescribeGroup\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kafka:\u0026lt;AWS-REGION\u0026gt;:\u0026lt;ACCOUNTID\u0026gt;:group/\u0026lt;SERVERLESS_CLUSTER_NAME\u0026gt;/*/*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] } The configuration above relates to the following actions:\nConnect, DescribeCluster – Required to initiate secure connections and retrieve metadata. DescribeTopic, ReadData, WriteData – Allow reading and writing data (consuming and producing data). CreateTopic (optional) – Allows dynamic topic creation if necessary. AlterGroup, DescribeGroup – Required for managing consumer groups in streaming jobs. These permissions ensure that the Spark Streaming job can authenticate and interact securely with MSK Serverless resources using its IAM role.\nRequired dependent libraries To enable Amazon MSK IAM authentication in Spark (especially on EMR Serverless), include the following JAR dependencies in the Spark Streaming job via the sparkSubmitParameters:\nspark-sql-kafka-0-10_2.12 – Kafka connector for Spark Structured Streaming, providing DataFrame APIs to read and write Kafka data. aws-msk-iam-auth – Provides IAM authentication mechanism required to connect to MSK Serverless using AWS_MSK_IAM SASL mechanism. You can include these dependencies directly using the \u0026ndash;packages option when submitting the EMR Serverless job.\nExample:\npackages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,software.amazon.msk:aws-msk-iam-auth:2.2.0 EMR Serverless automatically downloads these JARs from Maven Central (or another configured repository) at runtime.\nYou do not need to manually bundle these JARs unless offline use or strict version requirements apply.\nConfiguring Spark Streaming job for Amazon MSK IAM authentication In your Spark Streaming application, configure the Kafka source with SASL properties to enable IAM-based authentication.\nThe following code snippet demonstrates the required configuration:\ntopic_df = (spark.readStream .format(\u0026#34;kafka\u0026#34;) .option(\u0026#34;kafka.bootstrap.servers\u0026#34;, kafka_bootstrap_servers) .option(\u0026#34;subscribe\u0026#34;, topic_input) .option(\u0026#34;startingOffsets\u0026#34;, \u0026#34;earliest\u0026#34;) .option(\u0026#34;kafka.security.protocol\u0026#34;,\u0026#34;SASL_SSL\u0026#34;) .option(\u0026#34;kafka.sasl.mechanism\u0026#34;,\u0026#34;AWS_MSK_IAM\u0026#34;) .option(\u0026#34;kafka.sasl.jaas.config\u0026#34;,\u0026#34;software.amazon.msk.auth.iam.IAMLoginModule required;\u0026#34;) .option(\u0026#34;kafka.sasl.client.callback.handler.class\u0026#34;,\u0026#34;software.amazon.msk.auth.iam.IAMClientCallbackHandler\u0026#34;) .load() .selectExpr(\u0026#34;CAST(value AS STRING)\u0026#34;) ) Key properties:\nkafka.security.protocol = SASL_SSL – Enables encrypted communication via SSL with SASL authentication. kafka.sasl.mechanism = AWS_MSK_IAM – Instructs Kafka to use IAM-based SASL authentication. kafka.sasl.jaas.config = software.amazon.msk.auth.iam.IAMLoginModule required; – Specifies AWS-provided login module for IAM integration. kafka.sasl.client.callback.handler.class = software.amazon.msk.auth.iam.IAMClientCallbackHandler – Handles signing and actual IAM authentication. With this configuration, Spark uses IAM credentials associated with the EMR Serverless job execution role to authenticate with MSK Serverless — no additional credentials, certificates, or secrets are required.\nProcessing data using EMR Serverless streaming job with Amazon MSK IAM authentication Follow these steps to submit a Spark Streaming job that processes data from MSK Serverless:\nSubmit the Spark Streaming job to EMR Serverless using the AWS Command Line Interface (AWS CLI), which is pre-installed on the EC2 instance.\nLog in to the EC2 instance via Session Manager.\nSelect the instance named msk-emr-serverless-blog, then choose Connect. Run the following command to submit the streaming job:\nProvide the parameters from the CloudFormation stack output. sudo su - ec2-user aws emr-serverless start-job-run \\ --application-id \u0026lt;APPLICATION ID\u0026gt; \\ --execution-role-arn \u0026lt;EXECUTION ROLE ARN\u0026gt; \\ --mode \u0026#39;STREAMING\u0026#39; \\ --job-driver \u0026#39;{ \u0026#34;sparkSubmit\u0026#34;: { \u0026#34;entryPoint\u0026#34;: \u0026#34;s3://\u0026lt;EMR BLOG SCRIPT BUCKET\u0026gt;/emr_pyspark_streaming_script/pysparkStreamingBlog.py\u0026#34;, \u0026#34;entryPointArguments\u0026#34;:[\u0026#34;--topic_input\u0026#34;,\u0026#34;sales_data_topic\u0026#34;,\u0026#34;--kafka_bootstrap_servers\u0026#34;,\u0026#34;\u0026lt;BOOTSTRAP URL WITH PORT\u0026gt;\u0026#34;,\u0026#34;--output_s3_path\u0026#34;,\u0026#34;s3://\u0026lt;EMR STREAMING OUTPUT BUCKET\u0026gt;/output/sales-order-data/\u0026#34;,\u0026#34;--checkpointLocation\u0026#34;,\u0026#34;s3://\u0026lt;EMR STREAMING OUTPUT BUCKET\u0026gt;/checkpointing/checkpoint-sales-order-data/\u0026#34;,\u0026#34;--database_name\u0026#34;,\u0026#34;emrblog\u0026#34;,\u0026#34;--table_name\u0026#34;,\u0026#34;sales_order_data\u0026#34;], \u0026#34;sparkSubmitParameters\u0026#34;: \u0026#34;--conf spark.hadoop.hive.metastore.client.factory.class=com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory --conf spark.executor.cores=2 --conf spark.executor.memory=5g --conf spark.driver.cores=2 --conf spark.driver.memory=5g --conf spark.executor.instances=5 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,software.amazon.msk:aws-msk-iam-auth:2.2.0\u0026#34; }}\u0026#39; After submitting the job, log in to EMR Studio using the URL from the EmrServerlessStudioURL CloudFormation output.\nIn the navigation pane, choose Applications under Serverless.\nSelect the application ID matching the value\nEmrServerlessSparkApplicationID from the CloudFormation stack output.\nIn the Streaming job runs tab, verify that the job was successfully submitted and wait for it to start running.\nValidating data in Athena After the EMR Serverless Spark Streaming job has run and created the processed data table in the Data Catalog, follow these steps to validate the data using Athena:\nOpen the Athena console and access the query editor.\nSelect Data Catalog as the data source.\nSelect the emrblog database — created by the streaming job.\nTo validate the data, run the following query:\nSELECT DATE_TRUNC(\u0026#39;minute\u0026#39;, date) AS minute_window, ROUND(SUM(total_amount), 2) AS total_amount FROM emrblog.sales_order_data WHERE DATE_TRUNC(\u0026#39;day\u0026#39;, date) = CURRENT_DATE GROUP BY DATE_TRUNC(\u0026#39;minute\u0026#39;, date) ORDER BY minute_window DESC; Clean up To delete the resources and avoid charges, follow these steps:\nLog in to EMR Studio using the URL shown in the EmrServerlessStudioURL CloudFormation output.\nIn the navigation pane, choose Applications under Serverless.\nSelect the application ID matching the value\nEmrServerlessSparkApplicationID in the CloudFormation output.\nIn the Streaming job runs tab, select the running job and cancel it.\nAccess the AWS CloudFormation console and delete the stack named\nvpc-msk-emr-serverless-studio.\nConclusion In this blog, we presented a serverless pipeline for processing streaming data with IAM authentication, helping you focus on extracting analytics insights instead of managing complex infrastructure.\nYou can customize your Spark Streaming code in EMR Serverless to apply transformations and filters, ensuring that clean data is loaded into Amazon S3.\nThis solution combines the power of Amazon EMR Serverless Spark Streaming and MSK Serverless, integrated securely through IAM authentication — enabling you to simplify your streaming workflow without managing the integration between Amazon MSK and Amazon EMR Spark Streaming.\nAbout the authors Shubham Purwar is an AWS Analytics Specialist Solution Architect.\nHe helps organizations maximize their data potential by designing and implementing analytics solutions that are scalable, secure, and high-performance on AWS.\nWith deep expertise in AWS analytics services, Shubham works closely with customers to understand unique business requirements and build customized solutions that deliver actionable insights and drive business growth.\nIn his free time, Shubham enjoys spending time with family and traveling around the world.\nNitin Kumar is a Cloud Engineer (ETL) at AWS, specializing in AWS Glue.\nWith over 10 years of experience, he excels at helping customers manage large-scale data workloads, focusing on data processing and analytics.\nHe is dedicated to helping customers overcome ETL-related challenges and build scalable data processing and analytics pipelines on AWS.\nIn his free time, Nitin enjoys watching movies, cooking, and spending time with his family.\nPrashanthi Chinthala is a Cloud Engineer (DIST) at AWS.\nShe helps customers solve challenges related to Amazon EMR and build scalable data processing and analytics pipelines on AWS.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Goals: Become familiar with the working environment and members of First Cloud Journey. Build foundational knowledge of AWS and learn how to use both the Management Console and CLI tools. Tasks completed during the week: Day Task Start Date Completion Date Reference Material 2 - Introduced myself and connected with FCJ members - Reviewed and noted key internship rules and guidelines 08/11/2025 08/11/2025 3 - Studied an overview of AWS and its service categories - Learned how to navigate AWS Console and work with AWS CLI 09/09/2025 09/09/2025 https://youtu.be/2PQYqH_HkXw?si=AAWaEt0lYjuMHKdz 4 - Created an AWS Free Tier account - Set up security using Virtual MFA Device - Hands-on practice: + Create AWS account + Log in using both Root and IAM users 10/09/2025 10/09/2025 https://000001.awsstudygroup.com/ 5 - Explored cost control using AWS Budgets - Hands-on practice: + Create Budget from a template + Configure a custom Cost Budget 11/09/2025 11/09/2025 https://000007.awsstudygroup.com/vi/ 6 - Researched AWS Support Plans and compared different support tiers 12/09/2025 12/09/2025 https://000009.awsstudygroup.com/vi/ Week 1 Outcomes: Developed a clear understanding of AWS and its essential cloud services. Successfully registered and set up an AWS Free Tier account. Explored major AWS service groups such as Compute, Storage, Networking, Databases, and Security. Improved proficiency in using both the AWS Management Console and AWS CLI. Enabled MFA to enhance account security. Practiced logging in with Root user and IAM user credentials. Learned how to create and manage spending plans using AWS Budgets. Gained clarity on the differences between AWS Support tiers, including Basic, Developer, Business, and Enterprise. "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/","title":"Worklog Overview","tags":[],"description":"","content":"This worklog documents my 12-week internship at First Cloud Journey, summarizing the key learning activities and project tasks completed each week as follows:\nWeek 1: Introduction to the AWS environment, IAM, MFA, AWS CLI, and foundational cloud services\nWeek 2: AWS networking: VPC, Subnets, Route Tables, VPN, VPC Peering, and Transit Gateway\nWeek 3: Working with S3, RDS, and Cloud9; participating in Cloud Day Vietnam; initial research for the team project architecture\nWeek 4: Exploring AWS storage services, VM Import/Export, and drafting the first version of the project proposal\nWeek 5: Designing the project UI (Admin/Staff), implementing login flows, and collaborating with the Backend team\nWeek 6: Building the project’s AWS architecture, reviewing mentor feedback, refining the design, and preparing for the midterm exam\nWeek 7: Implementing the serverless frontend, working with API Gateway and Lambda, and integrating authentication using Amazon Cognito\nWeek 8: Studying AWS Well-Architected pillars: Security, Reliability, Performance Efficiency, and Cost Optimization\nWeek 9: Advanced API Gateway topics: Path Parameters, Query Strings, Integration Proxy, Usage Plans, and CloudWatch Logging\nWeek 10: Developing Lambda CRUD functions, importing Excel data into DynamoDB, testing APIs with Postman, and applying request validation\nWeek 11: DevOps practices on AWS: IaC, container services, Canary Deployments, Stage Variables, and Route 53\nWeek 12: Learning CloudFront, Docker, and ECR; building an Auto-Scoring Lambda function and storing results in DynamoDB\n"},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/4.2-event2/","title":"Discover Agentic AI – Amazon QuickSuite Workshop","tags":[],"description":"","content":"Discover Agentic AI – Amazon QuickSuite Workshop - Date: November 7, 2025 - Location: AWS Vietnam Office, Bitexco Financial Tower, HCMC\nEvent Overview An exclusive workshop focused on the shift from passive Generative AI to autonomous Agentic AI. The event featured the first live demonstration of Amazon QuickSuite in Vietnam and introduced the AWS LIFT Program to lower financial barriers for adoption.\nKey Objectives:\nDefine Agentic AI: Clarify the concept of autonomous AI agents that can reason and execute tasks. Introduce Amazon QuickSuite: Showcase the unified data visualization (QuickSight) and generative AI (Quick Suite Q) platform. Enable Hands-on Learning: Provide a practical environment to build AI concepts with expert guidance. Facilitate Adoption: Offer an $80,000 USD credit through the AWS LIFT Program to accelerate R\u0026amp;D. Key Takeaways \u0026amp; Learnings Focus on Autonomy: The design goal of Agentic AI is to build systems that act on a user\u0026rsquo;s behalf, not just provide information. Ecosystem Approach is Crucial: Effective agents require a connected network of tools, like the one provided by QuickSuite, to link data sources with action logic. Early Adoption Creates Advantage: Gaining proficiency with tools like QuickSuite before they become mainstream offers a significant competitive edge. Funding Accelerates Innovation: Financial incentives like the LIFT program enable companies to experiment and innovate more quickly. Application to Work Explore QuickSuite for Analytics: Investigate integrating QuickSight and Quick Suite Q to create \u0026ldquo;Analyst Agents\u0026rdquo; that can automate data reporting and analysis. Secure R\u0026amp;D Funding: Apply for the AWS LIFT Program to secure credits for upcoming AI-related research and development projects. Identify Automation Use Cases: Audit internal operations to find repetitive, multi-step tasks suitable for autonomous execution by an AI agent. Engage with Implementation Partners: Collaborate with partners like Cloud Kinetics for complex architectural design and implementation, reducing in-house development risks. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-perequisites/","title":"5.2 Prerequisites","tags":[],"description":"","content":"Module 2: Prerequisites - Preparing Account \u0026amp; Tools Module Objectives Create \u0026amp; configure AWS account Set up IAM roles \u0026amp; policies Verify required access permissions Set up cost monitoring \u0026amp; alerts Part 1: AWS Account Setup Step 1: Create AWS Account If you do not have an AWS account:\nAccess https://aws.amazon.com/ Click \u0026ldquo;Create an AWS Account\u0026rdquo; Enter email, password, account name Choose Support Plan (Free tier available) Verify email \u0026amp; set up billing information Step 2: Log in to AWS Console Access https://console.aws.amazon.com/ Enter root account email \u0026amp; password Verify MFA (Multi-Factor Authentication) if required Note: It is recommended to enable MFA for the root account for security\nPart 2: IAM Setup - Create Admin User Step 1: Access IAM Dashboard From AWS Console, search for \u0026ldquo;IAM\u0026rdquo; Click \u0026ldquo;IAM\u0026rdquo; from the services list Click \u0026ldquo;Users\u0026rdquo; in the navigation menu Step 2: Create IAM User for Workshop Click \u0026ldquo;Create user\u0026rdquo; Enter User name: \u0026ldquo;workshop-admin\u0026rdquo; Check \u0026ldquo;Provide user access to the AWS Management Console - optional\u0026rdquo; Check \u0026ldquo;Users must create a new password at next sign-in - Recommended\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Step 3: Assign Permissions Select \u0026ldquo;Attach policies directly\u0026rdquo;\nSearch and check the following policies:\nAdministratorAccess (allows all services) Click \u0026ldquo;Next\u0026rdquo;\nStep 4: Review \u0026amp; Create Review the user information Click \u0026ldquo;Create user\u0026rdquo; Download the \u0026ldquo;.csv\u0026rdquo; file containing credentials Step 5: Login using IAM User Copy the User sign-in link from the confirmation screen Open the link in a new browser Login using user name \u0026amp; password Part 3: Verify Permissions Verify access permissions for AWS Services Login to AWS Console using IAM user Access each service to verify permissions: Cognito: https://console.aws.amazon.com/cognito/ Lambda: https://console.aws.amazon.com/lambda/ EC2: https://console.aws.amazon.com/ec2/ API Gateway: https://console.aws.amazon.com/apigateway/ S3: https://console.aws.amazon.com/s3/ VPC: https://console.aws.amazon.com/vpc/ Verification: You should see \u0026ldquo;Create application\u0026rdquo; (not an error message)\nPart 4: Resources Naming Convention To manage resources easily, use the following naming convention:\n{project-name}-{service}-{environment}\nExamples:\nsmoking-cessation-cognito-dev smoking-cessation-lambda-auth-dev smoking-cessation-db-pg-dev (PostgreSQL on EC2) smoking-cessation-db-mongo-dev (MongoDB on EC2) smoking-cessation-api-dev smoking-cessation-frontend-dev smoking-cessation-vpc-dev Benefit: Easy to search \u0026amp; manage resources in the console\nTroubleshooting Cannot create IAM User Check: Are you logged in using the root account or another IAM user? Solution: Log in again using the root account to create an IAM user Permission Denied errors Verify: IAM policies attached to the user Check: Do the policies include the service you are using? Contact AWS support if elevated permissions are needed Notes From now on, all actions use the IAM user, not the root account Each service will have a specific IAM role (created in later modules) Free Tier provides sufficient resources for learning Achieved Results After Module 2, you will have:\nAn activated AWS account IAM user \u0026ldquo;workshop-admin\u0026rdquo; with admin permissions Access to all required AWS services Ready for Module 3 (Setup Cognito) "},{"uri":"https://thienluhoan.github.io/workshop-template/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Smoking Cessation Support System Proposal 1. Executive Summary This proposal outlines the design and implementation of a cloud-based Smoking Cessation Support Platform aimed at helping users quit smoking through data tracking, behavioral insights, AI coaching, and community engagement.\nThe system integrates a modern, scalable backend infrastructure deployed on AWS Cloud, ensuring high availability, security, and seamless user experience.\nThe goal is to provide an intelligent, personalized journey for users to monitor, plan, and achieve their smoking cessation goals—while giving administrators and health coaches the tools to support and guide them.\n2. System Objectives Help users build and follow personalized quit-smoking plans. Track smoking behavior and health progress in real-time. Offer AI-driven coaching, reminders, and motivational feedback. Enable social interaction and encouragement among members. Provide a secure, cloud-native infrastructure for scalability and reliability. 3. Key Features User-Oriented Features Registration \u0026amp; Membership Plans: Users can register, select subscription tiers, and make payments for premium features. Smoking Status Tracking: Log daily cigarette consumption, cost, and frequency. Personalized Cessation Plans: Create and adjust quitting plans based on user habits and goals. Progress Tracking: Display statistics such as smoke-free days, money saved, and health improvements. Motivational Notifications: Automated reminders and encouraging messages delivered periodically. Achievements \u0026amp; Badges: Unlock milestones such as “7 Days Smoke-Free” or “₫100K Saved”. Community Interaction: Share achievements, advice, and encouragement within a supportive network. AI Coaching Agent: Personalized guidance and advice powered by machine learning. Health Device Integration: Collect data from wearable or IoT health devices for progress tracking. Admin \u0026amp; Operator Features Dashboard \u0026amp; Reports: Monitor user metrics, engagement, and health impact analytics. Coach Portal: Health coaches can interact with users via chat or video for counseling. Feedback \u0026amp; Rating Management: Track and respond to user satisfaction metrics. Payment \u0026amp; Subscription Management: Manage fee packages and user subscriptions. 4. System Architecture (AWS Cloud) The system leverages AWS-managed services for scalability and security, as visualized in the architecture diagram.\nFrontend Layer Amazon S3 hosts the static website (React or Angular frontend). Amazon CloudFront distributes the web content globally and handles SSL/TLS encryption. Authentication \u0026amp; Authorization Amazon Cognito manages user sign-up, sign-in, and identity federation, ensuring secure access for both end-users and coaches. Application Layer AWS Lambda powers serverless services such as payment handling or lightweight API operations. Network Load Balancer (NLB) distributes requests across backend EC2 instances. EC2 Instances (Private Subnet) host core microservices: User Service Cessation Service Social Media Service Data Layer PostgreSQL Databases for user and cessation data (on EC2 or RDS). MongoDB for social features and unstructured data. S3 Bucket (Backup) stores periodic encrypted database backups. DevOps Pipeline GitLab CI/CD Pipeline automates deployment to Amazon ECR (Elastic Container Registry) and EC2 instances. VPC Endpoint ensures secure communication with AWS services without exposing traffic to the public internet. EC2 Instance Connect Endpoint enables controlled administrative access. Figure 1 – AWS-based cloud architecture for the Smoking Cessation Platform. 5. Security and Compliance Data Encryption: All sensitive data encrypted in transit (TLS) and at rest (AES-256). IAM Policies: Fine-grained access control for different system roles. Private Subnets: Backend and databases are isolated from public exposure. VPC Link \u0026amp; Endpoints: Secure internal communication between services. Backup Strategy: Automated daily backups to S3 with versioning and lifecycle policies. 6. Scalability and Performance Auto Scaling: EC2 and Lambda functions scale based on user demand. CDN Caching: CloudFront caches static content for faster global delivery. Load Balancing: NLB ensures traffic distribution and fault tolerance. Decoupled Microservices: Modular design allows independent scaling of user, cessation, and social services. 7. Future Enhancements Integration with mobile apps for Android and iOS. Advanced AI predictive relapse detection using user patterns. Real-time chat and video counseling. Integration with third-party payment gateways. Gamified health challenges and reward systems. 8. Expected Outcomes Increased smoking cessation success rates. Improved user motivation and engagement. Scalable platform capable of supporting large user bases. Secure, compliant, and maintainable cloud infrastructure. "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Understand and practice AWS networking services, especially Amazon VPC and its components. Set up and configure network connections in a Hybrid Cloud environment: VPN, DirectConnect, Hybrid DNS. Implement and configure advanced AWS networking features: VPC Peering, Transit Gateway, Network ACL, Load Balancer. Gain experience with CloudFormation to automate network resource deployment. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about AWS Virtual Private Cloud (VPC) + Subnet + Route table + ENI, EIP + Endpoint + Internet gateway - VPC Security and Multi-VPC features - VPN - DirectConnect - LoadBalancer - ExtraResources 15/09/2025 15/09/2025 https://youtu.be/O9Ac_vGHquM?si=_eLRx1ohGnWONjq6 3 - Practice Amazon VPC and AWS Site-to-Site VPN connections - Practice: + Create VPC + Deploying Amazon EC2 Instances + Setting Up Site-to-Site VPN Connection in AWS 16/09/2025 16/09/2025 https://000003.awsstudygroup.com 4 - Set up Hybrid DNS with Route 53 Resolver - Practice: + Initialize CloudFormation Template + Connecting to RDGW + Deploy Microsoft AD + Setup DNS 17/09/2025 17/09/2025 https://000010.awsstudygroup.com 5 - Setting up VPC Peering - Cross-Peer DNS - Network ACL 18/09/2025 18/09/2025 https://000019.awsstudygroup.com/vi/ 6 - Set up AWS Transit Gateway - Practice: + Create Transit Gateway + Create Transit Gateway Attachments + Create Transit Gateway Route Tables + Add Transit Gateway Routes to VPC Route Tables 19/09/2025 19/09/2025 https://000020.awsstudygroup.com/ Week 2 Achievements: Explored AWS VPC and its components: Subnet, Route Table, ENI, EIP, Endpoint, Internet Gateway. Understood VPC security concepts and Multi-VPC features. Learned the basics of VPN, DirectConnect, Load Balancer, and extra resources. Practiced creating a VPC and deploying EC2 instances inside it. Set up a Site-to-Site VPN connection between on-premises and AWS. Improved hands-on skills with AWS virtual networking. Configured Hybrid DNS with Route 53 Resolver. Deployed Microsoft AD using CloudFormation and set up DNS. Successfully connected to RDGW. Configured VPC Peering between multiple VPCs. Set up Cross-Peer DNS for domain resolution across VPCs. Managed network security using Network ACL. Deployed and configured AWS Transit Gateway. Created Transit Gateway Attachments and Route Tables. Added Transit Gateway routes to VPC Route Tables. Completed a multi-VPC network connectivity model. "},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/4.3-event3/","title":"AWS Cloud Mastery Series #3 - Security Pillar Deep Dive","tags":[],"description":"","content":"AWS Cloud Mastery Series #3 - Security Pillar Deep Dive - Date: December 1, 2025 - Location: AWS Vietnam Office, Bitexco Financial Tower, HCMC\nEvent Overview An in-depth workshop focused on the Security Pillar of the AWS Well-Architected Framework. The event provided knowledge and best practices for securing cloud workloads.\nKey Objectives:\nDeep Dive into the Security Pillar: Analyze the design principles and key areas of security on AWS. Identity and Access Management: Gain a deep understanding of AWS IAM, MFA, and best practices for access control. Data Protection: Explore techniques for encrypting data at-rest and in-transit. Automation and Monitoring: Learn how to use AWS Config, CloudTrail, and Security Hub to monitor and automate security controls. Key Takeaways \u0026amp; Learnings Security is a Shared Responsibility: Understand the shared responsibility model and the customer\u0026rsquo;s role in securing applications in the cloud. Defense in Depth: Apply multiple layers of security to protect resources comprehensively. Automation is Key: Automating security checks and remediation reduces human error and allows for faster responses to threats. Application to Work Re-evaluate IAM Policies: Review and strengthen existing IAM policies according to the principle of least privilege. Implement Security Monitoring: Set up AWS Security Hub for a centralized, comprehensive view of the security posture. Enhance Data Encryption: Ensure all sensitive data is encrypted using AWS KMS. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.3-setup-cognito/","title":"5.3 Setup Cognito","tags":[],"description":"","content":"Module 3: Create Cognito User Pool \u0026amp; Authentication Module Objectives Create a new Cognito User Pool Configure Sign-up \u0026amp; Sign-in options Create App Client for frontend Set up User Groups (admin, coach, user) Create test users Test authentication flow Duration: 3-4 hours\nPart 1: Create Cognito User Pool Step 1: Access Cognito Console Login to AWS Console (https://console.aws.amazon.com/) Search for \u0026ldquo;Cognito\u0026rdquo; Click \u0026ldquo;Cognito\u0026rdquo; from services list Click \u0026ldquo;User pools\u0026rdquo; (left menu) Click \u0026ldquo;Create user pool\u0026rdquo; Step 2: Fill \u0026ldquo;Set up resources for your application\u0026rdquo; After clicking \u0026ldquo;Create user pool\u0026rdquo;, you will see the form \u0026ldquo;Set up resources for your application\u0026rdquo;:\n2.1 Define your application Application type: Select \u0026ldquo;Single-page application (SPA)\u0026rdquo; This is the type of your React application Name your application: Enter smoking-cessation-app Limit: 128 characters, letters, numbers, spaces, +, =, ,, ., @, - 2.2 Options for sign-in identifiers Select these options:\n☑️ Email (Checked) ☐ Phone number (Unchecked) ☐ Username (Unchecked) Reason: Email is the simplest way for users to sign in\n2.3 Self-registration ☑️ Enable self-registration (Checked) This allows users to self-register on the platform The login page will display a \u0026ldquo;Sign up\u0026rdquo; link 2.4 Required attributes for sign-up Select required attributes:\n☑️ email (Already checked because Email is selected for sign-in) ☑️ name (Check - store user\u0026rsquo;s name) 2.5 Add a return URL (optional) Click the \u0026ldquo;Return URL\u0026rdquo; field\nEnter: https://localhost:3000/callback\nThis is where Cognito redirects after successful login Note: For development, localhost supports HTTP; for production, must use HTTPS After completing, click \u0026ldquo;Create user directory\u0026rdquo; at the bottom\nStep 3: Configure Security Requirements After clicking \u0026ldquo;Authentication methods\u0026rdquo;, you will reach the \u0026ldquo;Authentication methods\u0026rdquo; page:\nPassword policy:\nChoose Cognito defaults in Password policy mode Edit email configuration:\nSelect Send email with Cognito in Email provider Click Save changes Account recovery:\nSelf-service account recovery: ☑️ Enable Recovery method: ☑️ Email ☑️ SMS Step 4: Configure Sign-up Experience \u0026ldquo;Configure sign-up experience\u0026rdquo; page:\nSelf-registration (already enabled in Step 2):\nEnable self-registration: ✅ Yes Allow users to sign themselves up: ✅ Yes Standard attributes to collect:\n☑️ email (Required) ☑️ name (Required) ☐ phone_number (Optional) ☐ family_name (Optional) Verification settings:\nHow will a user be confirmed?: Email Cognito will send a confirmation link via email Click \u0026ldquo;Next\u0026rdquo;\nStep 5: Configure Message Delivery \u0026ldquo;Configure message delivery\u0026rdquo; page:\nEmail provider:\nSelect: Cognito (default) Note: Free tier allows 50 emails/day. For production, use Amazon SES. From email address:\nUse Cognito default email Emails will be sent from no-reply@cognito.amazonaws.com Click \u0026ldquo;Next\u0026rdquo;\nStep 6: Review \u0026amp; Create Final \u0026ldquo;Review and create\u0026rdquo; page:\nReview all settings you configured:\nApplication type: Single-page application (SPA) Application name: smoking-cessation-app Sign-in experience Security requirements Sign-up experience Message delivery Scroll down, enter User pool name:\nName: smoking-cessation-users This is the name of the User Pool (different from the Application name) Click \u0026ldquo;Create user pool\u0026rdquo;\n⏳ Wait 2-3 minutes for the user pool to be created. You will see a success message when completed.\nStep 7: Success Page - Quick Setup Guide After the user pool is created, you will see the \u0026ldquo;Set up resources for your application\u0026rdquo; page with the following:\nThis page displays:\n\u0026ldquo;Your application \u0026hellip; have been created successfully!\u0026rdquo; - Success notification \u0026ldquo;Check out your sign-in page\u0026rdquo; - Link to test login page \u0026ldquo;What\u0026rsquo;s the development platform for your single page application?\u0026rdquo; - Options (React, Angular, JavaScript) Code examples - Frontend integration instructions Note: You will configure integration code in the next module. For now, click \u0026ldquo;Go to overview\u0026rdquo; to go to the user pool overview page.\nPart 2: Retrieve User Pool ID After the user pool is created:\nYou will see the success message Note the User Pool ID: Format ap-southeast-1_xxxxxxxxxxxxx Example: ap-southeast-1_GAXOSoku5 Save it to your .env file: COGNITO_USER_POOL_ID=ap-southeast-1_dskxxxxt3 COGNITO_REGION=ap-southeast-1 ## Part 3: Create App Client ### Step 1: Access App Integration 1. From the User Pool dashboard (smoking-cessation-users) 2. Left menu: Click \u0026#34;App integration\u0026#34; 3. Click \u0026#34;App clients and analytics\u0026#34; 4. Click \u0026#34;Create app client\u0026#34; ![App Integration Menu](../assets/03-cognito-app-integration.png) ### Step 2: Configure App Client 1. **App client name**: `smoking-cessation-frontend` 2. **Refresh token expiration**: 30 days 3. **Access token expiration**: 1 hour (3600 seconds) 4. **ID token expiration**: 1 hour (3600 seconds) 5. **Token validity units**: hours 6. Click \u0026#34;Next\u0026#34; ![App Client Basic Config](../assets/03-cognito-app-client-config.png) ### Step 3: Configure Authentication Flows 1. **Authentication flows and security** 2. Select: - ✅ ALLOW_USER_PASSWORD_AUTH (for username/password login) - ✅ ALLOW_REFRESH_TOKEN_AUTH (for refresh token rotation) - ✅ ALLOW_USER_SRP_AUTH (secure password authentication) 3. Click \u0026#34;Next\u0026#34; ![Auth Flows](../assets/03-cognito-auth-flows.png) ### Step 4: Configure Hosted UI (Optional but Recommended) 1. **Hosted UI settings** 2. **Hosted UI domain name**: `smoking-cessation-dev` - Click \u0026#34;Check availability\u0026#34; - If taken, append `-{number}` (e.g., `smoking-cessation-dev-2`) 3. **Allowed callback URLs** (add for your frontend): - For development: `http://localhost:3000/callback` - For production: `https://yourdomain.com/callback` 4. **Allowed sign-out URLs**: - For development: `http://localhost:3000/logout` - For production: `https://yourdomain.com/logout` 5. **Allowed OAuth 2.0 scopes**: - ✅ openid - ✅ email - ✅ profile 6. Click \u0026#34;Next\u0026#34; ![Hosted UI Config](../assets/03-cognito-hosted-ui.png) ### Step 5: Advanced Security Settings 1. **Advanced security settings** 2. **Prevent user existence errors**: ✅ **Enable** - This prevents attackers from discovering valid usernames 3. Click \u0026#34;Create app client\u0026#34; ![Advanced Security](../assets/03-cognito-advanced-security.png) ⏳ **Wait for the app client to be created** ### Step 6: Retrieve App Client ID After the App Client is created: 1. Find the **Client ID** in the app client details - Example: `4175kqc33olfjinhkll4jme379` 2. Save to `.env`: COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379\n![App Client ID](../assets/03-cognito-client-id.png) --- ## Part 4: Create User Groups ### Step 1: Access User Groups 1. From the User Pool (smoking-cessation-users) 2. Left menu: Click \u0026#34;User groups\u0026#34; 3. Click \u0026#34;Create group\u0026#34; ![User Groups Menu](../assets/03-cognito-user-groups-menu.png) ### Step 2: Create Admin Group 1. **Group name**: `admins` 2. **Description**: `Platform administrators with full access` 3. **Assign IAM role to this group**: (Optional, skip for now) 4. Click \u0026#34;Create group\u0026#34; ![Create Admin Group](../assets/03-cognito-create-admin-group.png) ### Step 3: Create Coach Group 1. Click \u0026#34;Create group\u0026#34; 2. **Group name**: `coaches` 3. **Description**: `Coaches who help users quit smoking` 4. Click \u0026#34;Create group\u0026#34; ![Create Coach Group](../assets/03-cognito-create-coach-group.png) ### Step 4: Create User Group 1. Click \u0026#34;Create group\u0026#34; 2. **Group name**: `users` 3. **Description**: `Regular users of the platform` 4. Click \u0026#34;Create group\u0026#34; ![Create User Group](../assets/03-cognito-create-user-group.png) ## Part 5: Create Test Users ### Step 1: Access Users 1. From the User Pool (smoking-cessation-users) 2. Left menu: Click \u0026#34;Users\u0026#34; 3. Click \u0026#34;Create user\u0026#34; ![Users Menu](../assets/03-cognito-users-menu.png) ### Step 2: Create Admin User 1. **Username**: `admin-test` 2. **Email address**: `admin@test.com` 3. **Temporary password**: `TempAdminPass123!` 4. **Mark email as verified**: ✅ **Check** 5. **Mark phone number as verified**: ☐ 6. Click \u0026#34;Create user\u0026#34; ![Create Admin User](../assets/03-cognito-create-admin.png) ### Step 3: Assign Admin User to Admin Group 1. Click the newly created user `admin-test` 2. Scroll down to \u0026#34;Group membership\u0026#34; 3. Click \u0026#34;Add user to groups\u0026#34; 4. Select the `admins` group 5. Click \u0026#34;Add user to groups\u0026#34; ![Assign to Admin Group](../assets/03-cognito-assign-admin-group.png) ### Step 4: Create Coach User 1. Go back to Users list 2. Click \u0026#34;Create user\u0026#34; 3. **Username**: `coach-test` 4. **Email address**: `coach@test.com` 5. **Temporary password**: `TempCoachPass123!` 6. **Mark email as verified**: ✅ **Check** 7. Click \u0026#34;Create user\u0026#34; ![Create Coach User](../assets/03-cognito-create-coach.png) ### Step 5: Assign Coach User to Coach Group 1. Click the user `coach-test` 2. Scroll down to \u0026#34;Group membership\u0026#34; 3. Click \u0026#34;Add user to groups\u0026#34; 4. Select the `coaches` group 5. Click \u0026#34;Add user to groups\u0026#34; ![Assign to Coach Group](../assets/03-cognito-assign-coach-group.png) ### Step 6: Create Regular User 1. Go back to Users list 2. Click \u0026#34;Create user\u0026#34; 3. **Username**: `user-test` 4. **Email address**: `user@test.com` 5. **Temporary password**: `TempUserPass123!` 6. **Mark email as verified**: ✅ **Check** 7. Click \u0026#34;Create user\u0026#34; 8. Assign to the `users` group (same as Step 5) ![Create Regular User](../assets/03-cognito-create-user.png) --- ## Part 6: Set Permanent Passwords (Optional) If you want users to be able to log in immediately without changing the temporary password: 1. From Users list 2. Click the user (e.g., `admin-test`) 3. Click \u0026#34;Actions\u0026#34; → \u0026#34;Set password\u0026#34; 4. **Permanent password**: `AdminPass123!` 5. **Make this permanent password**: ✅ **Check** 6. Click \u0026#34;Set password\u0026#34; ![Set Permanent Password](../assets/03-cognito-set-password.png) --- ## Part 7: Additional App Client Configuration (Authentication Methods) ### Step 1: Configure App Client Details 1. From User Pool → App integration → App clients 2. Click `smoking-cessation-frontend` 3. Scroll down → \u0026#34;Client secret\u0026#34; - ⚠️ **Note**: If you create a Client Secret, frontend JavaScript cannot use it (because it cannot store secrets safely on the client) - **Recommendation**: Do not create a Client Secret for public frontend 4. Leave \u0026#34;Client secret\u0026#34; as-is (do not create) ![App Client Details](../assets/03-cognito-app-client-details.png) --- ## Part 8: Enable Cognito Hosted UI (Optional) ### Step 1: Configure Hosted UI Domain 1. From User Pool → App integration → Domain name 2. If already configured → Skip 3. If not → Click \u0026#34;Create domain\u0026#34; 4. **Domain prefix**: `smoking-cessation-dev` 5. Click \u0026#34;Create domain\u0026#34; ⏳ **Wait 1-2 minutes** for the domain to be created ### Step 2: Test Hosted UI 1. From App integration → App clients 2. Click `smoking-cessation-frontend` 3. Scroll down to \u0026#34;Hosted UI settings\u0026#34; 4. Find **Hosted UI domain URL**: - Format: `https://smoking-cessation-dev.auth.us-east-1.amazoncognito.com` 5. Click the link to open the Hosted UI 6. Login test: - Username: `admin-test` - Password: `AdminPass123!` - Should redirect to `http://localhost:3000/callback` (or configured callback URL) ![Hosted UI Login](../assets/03-cognito-hosted-ui-login.png) --- ## Part 9: Summary Information Save the following information into the `.env` file: ```env # Cognito Configuration COGNITO_REGION=us-east-1 COGNITO_USER_POOL_ID=us-east-1_dskUsnKt3 COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 COGNITO_DOMAIN=smoking-cessation-dev COGNITO_HOSTED_UI_DOMAIN=https://smoking-cessation-dev.auth.us-east-1.amazoncognito.com # Test User Credentials (remove before production) TEST_ADMIN_USER=admin-test TEST_ADMIN_PASSWORD=AdminPass123! TEST_COACH_USER=coach-test TEST_COACH_PASSWORD=TempCoachPass123! TEST_USER=user-test TEST_USER_PASSWORD=TempUserPass123! "},{"uri":"https://thienluhoan.github.io/workshop-template/3-blogstranslated/","title":"Blogs","tags":[],"description":"","content":"Blog 1 – Secure access to Amazon Q Developer using PingIdentity This blog explains how organizations can integrate PingIdentity with AWS IAM Identity Center to enable secure SAML-based authentication for Amazon Q Developer.\nIt walks through configuring PingIdentity as an external IdP, enabling AWS SSO, downloading and exchanging SAML metadata, setting up SCIM provisioning for automatic user and group synchronization, and assigning IAM Identity Center groups to Amazon Q Developer Pro subscriptions.\nThe blog also demonstrates how developers authenticate in their IDE using PingIdentity credentials, providing a seamless and secure login experience without managing separate AWS accounts.\nBlog 2 – Building an Energy Virtual Assistant using Amazon Bedrock, Amazon Connect, and Amazon Lex This blog introduces how to build an Energy Virtual Assistant that handles customer requests through natural-language conversations using Amazon Connect, Amazon Lex, and Amazon Bedrock Agents.\nIt describes how utility companies can automate common operations—such as outage reporting, billing inquiries, account updates, and consumption insights—by integrating Bedrock Agents with DynamoDB, Timestream, and simulated utility backend systems.\nThe blog provides detailed instructions for deploying the CloudFormation stack, configuring the Bedrock Agent intent inside Lex, linking Amazon Connect phone numbers, and testing the full interaction flow.\nThis solution demonstrates how generative AI can modernize utility contact centers by improving accuracy, reducing workloads, and enabling intelligent, context-aware voice automation.\nBlog 3 – Building a secure serverless streaming pipeline with Amazon MSK Serverless and Amazon EMR Serverless This blog outlines how to build a fully serverless data streaming pipeline using Amazon MSK Serverless for Kafka ingestion and Amazon EMR Serverless to process streaming data with Spark Structured Streaming.\nIt explains how IAM authentication replaces traditional TLS certificate management, allowing Spark jobs to securely connect to MSK Serverless without keystores or secrets.\nThe blog walks through deploying infrastructure with CloudFormation, creating Kafka topics, producing streaming data from an EC2 client, configuring Spark Streaming with IAM authentication, writing processed data to Amazon S3, integrating with AWS Glue Data Catalog, and querying real-time results using Amazon Athena.\nThis solution demonstrates how organizations can simplify streaming workloads, enhance security, and scale analytics without managing underlying clusters.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives Stay engaged in First Cloud Journey activities and actively connect with team members. Strengthen core AWS knowledge and practice using both the Console and the CLI. Complete hands-on labs with Amazon S3 and Amazon RDS; explore GenAI fundamentals using Amazon Bedrock. Tasks Completed This Week Day Task Start Date Completion Date Reference 2 - Reviewed AWS Cloud9 (not available in the current environment).\n- Continued reading documentation and preparing lab steps for Amazon S3 and Amazon RDS. 16/09/2025 16/09/2025 https://000057.awsstudygroup.com/vi/1-introduce/ 3 - Completed the S3 lab exercises:\n+ Upload and store objects\n+ Organize and manage stored data\n+ Configure basic access control and security 17/09/2025 17/09/2025 https://us-east-1.console.aws.amazon.com/s3/bucket/create 4 - Attended Cloud Day Vietnam and noted key insights on applying AI to streamline workflows and enhance business efficiency. 18/09/2025 18/09/2025 — 5 - Worked on RDS configuration; encountered multiple setup errors.\n- Reviewed documentation, studied guides, and drafted database table structures for the lab. 19/09/2025 19/09/2025 https://us-east-1.console.aws.amazon.com/rds/home 6 - RDS practice:\n+ Resolved previous issues\n+ Recreated tables and tested connectivity\n+ Successfully completed the full RDS lab 20/09/2025 20/09/2025 https://us-east-1.console.aws.amazon.com/rds/home Week 3 Outcomes Maintained consistent study habits and completed all assigned labs. Became more efficient navigating the AWS Management Console and locating services quickly. Finished both S3 and RDS labs, documenting troubleshooting steps for future reference. Explored Amazon Bedrock and learned how to call foundation-model APIs; recognized the importance of high-quality data for reliable GenAI outputs. Improved the ability to switch between AWS Console and CLI for day-to-day operations. "},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"Event 1 Event Name: AWS Cloud Day Vietnam - AI Edition 2025\nDate: September 18, 2025\nLocation: 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nEvent Overview and Key Activities The AWS Cloud Day Vietnam - AI Edition 2025 served as a pivotal forum designed to accelerate Vietnam\u0026rsquo;s digital transformation, harnessing the power of Cloud Computing and Artificial Intelligence. The event explored four core themes:\nDemocratizing Generative AI for Enterprises Bridging the Gap Between Business and IT in Finance Accelerating Industry Modernization Enhancing Security Frameworks The day’s activities featured high-level plenary sessions with government officials and industry leaders, followed by in-depth technical tracks focused on Data Strategy, DevOps, and Cloud Migration Pathways.\nKey Takeaways and Outcomes Strategic Insights: Gained a deeper understanding of the critical interplay between Generative AI and a robust data strategy, identified as the key driver for success in modern enterprises. Migration to Operate Mindset: Developed an appreciation for the \u0026ldquo;Migrate to Operate\u0026rdquo; framework, which emphasizes using AI to streamline operations and optimize costs post-cloud migration. Technical Knowledge: Acquired insights into the integration of Generative AI within the DevOps lifecycle, particularly in automating code generation and testing. Security Innovations: Learned about the \u0026ldquo;Security by Design\u0026rdquo; approach, which focuses on embedding security measures throughout the application lifecycle rather than relying solely on perimeter defenses. This event provided invaluable knowledge and practical takeaways, further enhancing my understanding of the intersection between AI, cloud computing, and security in the context of modern enterprise solutions.\nEvent 2 Event Name: Discover Agentic AI – Amazon QuickSuite Workshop\nDate: November 7, 2025\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, Ho Chi Minh City\nEvent Overview and Key Activities The \u0026ldquo;Discover Agentic AI – Amazon QuickSuite Workshop,\u0026rdquo; organized in collaboration with Cloud Kinetics, served as a strategic technical session marking the evolution from passive Generative AI to autonomous Agentic AI. The event featured the first-ever live demonstration of Amazon QuickSuite in Vietnam. The workshop focused on four key pillars:\nDefining the \u0026ldquo;Agentic\u0026rdquo; paradigm: Autonomy, Reasoning, and Execution. Integrating Data and AI through the Amazon QuickSuite ecosystem. Hands-on building of AI concepts with AWS technical experts. Financial enablement for innovation through the AWS LIFT Program. The agenda combined theoretical architectural sessions with practical, hands-on workshops using Amazon QuickSight and Quick Suite Q, allowing participants to build functional AI concepts in real-time.\nKey Takeaways and Outcomes Paradigm Shift: Gained a clear understanding of the transition from Generative AI (content creation) to Agentic AI (autonomous task execution), where systems can perceive environments and act independently to solve business problems. Unified Ecosystem: Acquired practical insights into Amazon QuickSuite, learning how to integrate business intelligence (QuickSight) with generative capabilities to create \u0026ldquo;Analyst Agents\u0026rdquo; that streamline operations. Operational Agility: Recognized the strategic value of the \u0026ldquo;Quick\u0026rdquo; framework, which emphasizes rapid deployment and \u0026ldquo;Time-to-Value,\u0026rdquo; allowing enterprises to implement complex AI solutions with speed. Strategic Enablement: Learned about the AWS LIFT Program (offering up to $80,000 USD in credit), identifying it as a critical mechanism to de-risk R\u0026amp;D and accelerate the adoption of high-performance computing. This workshop provided a concrete roadmap for building autonomous enterprise systems, combining theoretical knowledge with hands-on technical skills and strategic financial insights to accelerate digital transformation.\nEvent 3 Event Name: AWS Cloud Mastery Series #3 - Security Pillar Deep Dive\nDate: December 1, 2025\nLocation: Online\nEvent Overview and Key Activities This in-depth workshop focused on the Security Pillar of the AWS Well-Architected Framework. The session provided a structured approach to evaluating and securing cloud workloads, covering key areas such as:\nIdentity and Access Management (IAM) best practices. Data protection techniques for encryption at-rest and in-transit. Detective controls using AWS Config, CloudTrail, and Security Hub. Infrastructure protection and automated incident response. Key Takeaways and Outcomes Shared Responsibility Model: Gained a clear understanding of the division of security responsibilities between AWS and the customer. Defense in Depth: Learned to apply a multi-layered security approach to protect cloud resources comprehensively, from the network edge to individual data. Automated Security: Understood the importance of automating security checks and remediation to reduce human error and enable faster threat response. Proactive Security Posture: Acquired the skills to use AWS tools to proactively monitor and improve the security posture of cloud environments. Event 4 Event Name: AWS Cloud Mastery Series #2 - DevOps on AWS\nDate: November 17, 2025\nLocation: Bitexco Financial Tower, District 1, Ho Chi Minh City\nEvent Overview and Key Activities This full-day deep-dive session focused on implementing DevOps culture and practices on AWS. The workshop covered the entire CI/CD lifecycle, from source control to automated deployment, and explored modern technologies including:\nInfrastructure as Code (IaC) with AWS CloudFormation and CDK. Containerization with Docker, ECR, and ECS/EKS. Building automated CI/CD pipelines using the AWS Code service suite. Implementing observability with CloudWatch and AWS X-Ray for distributed tracing. Key Takeaways and Outcomes End-to-End Automation: Mastered the concept of building fully automated software release pipelines, minimizing manual intervention and increasing deployment frequency. IaC as Standard: Understood that managing infrastructure as code is essential for repeatability, consistency, and preventing configuration drift. Observability in Distributed Systems: Learned how to use AWS X-Ray to trace requests through microservices, providing critical insights for debugging and performance optimization. Measuring DevOps Success: Gained knowledge of key DORA metrics (Deployment Frequency, MTTR, etc.) to measure and improve team performance. Event 5 Event Name: AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS\nDate: November 15, 2025\nLocation: Bitexco Financial Tower, District 1, Ho Chi Minh City\nEvent Overview and Key Activities AWS Cloud Mastery Series #1 is a specialized workshop focusing on AI/ML and Generative AI on AWS. The agenda included:\nWelcome \u0026amp; networking Overview of Vietnam’s AI/ML landscape Deep dive into Amazon SageMaker (data preparation, training, MLOps, deployment) Live demo: SageMaker Studio Coffee break Generative AI with Amazon Bedrock (FM comparison, prompt engineering, RAG, Bedrock Agents, Guardrails) Live demo: Building a GenAI chatbot Key Takeaways and Outcomes End-to-End AI/ML Understanding: Gained clarity on how SageMaker powers the entire ML lifecycle. GenAI Implementation Skills: Learned practical techniques for RAG, prompt engineering, and Bedrock Agents. MLOps Awareness: Understood the importance of automation in ML workflows. AI Security: Recognized the importance of using Bedrock Guardrails for safe AI deployment. Event 6 Event Name: CloudThinker – Building Agentic AI \u0026amp; Context Optimization with Amazon Bedrock\nDate \u0026amp; Time: 9:00, December 05, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nMain activities: Participated in a technical seminar conducted by CloudThinker and AWS focusing on the architecture, development patterns, and optimization strategies for agentic AI systems built on Amazon Bedrock.\nLesson learned: The session highlighted the evolution of DevSecOps, emphasizing that modern practices extend well beyond automating CI/CD pipelines. Security must be integrated throughout the entire software development lifecycle, and AI—particularly agentic systems—plays a pivotal role in early vulnerability detection, automated testing, and rapid incident response.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/4.4-event4/","title":"AWS Cloud Mastery Series #2 - DevOps on AWS","tags":[],"description":"","content":"AWS Cloud Mastery Series #2 - DevOps on AWS - Date: November 17, 2025 (Full Day) - Location: Bitexco Financial Tower, District 1, Ho Chi Minh City\nEvent Overview This full-day deep-dive session focused on implementing DevOps culture, AWS Continuous Integration/Continuous Delivery (CI/CD) tools, and modernizing technologies like Infrastructure as Code (IaC) and Containerization.\nKey Objectives:\nDevelop DevOps Mindset: Grasp the culture, principles, and key performance metrics (DORA, MTTR, deployment frequency). Build CI/CD Pipelines: Master the use of AWS Code services (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) for automating the release process. Implement IaC: Practice deploying and managing infrastructure using AWS CloudFormation and AWS CDK. Application Modernization: Learn about containerization, image storage (ECR), and orchestration management (ECS/EKS). Improve Observability: Set up comprehensive monitoring using CloudWatch and AWS X-Ray for distributed tracing. Key Takeaways \u0026amp; Learnings Culture is Foundational: DevOps is a combination of culture, principles, and tools; DORA metrics are crucial for measuring team performance. End-to-End Automation: The entire process from source code (CodeCommit) to deployment (CodePipeline/CodeDeploy) must be automated, prioritizing safe deployment strategies like Blue/Green and Canary. IaC is Essential: Managing infrastructure as code increases repeatability, minimizes manual errors, and allows for easy drift detection in CloudFormation. Containers for Microservices: Utilizing Docker with AWS container management services (ECS, EKS, App Runner) is the standard model for deploying microservices architecture. Distributed Tracing: AWS X-Ray is vital for understanding the performance and bottlenecks in distributed systems, complementing traditional metrics and logs from CloudWatch. Application to Work Measure DORA: Begin measuring DORA metrics (Deployment Frequency, Lead Time for Changes, Mean Time to Recovery, Change Failure Rate) for current projects. Pipeline Transformation: Select one manual or semi-automated deployment process and fully transition it to an automated AWS CodePipeline with automated Build (CodeBuild) and Deployment (CodeDeploy) steps. Pilot CDK: Start piloting the use of AWS CDK to define and deploy a small service, leveraging familiar programming languages (e.g., Python/TypeScript). Integrate X-Ray: Apply AWS X-Ray to newly developed microservices to gather tracing data and analyze inter-component performance. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.4-setup-lambda/","title":"5.4 Setup Lambda","tags":[],"description":"","content":"Module 4: Create Lambda Functions Module Objectives Create 5 Lambda functions from scratch Configure IAM roles \u0026amp; permissions Set up environment variables Configure Cognito post-confirmation trigger Test Lambda functions Set up monitoring \u0026amp; alarms Duration: 4–5 hours\nLambda Functions Overview The Lambda functions will handle specific events:\nFunction Region Runtime Purpose Memory Timeout CognitoPostConfirmationTrigger us-east-1 nodejs20.x Create user profile when user signs up 256 MB 30s AdminManageCoachesFunction ap-southeast-1 nodejs20.x Manage coaches (CRUD operations) 512 MB 30s image-upload-lambda ap-southeast-1 nodejs20.x Handle image uploads to S3 256 MB 60s leaflungs-websocket-authorizer ap-southeast-1 nodejs20.x Authorize WebSocket connections 256 MB 30s PaymentFunction ap-southeast-1 nodejs24.x Process payments 512 MB 60s Part 1: Create IAM Role for Lambda Functions Step 1: Access IAM Console Login to AWS Console using IAM user Search \u0026ldquo;IAM\u0026rdquo; Click \u0026ldquo;IAM\u0026rdquo; from the services list Left menu: Click \u0026ldquo;Roles\u0026rdquo; Click \u0026ldquo;Create role\u0026rdquo; Step 2: Configure Trust Relationship Trusted entity type: Select \u0026ldquo;AWS service\u0026rdquo; Service or use case: Search and click \u0026ldquo;Lambda\u0026rdquo; Click \u0026ldquo;Next\u0026rdquo; Step 3: Add Permissions Search and check the following policies: ✅ AWSLambdaVPCAccessExecutionRole (for EC2 database access) ✅ AWSLambdaBasicExecutionRole (for CloudWatch logs) ✅ AmazonS3FullAccess (for image upload function) ✅ SecretsManagerReadSecret (for database credentials) Click \u0026ldquo;Next\u0026rdquo; Step 4: Review \u0026amp; Create Role name: smoking-cessation-lambda-role Description: Lambda execution role for smoking cessation platform Click \u0026ldquo;Create role\u0026rdquo; ⏳ Wait for the role to be created\nStep 5: Note Role ARN Click the newly created role: smoking-cessation-lambda-role Copy Role ARN: Format is arn:aws:iam::014097726842:role/smoking-cessation-lambda-role Save it to use in later modules Part 2: Create Cognito Post-Confirmation Trigger (us-east-1) Step 1: Access Lambda Console Login to AWS Console Search \u0026ldquo;Lambda\u0026rdquo; Click \u0026ldquo;Lambda\u0026rdquo; service Select region: us-east-1 (must match Cognito region) Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure Function Basics Function name: smoking-cessation-cognito-post-confirmation Runtime: nodejs20.x Execution role: Select \u0026ldquo;Use an existing role\u0026rdquo; Existing role: smoking-cessation-lambda-role (from Part 1) Click \u0026ldquo;Create function\u0026rdquo; ⏳ Wait for the function to be created (about 1–2 minutes)\nStep 3: Configure General Settings Scroll to \u0026ldquo;General configuration\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Memory: 256 MB (default) Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Step 4: Add Environment Variables Scroll to \u0026ldquo;Environment variables\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Add the following variables: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager later) PG_DATABASE = smoking_cessation PG_PORT = 5432 COGNITO_USER_POOL_ID = (get from Module 3) Click \u0026ldquo;Save\u0026rdquo; Step 5: Add Placeholder Code Click the \u0026ldquo;Code\u0026rdquo; tab In the code editor, replace everything with: exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Cognito post-confirmation event:\u0026#39;, JSON.stringify(event, null, 2)); try { const userId = event.request.userAttributes.sub; const email = event.request.userAttributes.email; const name = event.request.userAttributes.name; console.log(`Creating user profile for ${email}`); // TODO: Implement database connection to PostgreSQL // Create user record in users table // Initialize coaching session if needed return event; } catch (error) { console.error(\u0026#39;Error in post-confirmation:\u0026#39;, error); throw error; } }; Click \u0026ldquo;Deploy\u0026rdquo; Bước 6: Add Cognito Trigger (Later) Note: After deploying code, you will configure the Cognito trigger in Part 8. Part 3: Create Admin Manage Coaches Function (ap-southeast-1) Step 1: Switch to ap-southeast-1 Region Top left: Click region dropdown Select ap-southeast-1 Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure Function Function name: smoking-cessation-admin-manage-coaches Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; ⏳ Wait for the function to be created\nStep 3: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;General configuration\u0026rdquo; Memory: 512 MB (for database operations) Timeout: 30 seconds Click \u0026ldquo;Save\u0026rdquo; Step 4: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;Environment variables\u0026rdquo; Add: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager) PG_DATABASE = smoking_cessation API_REGION = ap-southeast-1 Click \u0026ldquo;Save\u0026rdquo; Step 5: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Admin coaches request:\u0026#39;, JSON.stringify(event, null, 2)); try { const httpMethod = event.httpMethod; const path = event.path; const body = event.body ? JSON.parse(event.body) : {}; console.log(`${httpMethod} ${path}`); // TODO: Implement database operations // GET /admin/coaches - List all coaches // POST /admin/coaches - Create new coach // PUT /admin/coaches/{id} - Update coach // DELETE /admin/coaches/{id} - Delete coach // Include RBAC check (admin only) return { statusCode: 200, body: JSON.stringify({ message: \u0026#39;Coaches function placeholder\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo; Part 4: Create Image Upload Lambda (ap-southeast-1) Step 1: Create Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-image-upload Runtime: nodejs20.x Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;General configuration\u0026rdquo; Memory: 256 MB Timeout: 60 seconds (because file upload may take time) Click \u0026ldquo;Save\u0026rdquo; Step 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;Environment variables\u0026rdquo;\nAdd: S3_BUCKET = smoking-cessation-images S3_REGION = ap-southeast-1 MAX_FILE_SIZE = 10485760\nClick \u0026ldquo;Save\u0026rdquo;\nStep 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Image upload request:\u0026#39;, JSON.stringify(event, null, 2)); try { const userId = event.requestContext.authorizer.claims.sub; const fileBuffer = Buffer.from(event.body, \u0026#39;base64\u0026#39;); const fileName = event.headers[\u0026#39;x-filename\u0026#39;] || `image-${Date.now()}.jpg`; console.log(`Uploading ${fileName} for user ${userId}`); // TODO: Implement S3 upload // Validate file size (max 10MB) // Upload to S3 with user prefix // Generate pre-signed URL // Store reference in database const s3Url = `https://${process.env.S3_BUCKET}.s3.${process.env.S3_REGION}.amazonaws.com/${userId}/${fileName}`; return { statusCode: 200, body: JSON.stringify({ url: s3Url }) }; } catch (error) { console.error(\u0026#39;Error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026#34;Deploy\u0026#34; --- ## Part 5: Create WebSocket Authorizer Lambda (ap-southeast-1) ### Step 1: Create Function 1. Click \u0026#34;Create function\u0026#34; 2. **Function name**: `smoking-cessation-websocket-authorizer` 3. **Runtime**: nodejs20.x 4. **Execution role**: `smoking-cessation-lambda-role` 5. Click \u0026#34;Create function\u0026#34; ### Step 2: Configure Settings 1. Click \u0026#34;Edit\u0026#34; in \u0026#34;General configuration\u0026#34; 2. **Memory**: 256 MB 3. **Timeout**: 30 seconds 4. Click \u0026#34;Save\u0026#34; ### Step 3: Add Environment Variables 1. Click \u0026#34;Edit\u0026#34; in \u0026#34;Environment variables\u0026#34; 2. Add: COGNITO_USER_POOL_ID = (from Module 3) COGNITO_CLIENT_ID = (from Module 3) JWT_SECRET = (will be set via Secrets Manager) 3. Click \u0026#34;Save\u0026#34; ### Step 4: Add Placeholder Code ```javascript exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;WebSocket authorization event:\u0026#39;, JSON.stringify(event, null, 2)); try { const token = event.authorizationToken; if (!token) { throw new Error(\u0026#39;No authorization token\u0026#39;); } console.log(\u0026#39;Validating WebSocket token\u0026#39;); // TODO: Implement JWT token validation // Validate token signature // Check token expiration // Extract user ID from token // Placeholder authorization response return { principalId: \u0026#39;user-id-placeholder\u0026#39;, policyDocument: { Version: \u0026#39;2012-10-17\u0026#39;, Statement: [ { Action: \u0026#39;execute-api:Invoke\u0026#39;, Effect: \u0026#39;Allow\u0026#39;, Resource: event.methodArn } ] } }; } catch (error) { console.error(\u0026#39;Authorization failed:\u0026#39;, error); throw new Error(\u0026#39;Unauthorized\u0026#39;); } }; Click \u0026ldquo;Deploy\u0026rdquo; Part 6: Create Payment Function (ap-southeast-1) Step 1: Create Function Click \u0026ldquo;Create function\u0026rdquo; Function name: smoking-cessation-payment Runtime: nodejs24.x (latest version) Execution role: smoking-cessation-lambda-role Click \u0026ldquo;Create function\u0026rdquo; Step 2: Configure Settings Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;General configuration\u0026rdquo; Memory: 512 MB (payment processing needs resources) Timeout: 60 seconds Click \u0026ldquo;Save\u0026rdquo; Step 3: Add Environment Variables Click \u0026ldquo;Edit\u0026rdquo; in \u0026ldquo;Environment variables\u0026rdquo; Add: PG_HOST = 172.0.8.55 PG_USER = postgres PG_PASSWORD = (will set via Secrets Manager) PG_DATABASE = smoking_cessation STRIPE_API_KEY = (will be set via Secrets Manager) STRIPE_WEBHOOK_SECRET = (will be set via Secrets Manager) PAYMENT_TABLE = payments Click \u0026ldquo;Save\u0026rdquo; Step 4: Add Placeholder Code exports.handler = async (event) =\u0026gt; { console.log(\u0026#39;Payment event:\u0026#39;, JSON.stringify(event, null, 2)); try { const { userId, amount, paymentMethod, description } = JSON.parse(event.body); console.log(`Processing payment for user ${userId}: $${amount}`); // TODO: Implement payment processing // Validate amount // Process payment via Stripe/Payment gateway // Store payment record in database // Send confirmation email // Handle webhooks return { statusCode: 200, body: JSON.stringify({ success: true, transactionId: `txn-${Date.now()}`, message: \u0026#39;Payment processed successfully\u0026#39; }) }; } catch (error) { console.error(\u0026#39;Payment error:\u0026#39;, error); return { statusCode: 500, body: JSON.stringify({ error: error.message }) }; } }; Click \u0026ldquo;Deploy\u0026rdquo; Part 7: Create Secrets Manager for Database Credentials Step 1: Access Secrets Manager Search for \u0026ldquo;Secrets Manager\u0026rdquo; Click the service Click \u0026ldquo;Store a new secret\u0026rdquo; Step 2: Store Database Password Secret type: \u0026ldquo;Other type of secret\u0026rdquo; Key/value pairs: Key: db-password Value: \u0026lt;your-postgres-password\u0026gt; Click \u0026ldquo;Next\u0026rdquo; Secret name: smoking-cessation/db-password Click \u0026ldquo;Store secret\u0026rdquo; Step 3: Store Payment Credentials (Optional) Click \u0026ldquo;Store a new secret\u0026rdquo; Secret type: \u0026ldquo;Other type of secret\u0026rdquo; Key/value pairs: Key: stripe-api-key Value: \u0026lt;your-stripe-key\u0026gt; Secret name: smoking-cessation/stripe-api-key Click \u0026ldquo;Store secret\u0026rdquo; Step 4: Update Lambda IAM Role Lambda needs permission to read secrets:\nGo to IAM console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Select the \u0026ldquo;JSON\u0026rdquo; tab Paste: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:secretsmanager:*:*:secret:smoking-cessation/*\u0026#34; ] } ] Click \u0026ldquo;Review policy\u0026rdquo;\nPolicy name: lambda-secrets-access\nClick \u0026ldquo;Create policy\u0026rdquo;\nPart 8: Configure Cognito Post-Confirmation Trigger Step 1: Go to Cognito User Pool Switch region to us-east-1 Search for \u0026ldquo;Cognito\u0026rdquo; Click Cognito service Click \u0026ldquo;User pools\u0026rdquo; Click the user pool: smoking-cessation-users (created in Module 3) Step 2: Add Lambda Trigger Left menu: Click \u0026ldquo;User lifecycle\u0026rdquo; Click \u0026ldquo;Post confirmation\u0026rdquo; Click \u0026ldquo;Add Lambda trigger\u0026rdquo; Lambda function: smoking-cessation-cognito-post-confirmation Click \u0026ldquo;Save\u0026rdquo; Step 3: Verify Trigger Refresh page Verify trigger shows: Trigger: Post confirmation Function: smoking-cessation-cognito-post-confirmation (us-east-1) Status: Active Part 9: Grant Cognito Permission to Invoke Lambda Cognito needs permission to invoke the Lambda function:\nStep 1: Add Resource-Based Policy Switch to us-east-1 region Go to Lambda console Click function: smoking-cessation-cognito-post-confirmation Scroll down to \u0026ldquo;Resource-based policy statements\u0026rdquo; Click \u0026ldquo;Add permissions\u0026rdquo; Statement ID: AllowCognitoInvoke Principal: cognito-idp.amazonaws.com Action: lambda:InvokeFunction Source account: Source ARN:\narn:aws:cognito-idp:us-east-1:\u0026lt;account-id\u0026gt;:userpool/\u0026lt;user-pool-id\u0026gt; Click \u0026ldquo;Save\u0026rdquo; Part 10: Test Lambda Functions Step 1: Test Cognito Post-Confirmation Trigger Go to Lambda console (us-east-1) Click function: smoking-cessation-cognito-post-confirmation Click the \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;userAttributes\u0026#34;: { \u0026#34;sub\u0026#34;: \u0026#34;12345678-1234-1234-1234-123456789012\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Test User\u0026#34; } }, \u0026#34;response\u0026#34;: {} } 5. Click \u0026#34;Test\u0026#34; 6. Verify: - ✅ Execution result: Succeeded - ✅ CloudWatch logs show console.log output ![Test Result](../assets/04-lambda-test-result.png) ### Step 2: Test Admin Coaches Function 1. Switch to **ap-southeast-1** 2. Click function: `smoking-cessation-admin-manage-coaches` 3. Click \u0026#34;Test\u0026#34; tab 4. **Test event JSON**: ```json { \u0026#34;httpMethod\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/admin/coaches\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;Authorization\u0026#34;: \u0026#34;Bearer test-token\u0026#34; }, \u0026#34;body\u0026#34;: null } Click \u0026ldquo;Test\u0026rdquo; Verify status code 200 in response Bước 3: Test Image Upload Function Click function: smoking-cessation-image-upload Click \u0026ldquo;Test\u0026rdquo; tab Test event JSON: { \u0026#34;httpMethod\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/upload\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;x-filename\u0026#34;: \u0026#34;test-image.jpg\u0026#34; }, \u0026#34;body\u0026#34;: \u0026#34;base64-encoded-image-data\u0026#34;, \u0026#34;requestContext\u0026#34;: { \u0026#34;authorizer\u0026#34;: { \u0026#34;claims\u0026#34;: { \u0026#34;sub\u0026#34;: \u0026#34;user-123\u0026#34; } } } } Click \u0026ldquo;Test\u0026rdquo; Verify response contains S3 URL Step 4: View CloudWatch Logs Click the \u0026ldquo;Monitor\u0026rdquo; tab of any function Click \u0026ldquo;View logs in CloudWatch\u0026rdquo; Select the most recent log stream Verify logs show: Input event Console.log statements Execution time Part 11: Create CloudWatch Alarms Step 1: Create Error Alarm Search for \u0026ldquo;CloudWatch\u0026rdquo; Click the \u0026ldquo;CloudWatch\u0026rdquo; service Left menu: \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;All alarms\u0026rdquo; Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Select Lambda Dimension: Function name Statistic: Sum Function: smoking-cessation-admin-manage-coaches Metric: Errors Threshold: \u0026gt; 5 in 1 minute Click \u0026ldquo;Next\u0026rdquo; Action: Create SNS topic Topic name: smoking-cessation-lambda-errors Email endpoint: your-email@example.com Click \u0026ldquo;Create alarm\u0026rdquo; Check your email to verify SNS subscription Step 2: Create Duration Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Select Lambda → Durations Function: smoking-cessation-admin-manage-coaches Statistic: Average Threshold: \u0026gt; 20 seconds (warning if approaching 30s timeout) Click \u0026ldquo;Next\u0026rdquo; Action: Use existing SNS topic smoking-cessation-lambda-errors Click \u0026ldquo;Create alarm\u0026rdquo; Step 3: Create Throttle Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Metric: Lambda → Throttles Function: All functions Threshold: \u0026gt; 0 Click \u0026ldquo;Next\u0026rdquo; Action: Notify via SNS Click \u0026ldquo;Create alarm\u0026rdquo; Part 12: Enable X-Ray Tracing (Optional) Step 1: Update IAM Role Go to IAM console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Click \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Attach policies directly\u0026rdquo; Search: AWSXRayWriteAccess Check ✅ Click \u0026ldquo;Attach policies\u0026rdquo; Step 2: Enable X-Ray on Functions For each Lambda function:\nClick function Click \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;Monitoring and operations tools\u0026rdquo; Under \u0026ldquo;X-Ray\u0026rdquo;: Check ✅ \u0026ldquo;Active tracing\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Environment Variables Summary Cognito Post-Confirmation Function (us-east-1) PG_HOST=172.0.8.55 PG_USER=postgres PG_PASSWORD=(from Secrets Manager) PG_DATABASE=smoking_cessation PG_PORT=5432 COGNITO_USER_POOL_ID=(from Module 3) Admin Coaches \u0026amp; Payment Functions (ap-southeast-1) PG_HOST=172.0.8.55 PG_USER=postgres PG_PASSWORD=(from Secrets Manager) PG_DATABASE=smoking_cessation API_REGION=ap-southeast-1 STRIPE_API_KEY=(from Secrets Manager) STRIPE_WEBHOOK_SECRET=(from Secrets Manager) Image Upload Function (ap-southeast-1) S3_BUCKET=smoking-cessation-images S3_REGION=ap-southeast-1 MAX_FILE_SIZE=10485760 WebSocket Authorizer (ap-southeast-1) COGNITO_USER_POOL_ID=(from Module 3) COGNITO_CLIENT_ID=(from Module 3) JWT_SECRET=(from Secrets Manager) Checklist IAM role smoking-cessation-lambda-role created Cognito Post-Confirmation function created (us-east-1) Admin Coaches function created (ap-southeast-1) Image Upload function created (ap-southeast-1) WebSocket Authorizer function created (ap-southeast-1) Payment function created (ap-southeast-1) All functions have correct runtime \u0026amp; memory Environment variables configured for all functions Secrets Manager setup (db-password, stripe-api-key) Cognito trigger configured (post-confirmation) Lambda resource-based policy added for Cognito All functions tested successfully CloudWatch alarms created (errors, duration, throttles) X-Ray tracing enabled (optional) CloudWatch logs reviewed Sẵn sàng cho Module 5 (Setup API Gateway) Troubleshooting Function Execution Failed Issue: \u0026ldquo;An error occurred while getting the logs from CloudWatch\u0026rdquo;\nSolution:\nCheck IAM role has AWSLambdaBasicExecutionRole Wait 1-2 minutes for logs to appear Check function code for syntax errors Cognito Trigger Not Working Issue: \u0026ldquo;User created but Lambda function didn\u0026rsquo;t execute\u0026rdquo;\nSolution:\nVerify trigger is enabled in Cognito console Check Lambda resource-based policy exists Review CloudWatch logs for errors Check IAM role permissions Timeout Errors Issue: \u0026ldquo;Task timed out after 30 seconds\u0026rdquo;\nSolution:\nIncrease timeout to 60 seconds Check database connectivity (VPC configuration in Module 8) Add console logs to identify slow operations Consider increasing memory (also increases CPU) Permission Denied Issue: \u0026ldquo;User is not authorized to perform: secretsmanager:GetSecretValue\u0026rdquo;\nSolution:\nAdd secrets manager policy to Lambda role Verify policy resource ARN matches secret name Check secret exists in correct region Cold Start Issues Issue: \u0026ldquo;High duration on first invocation\u0026rdquo;\nSolution:\nIncrease memory allocation (256 → 512 MB) Consider provisioned concurrency for frequently used functions Optimize code dependencies Next Steps Implement actual code for each Lambda function (provided separately) Setup database connections to EC2 instances (Module 6) Create API Gateway routes (Module 5) Test end-to-end flow Optimize based on CloudWatch metrics Results Achieved After Module 4, you will have:\n✅ 5 Lambda functions created and deployed ✅ IAM role with appropriate permissions ✅ Environment variables configured ✅ Secrets Manager setup for sensitive data ✅ Cognito post-confirmation trigger configured ✅ Resource-based policies for Cognito invocation ✅ CloudWatch alarms setup ✅ X-Ray tracing enabled (optional) ✅ All functions tested and verified ✅ Ready for Module 5 (Create API Gateway) "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives Build a strong understanding of the main AWS service groups: Compute, Storage, Networking, and Database. Improve proficiency in using both the AWS Management Console and the AWS CLI. Explore key storage-related services including S3, Amazon Storage Gateway, Snow Family, AWS Backup, and Amazon FSx. Practice VM Import/Export to import virtual machines into AWS and export EC2 instances back to a local environment. Attend the AWS GenAI Builder Club event and document important insights. Tasks Completed This Week Day Task Start Date Completion Date Reference Material 2 - Studied AWS storage services:\n+ S3\n+ Amazon Storage Gateway\n+ Snow Family\n- Learned about Disaster Recovery on AWS\n- Explored AWS Backup 29/09/2025 29/09/2025 https://youtu.be/hsCfP0IxoaM?si=IChJwQVIszhhCfZC 3 - Reviewed VM Import/Export\n- Hands-on:\n+ Import a virtual machine into AWS\n+ Export an EC2 instance from AWS 30/09/2025 30/09/2025 https://000014.awsstudygroup.com 4 - Wrote the proposal for the team project 01/10/2025 01/10/2025 5 - Studied Amazon FSx for Windows File Server\n- Hands-on:\n+ Created file shares\n+ Managed user sessions and open files 02/10/2025 02/10/2025 https://000025.awsstudygroup.com/vi/ 6 - Attended the AWS GenAI Builder Club event and noted key takeaways 03/10/2025 03/10/2025 Week 4 Achievements Gained a clear understanding of the structure and purpose of the major AWS service groups. Became comfortable navigating the AWS Management Console and accessing core services. Installed and configured the AWS CLI, including access credentials and default region. Used the CLI to carry out essential operations such as: Checking account and configuration details Listing supported AWS regions Viewing and managing EC2 instances and key pairs Retrieving information about active services Successfully practiced VM Import/Export between AWS and a local VM environment. Implemented storage and backup scenarios using S3, AWS Backup, and Amazon FSx. Participated in the AWS GenAI Builder Club and summarized major insights. Strengthened the ability to manage AWS resources using both Console and CLI workflows. "},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/4.5-event5/","title":"AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS","tags":[],"description":"","content":"AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS - Date: Saturday, November 15, 2025\n- Time: 8:00 AM – 11:30 AM\n- Location: Bitexco Financial Tower, District 1, Ho Chi Minh City\n- Status: Past Event\nEvent Overview The AWS Cloud Mastery Series #1 is a specialized workshop for builders and professionals interested in AI/ML and Generative AI on AWS, focusing on tools, services, and real-world implementation methodologies.\nThis event provides participants with a clear understanding of AWS’s AI/ML ecosystem and demonstrates how organizations can adopt GenAI to build modern and intelligent applications.\nMain agenda of the event included:\n1. Welcome \u0026amp; Introduction (8:30 – 9:00 AM) Participant check-in \u0026amp; networking Workshop overview and learning objectives Introductory ice-breaker Overview of the AI/ML landscape in Vietnam 2. AWS AI/ML Services Overview (9:00 – 10:30 AM) Amazon SageMaker – End-to-End ML Platform:\nData preparation and labeling Model training, tuning, and deployment MLOps capabilities: CI/CD for ML, monitoring, lineage tracking Live Demo: SageMaker Studio walkthrough 3. Coffee Break (10:30 – 10:45 AM) 4. Generative AI with Amazon Bedrock (10:45 AM – 12:00 PM) Deep-dive content covered:\nFoundation Models: Claude, Llama, Titan — comparison \u0026amp; selection guidelines Prompt Engineering: structured prompting, Chain-of-Thought, Few-shot methods RAG (Retrieval-Augmented Generation): architecture, vector stores \u0026amp; knowledge base integration Bedrock Agents: multi-step workflows and tool integrations Guardrails: safety controls and content filtering Live Demo: Building a Generative AI chatbot using Bedrock 5. 12:00 PM – Lunch Break (Self-arranged) Key Takeaways \u0026amp; Learnings The combination of SageMaker and Bedrock forms a powerful foundation for deploying end-to-end AI/ML + GenAI applications. MLOps is essential for operationalizing machine learning models in production. RAG enables GenAI models to leverage enterprise-specific knowledge safely and effectively. Effective Prompt Engineering significantly improves the quality and reliability of GenAI responses. Bedrock Agents allow automation of complex AI-driven workflows. Application to Work Optimize AI Workflows: Apply SageMaker for current model training, evaluation, and deployment pipelines. Deploy GenAI Assistants: Build internal AI-powered chatbots using Bedrock + RAG for documentation and process support. Adopt MLOps Practices: Automate model evaluation, monitoring, and lineage tracking. Enhance Development Speed: Utilize structured prompting techniques to improve model output quality. Improve AI Security: Implement Bedrock Guardrails to enforce content safety and access control. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.5-setup-api-gateway/","title":"5.5 Setup API Gateway","tags":[],"description":"","content":"Module 5: Create API Gateway REST APIs Module Objectives Create 2 REST APIs from scratch Create resources \u0026amp; methods Integrate with Lambda functions Configure authentication \u0026amp; authorization Set up CORS \u0026amp; rate limiting Deploy \u0026amp; test APIs Duration: 3–4 hours\nAPI Gateway Overview Two REST APIs will be created:\nAPI Name Region Purpose Resources Methods smoking-cessation-user-api ap-southeast-1 User management, Admin operations /admin/coaches, /api/user-info, /upload GET, POST, PUT, DELETE smoking-cessation-chat-api ap-southeast-1 Chat \u0026amp; WebSocket /chat/rooms, /chat/messages, /ws GET, POST, WebSocket Part 1: Create First REST API (User Management) Step 1: Go to API Gateway Console Log in to AWS Console Search for \u0026ldquo;API Gateway\u0026rdquo; Click \u0026ldquo;API Gateway\u0026rdquo; service Select region: ap-southeast-1 Click \u0026ldquo;Create API\u0026rdquo; Step 2: Choose API Type Select REST API Click Build Step 3: Configure API Details API name: smoking-cessation-user-api Description: REST API for user management and admin operations Endpoint type: Regional Click Create API ⏳ Wait ~1–2 minutes for API creation.\nStep 4: View API Dashboard After the API is created, you will see:\nResources tree (currently only the root /) Methods available for the root Integration settings Part 2: Create /admin Resource \u0026amp; /admin/coaches Sub-resource Step 1: Create /admin Resource Click the root / Click Create Resource Resource name: admin Resource path: /admin ✅ Enable API Gateway CORS Click Create Resource Step 2: Create /admin/coaches Sub-resource Click the /admin resource Click Create Resource Resource name: coaches Resource path: coaches → becomes /admin/coaches ✅ Enable API Gateway CORS Click Create Resource Step 3: Create GET Method for /admin/coaches Click /admin/coaches Click Create Method Select GET Click the checkmark Step 4: Configure GET Method Integration Integration type: Lambda Function Lambda Region: ap-southeast-1 Lambda Function: smoking-cessation-admin-manage-coaches ✅ Use Lambda Proxy integration Click Save Confirm permission popup Step 5: Create POST Method for /admin/coaches Click Create Method Select POST Same Lambda integration as GET Click Save Step 6: Create PUT Method for /admin/coaches Click Create Method Select PUT Use same Lambda integration Click Save Step 7: Create DELETE Method for /admin/coaches Click Create Method Select DELETE Same integration Click Save Result: /admin/coaches now has GET, POST, PUT, DELETE methods.\nPart 3: Create /api/user-info Resource \u0026amp; Sub-resources Step 1: Create /api Resource Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: api Resource path: /api ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Step 2: Create /api/user-info Resource Click the /api resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: user-info Resource path: user-info ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Step 3: Create Methods for /api/user-info Create GET, POST, PUT, DELETE methods (same as /admin/coaches):\nFor each method: Click \u0026ldquo;Create Method\u0026rdquo; Select method type Integration: smoking-cessation-admin-manage-coaches Lambda ✅ Lambda Proxy integration Save Step 4: Create /{id} Resource (Path Parameter) Click the /api/user-info resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: {id} Resource path: {id} Click \u0026ldquo;Create Resource\u0026rdquo; Step 5: Create GET Method for /api/user-info/{id} Click the /{id} resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;GET\u0026rdquo; Integration: smoking-cessation-admin-manage-coaches Lambda Save Step 6: Create /by-user-id Resource Click the /api/user-info parent resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: by-user-id Resource path: by-user-id Click \u0026ldquo;Create Resource\u0026rdquo; Add GET method with Lambda integration Step 7: Create /empty Resource Click the /api/user-info parent resource Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: empty Resource path: empty Click \u0026ldquo;Create Resource\u0026rdquo; Add GET method with Lambda integration Result: /api/user-info resource tree created with all sub-resources\nPart 4: Create /upload Resource Step 1: Create /upload Resource Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Resource name: upload Resource path: /upload ✅ \u0026ldquo;Enable API Gateway CORS\u0026rdquo; Click \u0026ldquo;Create Resource\u0026rdquo; Step 2: Create POST Method Click the /upload resource Click \u0026ldquo;Create Method\u0026rdquo; Select \u0026ldquo;POST\u0026rdquo; Integration type: Lambda Function Lambda Function: smoking-cessation-image-upload ✅ \u0026ldquo;Use Lambda Proxy integration\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Part 5: Configure Authentication \u0026amp; Authorization Step 1: Create Cognito Authorizer Left menu: Click \u0026ldquo;Authorizers\u0026rdquo; Click \u0026ldquo;Create Authorizer\u0026rdquo; Authorizer name: cognito-user-pool-authorizer Type: Cognito Cognito User Pool: smoking-cessation-users (created in Module 3) Token source: Authorization Click \u0026ldquo;Create authorizer\u0026rdquo; Step 2: Test Authorizer (Optional) Token: enter a valid JWT token from your Cognito user pool Click \u0026ldquo;Test authorizer\u0026rdquo; Verify the response shows user claims Step 3: Add Authorization to Methods For critical endpoints (e.g., /admin/coaches):\nClick the /admin/coaches resource Click \u0026ldquo;GET\u0026rdquo; method Click \u0026ldquo;Method Request\u0026rdquo; Authorization: Select cognito-user-pool-authorizer Click the checkmark to save Repeat for POST, PUT, DELETE methods Part 6: Setup Request Validators Step 1: Create Request Validator Left menu: Click \u0026ldquo;Request Validators\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Name: validate-body-and-params ✅ \u0026ldquo;Validate request body\u0026rdquo; ✅ \u0026ldquo;Validate query string parameters and headers\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Step 2: Apply Validator to POST Methods Click /admin/coaches → \u0026ldquo;POST\u0026rdquo; method Click \u0026ldquo;Method Request\u0026rdquo; Request Validator: Select validate-body-and-params Save Part 7: Setup CORS Step 1: Enable CORS for All Resources Click root \u0026ldquo;/\u0026rdquo; Click \u0026ldquo;Enable CORS\u0026rdquo; Review default settings Click \u0026ldquo;Enable CORS and replace existing CORS headers\u0026rdquo; Step 2: Configure CORS Headers CORS headers automatically configured:\nAccess-Control-Allow-Headers: Content-Type, X-Amz-Date, Authorization, X-Api-Key, X-Amz-Security-Token Access-Control-Allow-Methods: GET, POST, PUT, DELETE, OPTIONS Access-Control-Allow-Origin: * (for dev, restrict in production) Part 8: Create Second API - Chat API (WebSocket) Step 1: Create WebSocket API Click \u0026ldquo;Create API\u0026rdquo; Select \u0026ldquo;WebSocket API\u0026rdquo; Click \u0026ldquo;Build\u0026rdquo; Step 2: Configure WebSocket API API name: smoking-cessation-chat-api Description: WebSocket API for chat functionality Route Selection Expression: $request.body.action Click \u0026ldquo;Create API\u0026rdquo; ⏳ Wait for the API to be created\nStep 3: Create Routes Create default routes:\n$default route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer $connect route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer $disconnect route:\nIntegration: Lambda Function Function: smoking-cessation-websocket-authorizer Part 9: Deploy APIs Step 1: Create Deployment Stage For User API:\nClick \u0026ldquo;Deploy API\u0026rdquo; Stage name: prod Stage description: Production environment Click \u0026ldquo;Deploy\u0026rdquo; Step 2: Note API Endpoint After deployment, you will see:\nInvoke URL: https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod 📌 Save this URL.\nStep 3: Deploy Chat API Go to Chat API Click \u0026ldquo;Deploy API\u0026rdquo; Stage name: prod Click \u0026ldquo;Deploy\u0026rdquo; Note the WebSocket Invoke URL Part 10: Test REST API Endpoints Step 1: Test GET /admin/coaches In the API Gateway console:\nSelect the User API Click /admin/coaches → \u0026ldquo;GET\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: GET\nPath: /admin/coaches\nHeaders:\nAuthorization: Bearer {your-cognito-token} Content-Type: application/json Body: { \u0026#34;name\u0026#34;: \u0026#34;Coach Name\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;coach@example.com\u0026#34;, \u0026#34;specialization\u0026#34;: \u0026#34;Smoking Cessation\u0026#34; } Click \u0026ldquo;Test\u0026rdquo; Expected: Status 200 with created coach data Step 3: Test /upload Endpoint Click /upload → \u0026ldquo;POST\u0026rdquo; Click \u0026ldquo;Test\u0026rdquo; Method: POST Headers: Authorization: Bearer {your-cognito-token} Content-Type: multipart/form-data Click \u0026ldquo;Test\u0026rdquo; Expected: Status 200 with S3 URL Step 4: Test with cURL (Optional) # Get list of coaches curl -X GET \\ https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/admin/coaches \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; # Create new coach curl -X POST \\ https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/admin/coaches \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;Coach John\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john@example.com\u0026#34;, \u0026#34;specialization\u0026#34;: \u0026#34;Smoking Cessation\u0026#34; }\u0026#39; Part 11: Setup CloudWatch Logging Step 1: Enable Full Request/Response Logging Click \u0026ldquo;Settings\u0026rdquo; (left menu) CloudWatch log role ARN: Click \u0026ldquo;Edit\u0026rdquo; Select or create an IAM role for API Gateway logging Role should have logs:CreateLogGroup, logs:CreateLogStream, logs:PutLogEvents permissions Click \u0026ldquo;Save changes\u0026rdquo; Step 2: Set Log Level Go to \u0026ldquo;Stages\u0026rdquo; → \u0026ldquo;prod\u0026rdquo; Click \u0026ldquo;Logs\u0026rdquo; ✅ \u0026ldquo;Enable CloudWatch Logs\u0026rdquo; Log level: INFO (or DEBUG for troubleshooting) Data trace enabled: ✅ Full request/response data: ✅ Click \u0026ldquo;Save changes\u0026rdquo; Step 3: View Logs Search for \u0026ldquo;CloudWatch\u0026rdquo; Click \u0026ldquo;CloudWatch\u0026rdquo; service Left menu: \u0026ldquo;Logs\u0026rdquo; → \u0026ldquo;Log groups\u0026rdquo; Search for API-Gateway-Execution-Logs_{api-id} View recent requests Part 12: Setup Rate Limiting (Usage Plans) Step 1: Create API Key Left menu: Click \u0026ldquo;API Keys\u0026rdquo; Click \u0026ldquo;Create API Key\u0026rdquo; Name: mobile-app-key Description: API key for mobile app Click \u0026ldquo;Create API Key\u0026rdquo; Copy and save the key Step 2: Create Usage Plan Left menu: Click \u0026ldquo;Usage Plans\u0026rdquo; Click \u0026ldquo;Create\u0026rdquo; Name: free-tier-plan Description: Free tier plan with rate limiting Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Throttling \u0026amp; Quota Rate: 100 requests per second Burst: 200 requests Quota: 1,000,000 requests per month Click \u0026ldquo;Next\u0026rdquo; Step 4: Associate API to Plan Associated API Stages: Select User API Select stage: prod Click \u0026ldquo;Next\u0026rdquo; Step 5: Associate API Key to Plan API Keys: Search and select mobile-app-key Click \u0026ldquo;Finish\u0026rdquo; Part 13: Setup Resource-Based Policy (Optional) To restrict API access to specific IAM users/roles:\nStep 1: Add Resource Policy Left menu: Click \u0026ldquo;Resource Policy\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;execute-api:Invoke\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;execute-api:/*\u0026#34; } ] } Click \u0026ldquo;Save\u0026rdquo; Part 14: Enable API Caching (Optional) Step 1: Enable Cache for GET Endpoints Go to stage: \u0026ldquo;prod\u0026rdquo; Click \u0026ldquo;Settings\u0026rdquo; Cache cluster enabled: ✅ Cache cluster size: 0.5 (smallest) Click \u0026ldquo;Save changes\u0026rdquo; Step 2: Configure Cache per Method Click /admin/coaches → \u0026ldquo;GET\u0026rdquo; Click \u0026ldquo;Integration Response\u0026rdquo; Expand the \u0026ldquo;200\u0026rdquo; response Cache settings: ✅ \u0026ldquo;Enable method caching\u0026rdquo; Cache time to live (TTL): 300 seconds (5 minutes) Click the checkmark Environment Variables Summary Save these URLs after API deployment:\n# User Management API USER_API_ENDPOINT=https://{api-id-1}.execute-api.ap-southeast-1.amazonaws.com/prod USER_API_ID={api-id-1} # Chat API (WebSocket) CHAT_API_ENDPOINT=wss://{api-id-2}.execute-api.ap-southeast-1.amazonaws.com/prod CHAT_API_ID={api-id-2} # Authorizer COGNITO_AUTHORIZER_ID=cognito-user-pool-authorizer # Rate Limiting API_KEY={your-api-key} Checklist User API (smoking-cessation-user-api) created /admin/coaches resource with GET, POST, PUT, DELETE methods created /api/user-info resource with sub-resources created /upload resource with POST method created Chat API (smoking-cessation-chat-api) created Cognito authorizer configured CORS enabled for all resources Request validators configured Both APIs deployed to prod stage CloudWatch logging enabled Rate limiting with Usage Plans configured All endpoints tested successfully API endpoints saved to environment variables Sẵn sàng cho Module 6 (Create EC2 Instances \u0026amp; Databases) Troubleshooting CORS Errors in Browser Issue: \u0026ldquo;Access to XMLHttpRequest blocked by CORS policy\u0026rdquo;\nSolution:\nVerify CORS is enabled for resource Check Access-Control-Allow-Origin header For development, use * wildcard For production, restrict to specific domain 403 Unauthorized Errors Issue: \u0026ldquo;User is not authorized to perform: execute-api:Invoke\u0026rdquo;\nSolution:\nVerify JWT token is valid Check authorizer is configured on method Verify user has required role in Cognito Review API resource policy Lambda Function Not Found Issue: \u0026ldquo;Invalid Lambda function ARN specified\u0026rdquo;\nSolution:\nVerify Lambda function exists in same region Check Lambda function name spelling Verify IAM role has Lambda invoke permissions Check CloudWatch logs for integration errors Rate Limiting Not Working Issue: \u0026ldquo;Requests not throttled according to plan\u0026rdquo;\nSolution:\nVerify API key is passed in request Check Usage Plan is associated with stage Verify API key is associated with Usage Plan Wait for throttling to take effect (may take a few minutes) High Latency Issue: \u0026ldquo;API requests taking too long\u0026rdquo;\nSolution:\nEnable caching for GET requests Increase Lambda memory (Module 4) Check database connection from Lambda (Module 6) Monitor CloudWatch metrics Next Steps Implement API Gateway request/response transformations (optional) Setup WAF (Web Application Firewall) for security (optional) Configure CloudFront for API caching (Module 7) Setup API documentation (optional) Test end-to-end with frontend application Achieved Results After Module 5, you will have:\n✅ 2 REST APIs created (User API \u0026amp; Chat API) ✅ All resources \u0026amp; methods configured ✅ Lambda integrations setup ✅ Cognito authorization configured ✅ CORS enabled for all endpoints ✅ Request validators configured ✅ Both APIs deployed to prod stage ✅ CloudWatch logging enabled ✅ Rate limiting configured ✅ All endpoints tested \u0026amp; verified ✅ API endpoints documented ✅ Ready for Module 6 (Create EC2 Instances \u0026amp; Databases) "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives Continue collaborating with First Cloud Journey teammates throughout project development. Strengthen AWS fundamentals while working on admin/staff UI flows and preparing handoffs to the Back-End team. Tasks Completed This Week Day Task Start Date Completion Date Reference 2 - Wrapped up weekend work: added the product section to the footer; designed admin and staff UI screens in Figma.\n- On-site registration was not approved the same day → continued with Front-End tasks remotely. 06/10/2025 10/10/2025 — 3 - Collaborated on the login flow and admin/staff layout; helped teammates by resolving UI blockers.\n- Completed login testing and refined the admin/staff interfaces. 06/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Synced with the Back-End team to finalize the AWS services suitable for the system.\n- Conducted handoff and review across the team to identify missing or overlapping tasks; finalized the next UI steps. 06/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Prepared product images and demo data while waiting for API/Database delivery from BE.\n- Re-tested the login flow; finalized both admin and staff UI designs. 06/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Followed up on assigned tasks to ensure proper closure.\n- Side task: translated advisor-requested blog content into .docx (non-code). 06/10/2025 10/10/2025 — Week 5 Outcomes Implemented the footer product section and completed Figma UI screens for admin/staff; continued Front-End development during the waiting period for onsite approval. Built and tested the login flow, removed blockers for teammates, and finalized the admin/staff UIs. Reached alignment with the Back-End team on AWS service selections and established the next development roadmap. Prepared assets (images, demo data) required for future integration with API and Database. Assisted the team with follow-up tasks and document translation deliverables. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/","title":"Workshop","tags":[],"description":"","content":"BUILDING THE SMOKING-CESSATION SYSTEM ON AWS (END-TO-END) This workshop provides a full, practical, step-by-step guide to building a complete AWS-based system for the Smoking-Cessation Application, including Backend (Lambda + API Gateway), Databases (PostgreSQL + MongoDB), Authentication (Cognito), Infrastructure (VPC, EC2, Security), Frontend Hosting (S3 + CloudFront), Monitoring (CloudWatch), and final Cleanup.\nEach module corresponds to a major architectural component of the system.\n🎯 Workshop Objectives By completing all modules, you will understand how to:\nBuild a microservices-based system on AWS Implement user authentication with Cognito Create and operate Lambda serverless functions Publish REST APIs through API Gateway Deploy databases on EC2 (PostgreSQL + MongoDB) Configure VPC, subnets, NAT Gateway, routing, and security Host a frontend application using S3 and CloudFront Monitor logs, metrics, errors, and costs using CloudWatch Optimize cost and clean up unused infrastructure 🧩 System Architecture Overview This workshop will guide you through building a full production-grade system consisting of:\n8 Lambda functions 2 REST APIs (User API \u0026amp; Chat API) PostgreSQL + MongoDB databases on EC2 S3 + CloudFront for frontend hosting Cognito User Pool for authentication Custom VPC with public/private subnets, NAT Gateway, and NLB CloudWatch Dashboards \u0026amp; Alarms Secrets Manager for secure credential storage 📚 Workshop Structure (10 Modules) Each module contains detailed step-by-step instructions with screenshots.\n1️⃣ Introduction Overview of the project goals, AWS services used, and system architecture.\n2️⃣ Prerequisites Prepare your AWS environment, IAM user, VS Code, SSH keys, and project directory structure.\n3️⃣ Cognito Setup Create User Pool, App Client, password policy, verification email, and post-confirmation Lambda trigger.\n4️⃣ Lambda Setup Create all backend Lambda functions, assign IAM roles, configure environment variables, and connect to Secrets Manager.\n5️⃣ API Gateway Setup Create two REST APIs, integrate with Lambda, configure authorization, enable CORS, set request validation and throttling.\n6️⃣ RDS \u0026amp; Database Setup (EC2) Create two EC2 database servers, install PostgreSQL \u0026amp; MongoDB, create database users, configure instances for production.\n7️⃣ S3 + CloudFront Setup Configure S3 buckets, static website hosting, OAC, CloudFront distribution, HTTPS, caching, and invalidation.\n8️⃣ VPC \u0026amp; Security Setup Create a custom VPC, subnets, routing tables, NAT Gateway, Internet Gateway, Security Groups, and Network Load Balancer.\n9️⃣ Monitoring \u0026amp; Logging Set up CloudWatch dashboards, logs, alerts, SNS notifications, CloudTrail auditing, and X-Ray tracing.\n🔟 Cleanup \u0026amp; Cost Optimization Analyze costs, remove unused resources, back up databases, archive S3 objects, and clean up all AWS infrastructure safely.\n✔ Final Notes This workshop equips you with the knowledge to build a complete, secure, scalable, and cost-efficient AWS architecture from scratch.\nYou may now continue with Module 5.1 — Introduction.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/4.6-event6/","title":"AWS Cloud Mastery Series #1","tags":[],"description":"","content":"Summary Report: “BUILDING AGENTIC AI - Context Optimization with Amazon Bedrock” Event Objectives Offer a clear introduction to Agentic AI and the transition toward autonomous AI systems Present Amazon Bedrock AgentCore along with AWS’s broader agentic ecosystem Walk through practical examples of designing Agentic Workflows on AWS Highlight CloudThinker’s orchestration approach and context optimization methods Provide hands-on practice in building agent-based applications using AWS Bedrock Create opportunities to connect with professionals in the AI and cloud community Speakers Nguyen Gia Hung – Head of Solutions Architect, AWS Kien Nguyen – Solutions Architect, AWS Viet Pham – Founder \u0026amp; CEO, Diaflow Thang Ton – Co-founder \u0026amp; COO, CloudThinker Henry Bui – Head of Engineering, CloudThinker Kha Van – Community Leader, AWS Key Highlights The Evolution of Agentic AI Traditional ML / Classical AI\nNarrowly defined tasks and limited capabilities Depend heavily on structured datasets and preprocessing Difficult to scale or adapt to new use cases Modern Agentic AI\nPowered by Foundation Models with multi-step reasoning Automatically breaks down tasks and leverages tools Capable of API integration, workflow execution, and knowledge access Becomes highly adaptable and production-ready when combined with AWS services Challenges in Deploying Agentic AI Performance concerns such as latency, parallel reasoning, and throughput Scalability for multi-agent execution and complex context handling Security requirements including data control, identity flow, and access permissions Governance needs like logging, traceability, and workflow boundaries AWS Agentic AI Portfolio Amazon Bedrock AgentCore for identity, memory, runtime, tool access, and workflows Agent Gateway for unified tool and API integration Broad model support including Anthropic, Meta Llama, Amazon Titan, and others Enterprise-focused design with guardrails, observability, and scaling features Amazon Bedrock AgentCore Runtime for orchestrating multi-step tasks Memory for both short-term and long-term context Identity Flow to manage permissions and security Agent Gateway for connecting to tools, APIs, and enterprise systems Code Interpreter for secure code execution Browser Tool for retrieving external information Observability features including logs, traces, and metrics Building Agentic Workflow on AWS (Diaflow Use Case) Coordination between multiple agents Context lookup and function calling Integrating agents with internal data systems Executing business logic using Bedrock and Diaflow tools Practical design strategies suitable for startups and SMEs CloudThinker Orchestration \u0026amp; Context Optimization High-level coordination patterns for agent systems Context filtering to improve model efficiency Adaptive workflows that change based on agent insights Techniques to evaluate and strengthen reasoning reliability Integration of CloudThinker workflows with Amazon Bedrock AgentCore CloudThinker Hack: Hands-On Session Initial setup of Bedrock agents Building a simple agent-driven workflow Adding external tools into the pipeline Troubleshooting and refining agent behavior Deploying a functional proof-of-concept Key Takeaways Agentic AI Mindset AI is progressing from passive responses to autonomous action Effective agents combine memory, tools, identity, and orchestration Foundation Models + workflow control lead to next-generation AI solutions AWS currently offers one of the most production-ready environments for agentic development Technical Understanding Why context optimization matters How tool usage and identity management influence reliability How AgentCore simplifies multi-step reasoning The importance of practical orchestration patterns Methods for connecting models with APIs, logic layers, and data sources Practical Development Skills Designing a full AI workflow from end to end Integrating external tools into an agent pipeline Coordinating multiple agents effectively Managing latency, scaling, and security aspects Deploying agents with proper guardrails and monitoring Applying to Work Participants can directly use these skills to:\nBuild assistants, automation flows, or internal copilots Connect Bedrock models with enterprise platforms Develop structured, multi-step workflows with AgentCore Create prototypes quickly without heavy DevOps requirements Apply CloudThinker orchestration methods to boost performance Use agentic design patterns in both startup and enterprise environments Event Experience The “Agentic Build AI – Optimization with Amazon Bedrock” workshop provided a comprehensive look into modern agentic AI development.\nKnowledge from Industry Experts Speakers from AWS, CloudThinker, and Diaflow shared real implementation insights Clear guidance on how to scale and operationalize GenAI solutions Practical examples of automating business workflows with agentic systems Hands-On Experience Built a working agent workflow during the workshop Learned how agent memory, identity, and tools interact Gained hands-on exposure to Bedrock APIs and orchestration components Networking Opportunities Met AWS architects, engineers, founders, and community contributors Explored career paths and discussed AI product development Exchanged ideas about cloud-native AI systems Lessons Learned Agentic AI goes far beyond traditional chatbots and LLM applications Real-world deployment requires identity, observability, and scalability Bedrock and CloudThinker offer a strong path from prototype to production Practical projects deliver clearer value than isolated academic tasks Some event photos Figure 1 Figure 2 Figure 3 In summary, the workshop delivered a strong mix of strategic understanding and applied knowledge. Participants walked away with practical skills in workflow design, context tuning, tool integration, and building scalable, secure agentic systems on AWS.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.6-setup-rds-database/","title":"5.6 Setup RDS Database","tags":[],"description":"","content":"Module 6: Create EC2 Instances \u0026amp; Setup Databases Module Objectives Create 4 EC2 instances from scratch Set up PostgreSQL on the DB-PG instance Set up MongoDB on the DB-Mongo instance Configure security groups Create databases \u0026amp; users Test connectivity between instances Set up monitoring \u0026amp; backups Duration: 5–6 hours\nEC2 Instances Overview 4 instances will be created in ap-southeast-1 (t4g.small, ARM-based, cost-effective):\nInstance Name Type Purpose Database Port smoking-db-pg t4g.small PostgreSQL Server smoking_cessation 5432 smoking-db-mongo t4g.small MongoDB Server smoking_cessation 27017 smoking-app-user t4g.small User Cessation App (PostgreSQL) 8000 smoking-app-social t4g.small Social Media App (MongoDB) 8000 Part 1: Create Security Groups Step 1: Create Database Security Group EC2 Console Left menu: \u0026ldquo;Security Groups\u0026rdquo; Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-db-sg Description: Security group for database servers VPC: Default VPC (or your VPC) Click \u0026ldquo;Create security group\u0026rdquo; Step 2: Add Inbound Rules for DB-SG Click the security group just created \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add these rules: Type: PostgreSQL (5432) Source: Custom → 172.0.0.0/16 (internal VPC CIDR) Type: Custom TCP 27017 (MongoDB) Source: 172.0.0.0/16 Click \u0026ldquo;Save rules\u0026rdquo; Step 3: Create Application Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-app-sg Description: Security group for application servers Click \u0026ldquo;Create security group\u0026rdquo; Step 4: Add Inbound Rules for App-SG Click the security group just created \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: SSH (22) Source: My IP (or 0.0.0.0/0 if no fixed IP) Type: Custom TCP 8000 Source: 0.0.0.0/0 (or restrict to NLB later) Click \u0026ldquo;Save rules\u0026rdquo; Step 5: Add Outbound Rules \u0026ldquo;Outbound rules\u0026rdquo; → \u0026ldquo;Edit outbound rules\u0026rdquo; Verify: All traffic to smoking-db-sg (for database access) All traffic to internet (for package downloads) Default rule should allow this Click \u0026ldquo;Save rules\u0026rdquo; Part 2: Create EC2 Instances Step 1: Launch First Instance (PostgreSQL) EC2 Console Click \u0026ldquo;Launch Instances\u0026rdquo; Name: smoking-db-pg AMI: Amazon Linux 2023 (free tier eligible) Instance type: t4g.small Keypair: Create new or select existing Key pair name: smoking-cessation-key Click \u0026ldquo;Create key pair\u0026rdquo; Download \u0026amp; store securely Click \u0026ldquo;Next\u0026rdquo; Step 2: Configure Network VPC: Default VPC (or your VPC) Subnet: Any (or a specific subnet in ap-southeast-1a) Auto-assign public IP: Disable (private subnet) Security group: smoking-db-sg Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Storage Size: 30 GB Volume type: gp3 Delete on termination: ✅ Click \u0026ldquo;Next\u0026rdquo; Step 4: Add Tags Tag key: Name Tag value: smoking-db-pg Click \u0026ldquo;Launch instance\u0026rdquo; ⏳ Wait for the instance to be created (2–3 minutes)\nStep 5: Note Private IP Address Wait for the instance to show \u0026ldquo;running\u0026rdquo; Copy the Private IPv4 address (e.g., 172.0.8.55) Save for later: PG_HOST=172.0.8.55 Step 6: Create MongoDB Instance (Same Steps) Click \u0026ldquo;Launch Instances\u0026rdquo; Name: smoking-db-mongo Same configuration as PostgreSQL Security group: smoking-db-sg Launch instance Note IP address: MONGO_HOST=\u0026lt;ip\u0026gt; Step 7: Create Application Instances Launch instance: smoking-app-user\nSecurity group: smoking-app-sg Note IP: APP_USER_HOST=\u0026lt;ip\u0026gt; Launch instance: smoking-app-social\nSecurity group: smoking-app-sg Note IP: APP_SOCIAL_HOST=\u0026lt;ip\u0026gt; All 4 instances should now be running.\nPart 3: Setup PostgreSQL on DB-PG Instance Step 1: Connect to Instance Using AWS Session Manager (recommended) or SSH:\n# Via SSH (if you have keypair) ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;PRIVATE_IP\u0026gt; # Or use Session Manager in EC2 Console # Click instance → Connect → Session Manager → Connect Step 2: Update System sudo yum update -y sudo yum upgrade -y Step 3: Install PostgreSQL # Add PostgreSQL repository sudo tee /etc/yum.repos.d/pgdg.repo \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [pgdg15] name=PostgreSQL 15 for RHEL/CentOS 9 - x86_64 baseurl=https://download.postgresql.org/pub/repos/yum/15/rhel/rhel-9-x86_64 enabled=1 gpgcheck=1 gpgkey=https://download.postgresql.org/pub/repos/yum/RPM-GPG-KEY-PGDG EOF # Install PostgreSQL sudo yum install -y postgresql15-server postgresql15-contrib Step 4: Initialize Database Cluster # Initialize cluster sudo /usr/pgsql-15/bin/initdb -D /var/lib/pgsql/15/data # Create system user if needed sudo useradd postgres || true # Change permissions sudo chown -R postgres:postgres /var/lib/pgsql/15/data Step 5: Start PostgreSQL Service # Enable service to start on boot sudo systemctl enable postgresql-15 # Start service sudo systemctl start postgresql-15 # Verify status sudo systemctl status postgresql-15 Step 6: Configure PostgreSQL for Network Access # Edit config file sudo nano /var/lib/pgsql/15/data/postgresql.conf # Find and change these lines: # listen_addresses = \u0026#39;localhost\u0026#39; → listen_addresses = \u0026#39;*\u0026#39; # port = 5432 → keep as is # Save: Ctrl+O, Enter, Ctrl+X Step 7: Configure Client Authentication # Edit pg_hba.conf sudo nano /var/lib/pgsql/15/data/pg_hba.conf # Add this line at the end (before any reject lines): # host all all 172.0.0.0/16 md5 # This allows connections from VPC CIDR 172.0.0.0/16 Step 8: Restart PostgreSQL sudo systemctl restart postgresql-15 sudo systemctl status postgresql-15 Step 9: Create smoking_cessation Database # Switch to postgres user sudo su - postgres # Connect to psql psql # Create database CREATE DATABASE smoking_cessation; # Create application user CREATE USER app_user WITH PASSWORD \u0026#39;YourSecurePassword123!\u0026#39;; # Grant privileges GRANT ALL PRIVILEGES ON DATABASE smoking_cessation TO app_user; # Connect to database \\c smoking_cessation # Grant schema privileges GRANT ALL ON SCHEMA public TO app_user; GRANT ALL ON ALL TABLES IN SCHEMA public TO app_user; GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO app_user; # Verify \\du # List users \\l # List databases # Exit \\q exit Step 10: Verify PostgreSQL is Listening # Check if listening on port 5432 sudo netstat -tlnp | grep 5432 # Or use ss command sudo ss -tlnp | grep 5432 # Output should show: LISTEN ... 0.0.0.0:5432 or :::5432 Part 4: Setup MongoDB on DB-Mongo Instance Step 1: Connect to Instance ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;MONGO_PRIVATE_IP\u0026gt; # Or use Session Manager Step 2: Update System sudo yum update -y sudo yum upgrade -y Step 3: Install MongoDB # Create MongoDB repository sudo tee /etc/yum.repos.d/mongodb-org.repo \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [mongodb-org-7.0] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/amazon/2023/mongodb-org/7.0/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-7.0.asc EOF # Install MongoDB sudo yum install -y mongodb-org Step 4: Configure MongoDB for Network Access # Edit MongoDB config sudo nano /etc/mongod.conf # Find these sections and modify: # network: # port: 27017 # bindIp: localhost → Change to bindIp: 0.0.0.0 # Save: Ctrl+O, Enter, Ctrl+X Step 5: Start MongoDB Service # Enable service to start on boot sudo systemctl enable mongod # Start service sudo systemctl start mongod # Verify status sudo systemctl status mongod Step 6: Create MongoDB Database \u0026amp; User # Connect to MongoDB mongosh # Switch to admin database use admin # Create admin user db.createUser({ user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;YourAdminPassword123!\u0026#34;, roles: [\u0026#34;root\u0026#34;] }) # Exit mongosh exit # Restart with authentication sudo nano /etc/mongod.conf # Find security section and uncomment: # security: # authorization: enabled # Save and restart sudo systemctl restart mongod Step 7: Create Application Database \u0026amp; User # Connect with authentication mongosh -u admin -p YourAdminPassword123! # Switch to smoking_cessation database use smoking_cessation # Create application user db.createUser({ user: \u0026#34;app_user\u0026#34;, pwd: \u0026#34;AppPassword123!\u0026#34;, roles: [{role: \u0026#34;readWrite\u0026#34;, db: \u0026#34;smoking_cessation\u0026#34;}] }) # Verify user created show users # Exit exit Step 8: Verify MongoDB is Listening # Check if listening on port 27017 sudo netstat -tlnp | grep 27017 # Or sudo ss -tlnp | grep 27017 # Output should show LISTEN on port 27017 Part 5: Test Database Connectivity Step 1: Test PostgreSQL from App Instance Connect to application instance:\nssh -i smoking-cessation-key.pem ec2-user@\u0026lt;APP_USER_HOST\u0026gt; # Install PostgreSQL client sudo yum install -y postgresql15 # Test connection to PostgreSQL psql -h \u0026lt;PG_HOST_IP\u0026gt; -U app_user -d smoking_cessation -c \u0026#34;SELECT 1\u0026#34; # Expected output: Should show \u0026#34;1\u0026#34; (success) Step 2: Test MongoDB from App Instance # Install MongoDB tools sudo yum install -y mongodb-mongosh # Test connection to MongoDB mongosh --host \u0026lt;MONGO_HOST_IP\u0026gt;:27017 --username app_user --password AppPassword123! --authenticationDatabase smoking_cessation --eval \u0026#34;db.adminCommand(\u0026#39;ping\u0026#39;)\u0026#34; # Expected output: { ok: 1 } Step 3: Test Inter-Instance Ping # From any instance, test network connectivity ping -c 3 \u0026lt;TARGET_IP\u0026gt; # Expected: Low latency (\u0026lt; 5ms in same VPC) Part 6: Create Database Tables (PostgreSQL) Step 1: Connect to Database From app instance or via psql:\n# Connect to smoking_cessation database psql -h \u0026lt;PG_HOST_IP\u0026gt; -U app_user -d smoking_cessation Step 2: Create Tables -- Create users table CREATE TABLE users ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), cognito_id VARCHAR(255) UNIQUE NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, name VARCHAR(255) NOT NULL, role VARCHAR(50) DEFAULT \u0026#39;user\u0026#39;, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create coaches table CREATE TABLE coaches ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id UUID REFERENCES users(id) ON DELETE CASCADE, specialization VARCHAR(255), bio TEXT, hourly_rate DECIMAL(10, 2), created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create coaching_sessions table CREATE TABLE coaching_sessions ( id UUID PRIMARY KEY DEFAULT gen_random_uuid(), user_id UUID REFERENCES users(id) ON DELETE CASCADE, coach_id UUID REFERENCES coaches(id) ON DELETE SET NULL, status VARCHAR(50) DEFAULT \u0026#39;active\u0026#39;, started_at TIMESTAMP, ended_at TIMESTAMP, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); -- Create indexes for performance CREATE INDEX idx_users_cognito_id ON users(cognito_id); CREATE INDEX idx_users_email ON users(email); CREATE INDEX idx_coaches_user_id ON coaches(user_id); CREATE INDEX idx_sessions_user_id ON coaching_sessions(user_id); CREATE INDEX idx_sessions_coach_id ON coaching_sessions(coach_id); -- Grant permissions to app_user GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO app_user; GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO app_user; -- Verify tables \\dt Step 3: Exit psql \\q Part 7: Setup Application Servers (EC2 Instances) Step 1: Connect to Application Instance ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;APP_USER_HOST\u0026gt; Step 2: Install Node.js \u0026amp; npm # Update system sudo yum update -y # Install Node.js (Amazon Linux version) curl -fsSL https://rpm.nodesource.com/setup_20.x | sudo bash - sudo yum install -y nodejs # Verify installation node --version npm --version Step 3: Create Application Directory # Create app directory sudo mkdir -p /opt/smoking-cessation sudo chown -R ec2-user:ec2-user /opt/smoking-cessation # Change to directory cd /opt/smoking-cessation # Create basic package.json cat \u0026gt; package.json \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; { \u0026#34;name\u0026#34;: \u0026#34;smoking-cessation-app\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Smoking cessation user app\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;server.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node server.js\u0026#34;, \u0026#34;dev\u0026#34;: \u0026#34;nodemon server.js\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;^4.18.2\u0026#34;, \u0026#34;pg\u0026#34;: \u0026#34;^8.10.0\u0026#34; } } EOF # Install dependencies npm install Step 4: Create Basic Express Server # Create server.js cat \u0026gt; server.js \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; const express = require(\u0026#39;express\u0026#39;); const { Pool } = require(\u0026#39;pg\u0026#39;); const app = express(); const port = 8000; // Database connection pool const pool = new Pool({ user: \u0026#39;app_user\u0026#39;, password: process.env.DB_PASSWORD || \u0026#39;AppPassword123!\u0026#39;, host: process.env.DB_HOST || \u0026#39;localhost\u0026#39;, port: 5432, database: \u0026#39;smoking_cessation\u0026#39; }); app.use(express.json()); // Health check endpoint app.get(\u0026#39;/health\u0026#39;, (req, res) =\u0026gt; { res.json({ status: \u0026#39;ok\u0026#39;, service: \u0026#39;user-app\u0026#39; }); }); // Test database connection app.get(\u0026#39;/db-test\u0026#39;, async (req, res) =\u0026gt; { try { const result = await pool.query(\u0026#39;SELECT NOW()\u0026#39;); res.json({ message: \u0026#39;Database connected\u0026#39;, time: result.rows[0] }); } catch (error) { res.status(500).json({ error: error.message }); } }); app.listen(port, () =\u0026gt; { console.log(`App listening on port ${port}`); }); EOF Step 5: Test Application # Start server node server.js # In another terminal, test endpoints curl http://localhost:8000/health curl http://localhost:8000/db-test # Ctrl+C to stop Step 6: Create Systemd Service (Optional) # Create service file sudo tee /etc/systemd/system/smoking-app.service \u0026gt; /dev/null \u0026lt;\u0026lt;EOF [Unit] Description=Smoking Cessation Application After=network.target [Service] Type=simple User=ec2-user WorkingDirectory=/opt/smoking-cessation ExecStart=/usr/bin/node server.js Restart=on-failure RestartSec=10 [Install] WantedBy=multi-user.target EOF # Enable and start service sudo systemctl daemon-reload sudo systemctl enable smoking-app sudo systemctl start smoking-app sudo systemctl status smoking-app Part 8: Setup Monitoring \u0026amp; CloudWatch Step 1: Enable Detailed Monitoring EC2 Console Select each instance Right-click → \u0026ldquo;Monitoring and troubleshooting\u0026rdquo; Click \u0026ldquo;Enable detailed monitoring\u0026rdquo; This provides 1-minute metrics instead of default 5-minute.\nStep 2: Create CloudWatch Alarms For high CPU on database instances:\nCloudWatch Console \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;Create alarm\u0026rdquo; Metric: Namespace: AWS/EC2 Metric: CPUUtilization Dimension: Instance ID (select DB-PG) Conditions: Statistic: Average Period: 5 minutes Threshold: \u0026gt; 80% Notification: Create SNS topic for alerts Click \u0026ldquo;Create alarm\u0026rdquo; Repeat for all instances.\nStep 3: Create Dashboard CloudWatch → Dashboards \u0026ldquo;Create dashboard\u0026rdquo; Name: smoking-cessation-infrastructure Add widgets: EC2 CPU Utilization (all instances) Network In/Out Disk usage (if CloudWatch agent installed) Click \u0026ldquo;Create dashboard\u0026rdquo; Part ần 9: Setup Database Backups Step 1: Create Backup Directory On each database instance:\n# Create backup directory sudo mkdir -p /backups sudo chown -R postgres:postgres /backups # For PostgreSQL Step 2: PostgreSQL Automated Backup # Connect as ec2-user ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;PG_HOST\u0026gt; # Create backup script cat \u0026gt; ~/backup-pg.sh \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; #!/bin/bash BACKUP_DIR=\u0026#34;/backups\u0026#34; TIMESTAMP=$(date +%Y%m%d_%H%M%S) BACKUP_FILE=\u0026#34;$BACKUP_DIR/smoking_cessation_$TIMESTAMP.sql\u0026#34; sudo -u postgres pg_dump -d smoking_cessation -h localhost \u0026gt; \u0026#34;$BACKUP_FILE\u0026#34; # Keep only last 7 days of backups find $BACKUP_DIR -name \u0026#34;smoking_cessation_*.sql\u0026#34; -mtime +7 -delete echo \u0026#34;Backup completed: $BACKUP_FILE\u0026#34; EOF # Make executable chmod +x ~/backup-pg.sh # Test backup ./backup-pg.sh # Add to crontab for daily backups at 3 AM crontab -e # Add: 0 3 * * * /home/ec2-user/backup-pg.sh \u0026gt;\u0026gt; /var/log/postgres-backup.log 2\u0026gt;\u0026amp;1 Step 3: MongoDB Automated Backup # Connect as ec2-user ssh -i smoking-cessation-key.pem ec2-user@\u0026lt;MONGO_HOST\u0026gt; # Create backup script cat \u0026gt; ~/backup-mongo.sh \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; #!/bin/bash BACKUP_DIR=\u0026#34;/backups\u0026#34; TIMESTAMP=$(date +%Y%m%d_%H%M%S) BACKUP_PATH=\u0026#34;$BACKUP_DIR/smoking_cessation_$TIMESTAMP\u0026#34; mongodump --username=admin --password=\u0026#34;YourAdminPassword123!\u0026#34; --db smoking_cessation --out \u0026#34;$BACKUP_PATH\u0026#34; # Keep only last 7 days find $BACKUP_DIR -maxdepth 1 -type d -mtime +7 -exec rm -rf {} \\; echo \u0026#34;MongoDB backup completed: $BACKUP_PATH\u0026#34; EOF # Make executable chmod +x ~/backup-mongo.sh # Test backup ./backup-mongo.sh # Add to crontab for daily backups at 4 AM crontab -e # Add: 0 4 * * * /home/ec2-user/backup-mongo.sh \u0026gt;\u0026gt; /var/log/mongo-backup.log 2\u0026gt;\u0026amp;1 Step 4: Upload Backups to S3 (Optional) To backup off-instance (safer):\n# Configure AWS CLI on instance (requires IAM role) aws configure # Modify backup scripts to upload to S3: # aws s3 cp $BACKUP_FILE s3://smoking-cessation-backups/ Environment Variables Summary Save these for Lambda functions \u0026amp; applications:\n# PostgreSQL PG_HOST=\u0026lt;DB-PG_PRIVATE_IP\u0026gt; PG_USER=app_user PG_PASSWORD=AppPassword123! PG_DATABASE=smoking_cessation PG_PORT=5432 # MongoDB MONGO_HOST=\u0026lt;DB-Mongo_PRIVATE_IP\u0026gt; MONGO_USERNAME=app_user MONGO_PASSWORD=AppPassword123! MONGO_DATABASE=smoking_cessation MONGO_PORT=27017 MONGO_URI=mongodb://app_user:AppPassword123!@\u0026lt;MONGO_HOST\u0026gt;:27017/smoking_cessation # Application Instances APP_USER_HOST=\u0026lt;APP_USER_PRIVATE_IP\u0026gt; APP_SOCIAL_HOST=\u0026lt;APP_SOCIAL_PRIVATE_IP\u0026gt; Checklist 4 EC2 instances launched (DB-PG, DB-Mongo, App-User, App-Social) Security groups created with proper inbound/outbound rules PostgreSQL installed, configured, and accessible MongoDB installed, configured, and accessible smoking_cessation database created in both databases Application users created with proper permissions Database tables created (users, coaches, sessions) Application instances can connect to databases Inter-instance connectivity tested (ping, port access) Node.js \u0026amp; npm installed on app instances Express server created and tested CloudWatch detailed monitoring enabled CloudWatch alarms configured for high CPU CloudWatch dashboard created Database backup scripts created and tested Backup scripts added to crontab All database credentials saved securely Sẵn sàng cho Module 7 (Create S3 \u0026amp; CloudFront) Troubleshooting Cannot Connect to PostgreSQL Issue: Connection refused on port 5432\nSolution:\n# Check PostgreSQL is running sudo systemctl status postgresql-15 # Check listening on port 5432 sudo netstat -tlnp | grep 5432 # Check security group rules allow 5432 # From app instance, verify: telnet \u0026lt;PG_HOST\u0026gt; 5432 # Check pg_hba.conf allows VPC CIDR sudo nano /var/lib/pgsql/15/data/pg_hba.conf Cannot Connect to MongoDB Issue: Connection refused on port 27017\nSolution:\n# Check MongoDB is running sudo systemctl status mongod # Check port listening sudo netstat -tlnp | grep 27017 # Check mongod.conf bindIp is correct sudo nano /etc/mongod.conf # Verify authentication enabled correctly mongosh -u admin -p \u0026lt;password\u0026gt; Network Connectivity Issues Issue: Instances cannot ping each other\nSolution:\nVerify all instances are in same VPC Check security group rules allow traffic between groups Check Network ACLs don\u0026rsquo;t block traffic Verify instances have route table entries High CPU on Database Instance Issue: CPU Utilization \u0026gt; 80%\nSolution:\n# Check top processes top -b -n 1 | head -20 # For PostgreSQL, check long-running queries: psql -h localhost -U postgres -d smoking_cessation SELECT pid, usename, query, query_start FROM pg_stat_activity WHERE query != \u0026#39;autovacuum\u0026#39;; # Consider: Scale up instance type, optimize queries, or add replication Cost Analysis Current costs (4 × t4g.small at $0.0252/hour):\nCompute: ~$30/month (4 instances × 730 hours) Storage: ~$10/month (4 × 30GB EBS volumes) Data transfer: ~$5/month Total: ~$45/month Optimization options:\nUse Reserved Instances for 30% savings (~$31/month) Right-size if low usage (t4g.micro: ~$10/month) Consolidate to 2 instances if possible Next Steps Configure auto-scaling for application instances (optional) Setup read replicas for PostgreSQL (optional) Enable database replication for high availability (optional) Configure point-in-time recovery (PITR) for databases (optional) Setup monitoring alerts (Module 9) Achieved Results After completing Module 6, you will have:\n✅ 4 EC2 instances created \u0026amp; running ✅ Security groups configured with proper rules ✅ PostgreSQL server fully set up \u0026amp; database created ✅ MongoDB server fully set up \u0026amp; database created ✅ Application users created in both databases ✅ Database tables created \u0026amp; indexed ✅ Application server configuration completed ✅ Inter-instance connectivity tested ✅ CloudWatch monitoring enabled ✅ CloudWatch alarms configured ✅ Database backup scripts set up ✅ All databases operational \u0026amp; accessible ✅ Ready for Module 7 (Create S3 \u0026amp; CloudFront) "},{"uri":"https://thienluhoan.github.io/workshop-template/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"During my internship at AWS from September 8th, 2025 to November 28th, 2025, I had the opportunity to experience a real working environment, learn new skills, and apply the knowledge I had previously studied at university. I also participated in the Insight HR project, where I further developed my programming abilities, teamwork skills, and progress reporting.\nThroughout the internship, I consistently strived to complete my tasks on time, follow the company\u0026rsquo;s workflows and guidelines, and proactively collaborate with my teammates to improve overall work efficiency.\nTo provide an objective overview of my internship experience, I would like to assess myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ✅ ☐ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ☐ ✅ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Areas for Improvement During the internship, besides the skills I successfully developed, I also identified several areas where I need to improve in order to perform more effectively in a professional environment:\nAbility to learn:\nAlthough I can absorb new knowledge fairly well, I still need to improve my learning speed when dealing with advanced topics such as complex AWS architectures or system-level services. Becoming more proactive in deep research will help strengthen my expertise.\nProactiveness:\nAt times, I still rely on mentor guidance before starting new tasks. Moving forward, I aim to take more initiative—exploring documentation, proposing potential solutions, and experimenting independently before seeking assistance.\nProgressive mindset:\nWhile I am open to feedback, I need to develop a stronger habit of self-evaluation to recognize my weaknesses and set long-term improvement goals, especially in areas such as serverless development, cloud architecture, and DevOps.\nCommunication:\nI recognize the need to enhance my clarity and confidence when presenting ideas or reporting progress in team meetings. Stronger communication will support teamwork and ensure smooth coordination.\nProblem-solving skills:\nWhen working with API Gateway, Lambda, or DynamoDB, I sometimes spend significant time identifying root causes of issues. I need to practice structured debugging, improve my log-reading skills, and adopt more systematic troubleshooting methods.\nThese areas will be my focus for continuous improvement as I work toward becoming a more capable and well-rounded Cloud Engineer.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives Develop a structured study plan and gather materials for the midterm exam. Draft the initial project architecture and submit it to the mentor for review. Tasks Completed This Week Day Task Start Date Completion Date Reference 2 - Created a study plan for the exam; outlined key topics and questions to review.\n- Carefully examined mentor-provided materials and aligned preparation with the expected exam scope. 13/10/2025 15/10/2025 https://www.notion.so/Nguy-n-Duy-Hi-u-26b17fef5a7781bf8f71e6846c27ad86 3 - Continued midterm preparation with a full day dedicated to revisiting labs and practical knowledge. 13/10/2025 15/10/2025 Same as above 4 - Searched for additional practice questions and midterm-style exercises; continued pending project tasks simultaneously. 13/10/2025 15/10/2025 Same as above 5 - Collaborated with teammates to design the project’s AWS architecture; incorporated AWS best practices into the initial draft.\n- Reviewed and refined the diagram together, preparing a version for mentor evaluation. 16/10/2025 18/10/2025 https://skillbuilder.aws/ 6 - Mentor feedback: the submitted architecture was rejected due to incorrect diagram standards, improper icon usage, and projected cost issues.\n- Organized a follow-up meeting to redefine scope and plan a revised, cost-optimized architecture. 16/10/2025 18/10/2025 https://cloudjourney.awsstudygroup.com/ Week 6 Outcomes Built a clear study roadmap and aligned revision topics with mentor expectations. Reviewed key labs to reinforce hands-on knowledge before the midterm exam. Collected supporting practice materials and progressed project-related tasks. Produced the initial AWS architecture draft as a team and documented mentor feedback. Identified mistakes in the current design (diagram formatting, icon choice, cost estimation) → scheduled a redesign focused on accuracy and cost optimization. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.7-setup-s3-cloudfront/","title":"5.7 Setup S3 + CloudFront","tags":[],"description":"","content":"Module 7: Create S3 Buckets \u0026amp; CloudFront Distribution Module Objectives Create an S3 bucket for the frontend Configure bucket properties \u0026amp; policies Create a CloudFront distribution Set up Origin Access Control (OAC) Configure caching \u0026amp; security Deploy the frontend application Test access \u0026amp; cache invalidation Duration: 3–4 hours\nS3 \u0026amp; CloudFront Overview You will create 2 S3 buckets and 1 CloudFront distribution:\nComponent Name Region Purpose S3 Bucket 1 smoking-cessation-frontend us-east-1 React frontend hosting S3 Bucket 2 smoking-cessation-backups ap-southeast-1 Database backups \u0026amp; logs CloudFront CF Distribution Global CDN for frontend (edge caching) Part 1: Create Frontend S3 Bucket Step 1: Open S3 Console Log in to the AWS Console Search for “S3” Click the S3 service Click “Create bucket” Step 2: Configure Bucket Details Bucket name: smoking-cessation-frontend Must be globally unique Use lowercase letters and hyphens only Region: us-east-1 (required for CloudFront SSL) Object Ownership: ACLs disabled (recommended) Click “Create bucket” ⏳ Wait a few seconds for the bucket to be created.\nStep 3: Enable Versioning Open the bucket: smoking-cessation-frontend Go to the Properties tab Scroll to Versioning Click Edit Enable versioning Click Save changes This enables rollback capability when deploying new frontend builds.\nStep 4: Configure Server Access Logging Still inside the Properties tab Scroll to Server access logging Click Edit Enable logging Target bucket: Create a new bucket Name: smoking-cessation-logs Click Save changes Step 5: Enable Static Website Hosting Go to the Properties tab Scroll to Static website hosting Click Edit Enable static website hosting Index document: index.html Error document: index.html (for SPA routing) Click Save changes Step 6: Block Public Access (Required) Go to the Permissions tab Scroll to Block public access Click Edit Make sure all 4 settings are enabled Click Save changes This ensures the bucket is private and only accessible via CloudFront through OAC.\nPart 2: Create Bucket Policy for CloudFront Access Step 1: Create Origin Access Control (OAC) CloudFront Console Left menu: Origin access control Click Create origin access control Name: smoking-cessation-oac Origin type: S3 Signing behavior: Sign requests Click Create ⏳ Wait for the OAC to be created\nNote the OAC ID shown (e.g., E7DE5EADPNE96) — you will need this for the S3 bucket policy.\nStep 2: Create Bucket Policy Go to the S3 bucket: smoking-cessation-frontend Click Permissions tab Scroll to Bucket policy Click Edit Paste this policy (replace OAC_ID with your real OAC ID): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontOAC\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::smoking-cessation-frontend/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;DISTRIBUTION_ID\u0026gt;\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo; Note: You\u0026rsquo;ll update the distribution ID after creating CloudFront distribution.\nPart 3: Create Backups S3 Bucket Step 1: Create Second Bucket S3 Console Click \u0026ldquo;Create bucket\u0026rdquo; Bucket name: smoking-cessation-backups Region: ap-southeast-1 (same as databases) Click \u0026ldquo;Create bucket\u0026rdquo; Step 2: Configure Backup Bucket Click into bucket Properties tab Versioning: Enable (to keep backup history) Encryption: Use server-side encryption Type: AES-256 Click \u0026ldquo;Save changes\u0026rdquo; Step 3: Create Lifecycle Policy (Optional) To archive old backups after 30 days:\nManagement tab Click \u0026ldquo;Create lifecycle rule\u0026rdquo; Rule name: archive-old-backups Scope: Apply to all objects Transitions: Transition to Glacier: 30 days Expiration: Delete after 90 days Click \u0026ldquo;Create rule\u0026rdquo; Part 4: Create CloudFront Distribution Step 1: Go to CloudFront Console Tìm kiếm \u0026ldquo;CloudFront\u0026rdquo; Click \u0026ldquo;CloudFront\u0026rdquo; service Click \u0026ldquo;Create distribution\u0026rdquo; Step 2: Configure Origin Origin domain: Select smoking-cessation-frontend.s3.us-east-1.amazonaws.com S3 access: Enable Origin Access Control (OAC) Select: smoking-cessation-oac (created in Phần 2) HTTP version: HTTP/2 and HTTP/1.1 Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Default Cache Behavior Viewer protocol policy: Redirect HTTP to HTTPS Allowed HTTP methods: GET, HEAD, OPTIONS Cache policy: CachingOptimized (recommended) TTL: 86400 seconds (1 day) for HTML TTL: 31536000 seconds (1 year) for assets (js, css) Compress objects automatically: ✅ Click \u0026ldquo;Next\u0026rdquo; Step 4: Configure Distribution Settings Enabled: ✅ Default root object: index.html Standard logging: Disabled (use CloudWatch instead) IPv6: ✅ Enabled Comment: Smoking Cessation Frontend CDN Click \u0026ldquo;Create distribution\u0026rdquo; ⏳ Chờ distribution được tạo \u0026amp; deployed (5-10 phút)\nDeployment status will show \u0026ldquo;In Progress\u0026rdquo; → \u0026ldquo;Deployed\u0026rdquo;\nStep 5: Note CloudFront Details After deployment, note:\nDistribution ID: (e.g., E1NREZDKTJH6Y9) Domain name: (e.g., d2yo2hr161ib8h.cloudfront.net) CNAME: (if custom domain configured) Part 5: Update S3 Bucket Policy with Distribution ID Step 1: Get Distribution ARN CloudFront console Select your distribution Copy Distribution ID Step 2: Update Bucket Policy Go to S3 bucket: smoking-cessation-frontend Permissions → Bucket policy Update the policy with your Distribution ID: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontOAC\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::smoking-cessation-frontend/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::\u0026lt;ACCOUNT_ID\u0026gt;:distribution/\u0026lt;YOUR_DISTRIBUTION_ID\u0026gt;\u0026#34; } } } ] } Click \u0026ldquo;Save changes\u0026rdquo; Part 6: Configure Custom Domain (Optional) Step 1: Request ACM Certificate Important: The ACM certificate must be in the us-east-1 region for CloudFront!\nSwitch the region to us-east-1 (top right) Search for \u0026ldquo;ACM\u0026rdquo; Click Certificate Manager Click Request certificate Certificate type: Public certificate Domain names: yourdomain.com *.yourdomain.com Validation method: DNS Click Request ⏳ Wait for the certificate to be issued\nYou will need to validate using DNS CNAME records.\nStep 2: Validate Certificate (DNS Method) Return to ACM certificates Click on your certificate Click Create records in Route 53 (if using Route 53) Or manually add the CNAME records to your DNS provider Step 3: Add Custom Domain to CloudFront Once the certificate is validated:\nGo to your CloudFront distribution Click Edit Alternate domain names (CNAMEs): yourdomain.com www.yourdomain.com Custom SSL certificate: Select your ACM certificate Click Save changes Step 4: Update DNS Records Route 53 or your external DNS provider Create CNAME records: yourdomain.com → d2yo2hr161ib8h.cloudfront.net www.yourdomain.com → d2yo2hr161ib8h.cloudfront.net Wait for DNS propagation (up to 24 hours) Part 7: Configure CORS for S3 (If Needed) Step 1: Enable CORS S3 bucket: smoking-cessation-frontend Permissions tab Scroll to \u0026ldquo;CORS\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; Paste CORS configuration: [ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;Authorization\u0026#34;, \u0026#34;Content-Length\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;https://yourdomain.com\u0026#34;, \u0026#34;https://www.yourdomain.com\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;ETag\u0026#34; ], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] Click \u0026ldquo;Save changes\u0026rdquo; Part 8: Build \u0026amp; Deploy Frontend Step 1: Build React Application On your local machine:\n# Navigate to frontend directory cd /path/to/frontend # Install dependencies npm install # Build production npm run build # Output in dist/ or build/ folder Step 2: Upload to S3 Option A: Using AWS CLI\n# Configure AWS credentials aws configure # Sync build folder to S3 aws s3 sync dist/ s3://smoking-cessation-frontend/ --delete # Set index.html to not cache aws s3 cp s3://smoking-cessation-frontend/index.html s3://smoking-cessation-frontend/index.html \\ --metadata-directive REPLACE \\ --cache-control \u0026#34;max-age=0, no-cache, no-store, must-revalidate\u0026#34; Option B: Using S3 Console\nS3 bucket: smoking-cessation-frontend Click \u0026ldquo;Upload\u0026rdquo; Select all files from dist/ folder Click \u0026ldquo;Upload\u0026rdquo; Step 3: Verify Files Uploaded S3 bucket content Should see: index.html assets/ *.js, *.css files Other static files Part 9: Test Frontend Access Step 1: Test CloudFront URL Open browser Navigate to https://\u0026lt;your-cloudfront-domain\u0026gt;.cloudfront.net Should see your React application loading Step 2: Test Custom Domain (If Configured) Navigate to https://yourdomain.com Verify page loads properly Check browser console for no errors Step 3: Test SPA Routing Navigate to an invalid path (e.g., /invalid) Should show 404 from your React app (not AWS 404) This confirms index.html error document is working Step 4: Check HTTPS Certificate Click lock icon in browser Verify certificate is valid Hostname matches your domain Part 10: Setup Cache Invalidation Step 1: Create Invalidation via Console When you deploy new code:\nCloudFront distribution \u0026ldquo;Invalidations\u0026rdquo; tab Click \u0026ldquo;Create invalidation\u0026rdquo; Object paths: /* /index.html Click \u0026ldquo;Create invalidation\u0026rdquo; Step 2: Automate Invalidation (Optional) Create a deployment script:\n#!/bin/bash # deploy.sh # Build npm run build # Upload to S3 aws s3 sync dist/ s3://smoking-cessation-frontend/ --delete # Invalidate CloudFront aws cloudfront create-invalidation \\ --distribution-id E1NREZDKTJH6Y9 \\ --paths \u0026#34;/*\u0026#34; echo \u0026#34;Deployment complete!\u0026#34; Make executable:\nchmod +x deploy.sh # Run deployment ./deploy.sh Part 11: Configure Security Headers Step 1: Add Response Headers via CloudFront CloudFront distribution \u0026ldquo;Behaviors\u0026rdquo; tab Click default behavior Edit → \u0026ldquo;Response headers policy\u0026rdquo; Select or create custom policy: X-Frame-Options: DENY X-Content-Type-Options: nosniff X-XSS-Protection: 1; mode=block Strict-Transport-Security: max-age=31536000; includeSubDomains Content-Security-Policy: default-src \u0026lsquo;self\u0026rsquo; Click \u0026ldquo;Save changes\u0026rdquo; Step 2: Add Cache Key Policy For optimal caching:\nBehaviors tab Click default behavior Edit → \u0026ldquo;Cache key and origin requests\u0026rdquo; Cache policy: CachingOptimized Origin request policy: All ViewerExcept CloudFront-Authorization Click \u0026ldquo;Save changes\u0026rdquo; Part 12: Setup Monitoring \u0026amp; Logging Step 1: Enable CloudFront Metrics CloudFront distribution \u0026ldquo;Monitoring\u0026rdquo; tab View metrics: Requests (total per time period) Data transferred (GB) Cache hit rate (%) 4xx/5xx error rate Default metrics available (no extra cost) Step 2: Create CloudWatch Alarms For 4xx errors:\nCloudWatch console \u0026ldquo;Alarms\u0026rdquo; → \u0026ldquo;Create alarm\u0026rdquo; Metric: Namespace: CloudFront Metric: 4xxErrorRate Distribution: Your distribution Conditions: Statistic: Average Period: 5 minutes Threshold: \u0026gt; 5% Notification: Create SNS topic Topic name: smoking-cessation-alerts Email: your@email.com Click \u0026ldquo;Create alarm\u0026rdquo; Verify SNS subscription via email Step 3: Create CloudFront Dashboard CloudWatch → Dashboards \u0026ldquo;Create dashboard\u0026rdquo; Name: smoking-cessation-cdn Add widgets: CloudFront requests Bytes transferred Cache hit rate Error rates (4xx/5xx) Save dashboard Environment Variables \u0026amp; URLs Save these URLs:\n# Frontend URLs FRONTEND_CLOUDFRONT_URL=https://d2yo2hr161ib8h.cloudfront.net FRONTEND_CUSTOM_DOMAIN=https://yourdomain.com FRONTEND_BUCKET=smoking-cessation-frontend FRONTEND_DISTRIBUTION_ID=E1NREZDKTJH6Y9 # Backup S3 BACKUPS_BUCKET=smoking-cessation-backups Checklist Frontend S3 bucket created (smoking-cessation-frontend) Versioning enabled on frontend bucket Static website hosting enabled Public access blocked Backup S3 bucket created (smoking-cessation-backups) Lifecycle policy configured for backups Origin Access Control (OAC) created CloudFront distribution created S3 bucket policy configured with Distribution ID Frontend built \u0026amp; uploaded to S3 CloudFront URL accessible via HTTPS Custom domain configured (optional) ACM certificate issued \u0026amp; validated CORS configured if needed Security headers configured Cache invalidation tested CloudWatch monitoring enabled CloudWatch alarms created CloudWatch dashboard created Ready for Module 8 (Create VPC \u0026amp; Security) Troubleshooting CloudFront Shows 403 Forbidden Issue: Getting 403 error when accessing via CloudFront\nSolution:\nVerify S3 bucket policy is correct with Distribution ID Verify OAC is properly configured Check CloudFront distribution status (must be \u0026ldquo;Deployed\u0026rdquo;) Wait 5 minutes for changes to propagate Try cache invalidation: /* Files Return 404 from S3 Issue: Some files return 404 when accessed directly\nSolution:\nEnsure all files were uploaded to S3 Check file permissions (should be private) Verify index.html exists For SPA, ensure error document is index.html SPA Routes Don\u0026rsquo;t Work Issue: Navigating to /dashboard returns 404\nSolution:\nVerify error document is set to index.html This allows React Router to handle routing Invalidate CloudFront cache: /* Browser cache: Hard refresh (Ctrl+Shift+R or Cmd+Shift+R) Slow Content Delivery Issue: Pages loading slowly\nSolution:\nEnable compression in CloudFront (gzip, brotli) Check cache policy TTL Verify assets are in /assets folder Monitor CloudFront metrics for cache hit ratio Consider adding more edge locations (available in pricing) DNS Resolution Issues Issue: Custom domain not resolving\nSolution:\nVerify DNS records created in Route 53 Check CNAME points to CloudFront domain Verify ACM certificate is issued \u0026amp; validated Wait for DNS TTL propagation (up to 24 hours) Use nslookup yourdomain.com to test Cost Analysis Monthly costs estimate:\nS3 storage: ~$0.50 (100GB frontend + backups) S3 data transfer: ~$2 (to CloudFront) CloudFront: ~$2-5 (based on traffic) Cache invalidation: ~$0.10 (20 invalidations) Total: ~$5-8/month (very economical!) Cost optimization:\nUse CloudFront TTL effectively (less invalidations) Compress objects in S3 Use S3 lifecycle policies for backups Next Steps Integrate frontend with API Gateway endpoints (Module 5) Setup authentication flow with Cognito (Module 3) Configure error boundaries in React Setup analytics (Google Analytics optional) Monitor CloudFront performance metrics Results Achieved After Module 7, you will have:\n✅ Frontend S3 bucket created \u0026amp; configured ✅ Backup S3 bucket created with lifecycle policy ✅ Origin Access Control configured ✅ CloudFront distribution deployed globally ✅ HTTPS/SSL certificates configured ✅ Custom domain configured (optional) ✅ Frontend application deployed \u0026amp; accessible ✅ Cache invalidation setup ✅ Security headers configured ✅ CORS configuration applied ✅ CloudWatch monitoring \u0026amp; alarms configured ✅ CDN optimized for performance ✅ Ready for Module 8 (Create VPC \u0026amp; Security) "},{"uri":"https://thienluhoan.github.io/workshop-template/7-feedback/","title":"Feedback &amp; Suggestions","tags":[],"description":"","content":"General Feedback 1. Working environment\nThe working environment at FCJ is friendly and easy to adapt to. Everyone in the company is very supportive and willing to help whenever I face difficulties, even outside working hours. The workspace and office areas are organized neatly and equipped with essential facilities such as power outlets, air conditioning, and projectors.\n2. Support from mentor / admin team\nMy mentor provides clear guidance, explains technical issues in detail, and encourages me to explore solutions on my own before giving direct answers. This helps me improve my self-learning ability. The admin team responds quickly with paperwork and resources, and always creates favorable conditions for interns.\n3. Alignment between tasks and my major\nThe tasks assigned match well with the knowledge I learned at university, while also allowing me to develop new skills such as cloud computing, serverless technology, and system architecture. This helps me strengthen my foundation while gaining valuable hands-on experience.\n4. Opportunities for learning and development\nThroughout the internship, I had the opportunity to develop many important skills: working with AWS services, collaborating in a team, discussing technical topics, presenting progress, and participating in insightful events. My mentor also shared practical experiences that helped me better orient my future career path.\n5. Team culture and collaboration\nDuring my internship, what impressed me most was the supportive culture at FCJ. Everyone is willing to share knowledge, give constructive feedback, and work together when facing difficult tasks. There is no gap between interns and full-time staff; everyone is listened to and treated with respect. When the project becomes urgent, the whole team cooperates smoothly, shares workload, and motivates each other to achieve the common goal. This made me feel very comfortable working here and truly consider myself part of the team.\n6. Policies for interns\nThe company offers flexible working hours, making it easier to balance studying and working. In addition, during events, there are always small gifts for participating students, creating a friendly atmosphere where we can learn while also enjoying the experience.\nSuggestions \u0026amp; Expectations The aspect I appreciate the most is the flexible working policy, which allows interns to choose their on-site working days. This creates a comfortable environment and helps me maintain a good balance between my studies and internship responsibilities.\nThis is an excellent environment for IT students. Therefore, I would gladly recommend AWS/FCJ to my friends so they can also gain practical experience and learn valuable knowledge about cloud computing—topics that are not covered in depth in university courses.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives Perform cost and performance analysis using AWS Glue and Amazon Athena. Build and test a serverless frontend integrated with API Gateway. Implement user authentication through Amazon Cognito. Understand how API Gateway handles Integration Request and Integration Response. Tasks Completed This Week Day Task Start Date Completion Date Reference Material 2 - Conducted cost and usage performance analysis using AWS Glue and Amazon Athena.\n- Reviewed workload performance and estimated operational costs. 20/10/2025 20/10/2025 https://000040.awsstudygroup.com/ 3 - Serverless workflow: built the frontend to call API Gateway.\n- Hands-on:\n+ Deployed FE and Lambda\n+ Configured API Gateway\n+ Tested APIs using both Postman and the frontend interface 21/10/2025 21/10/2025 https://000079.awsstudygroup.com 4 - Studied Amazon Cognito authentication mechanisms. 22/10/2025 22/10/2025 https://000081.awsstudygroup.com/vi/ 5 - Created an Amazon Cognito User Pool and configured required settings. 23/10/2025 23/10/2025 https://youtu.be/S1X5QxBoX4M?si=wSddLWXGzbsceVS3 6 - Learned how Integration Request and Integration Response work in API Gateway. 24/10/2025 24/10/2025 https://youtu.be/q-0JoYFag7k?si=E343RKXlnw9f456A Week 7 Outcomes Completed performance and cost analysis successfully. Deployed frontend and Lambda functions; validated the API interactions. Configured Cognito and created a User Pool for authentication. Gained a clearer understanding of how API Gateway processes integration flows. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.8-setup-vpc-security/","title":"Setup VPC &amp; Security","tags":[],"description":"","content":"Module 8: Create VPC, Subnets, Security Groups \u0026amp; NLB Module Objectives Create a new VPC from scratch Create public \u0026amp; private subnets Configure Internet Gateway \u0026amp; NAT Gateway Create 3 Security Groups Create a Network Load Balancer (NLB) for WebSocket Configure IAM policies Set up VPC Flow Logs \u0026amp; security monitoring Duration: 4–5 hours\nVPC \u0026amp; Network Overview The VPC architecture will be created in ap-southeast-1:\nVPC: smoking-cessation-vpc (172.0.0.0/16) ├── Public Subnets (Internet-facing) │ ├── ap-southeast-1a: 172.0.0.0/24 │ └── ap-southeast-1b: 172.0.1.0/24 ├── Private Subnets (Database \u0026amp; Lambda) │ ├── ap-southeast-1a: 172.0.10.0/24 │ ├── ap-southeast-1b: 172.0.11.0/24 │ └── ap-southeast-1c: 172.0.12.0/24 ├── Internet Gateway: smoking-igw ├── NAT Gateway: smoking-nat (in public subnet) ├── NLB: smoking-nlb (WebSocket endpoint) └── 3 Security Groups: ├── smoking-nlb-sg (NLB) ├── smoking-app-sg (EC2 Applications) └── smoking-db-sg (EC2 Databases) Part 1: Create VPC Step 1: Open VPC Console Log in to AWS Console Search for \u0026ldquo;VPC\u0026rdquo; Click the \u0026ldquo;VPC\u0026rdquo; service Select region: ap-southeast-1 Click Create VPC Step 2: Configure VPC Details Name tag: smoking-cessation-vpc IPv4 CIDR block: 172.0.0.0/16 Large enough for all subnets (65,536 addresses) IPv6 CIDR block: Leave empty Tenancy: Default Click Create VPC ⏳ Wait a few seconds for the VPC to be created\nStep 3: Note VPC Details After creation, note:\nVPC ID (e.g., vpc-049ff1c1372e1f3b8) VPC CIDR: 172.0.0.0/16 Part 2: Create Internet Gateway Step 1: Create IGW VPC Console Left menu → \u0026ldquo;Internet Gateways\u0026rdquo; Click Create internet gateway Name: smoking-igw Click Create internet gateway ⏳ Wait for IGW to be created\nStep 2: Attach IGW to VPC Click the newly created IGW Click Attach to VPC Select VPC: smoking-cessation-vpc Click Attach internet gateway Part 3: Create Subnets Step 1: Create Public Subnet 1a VPC Console Left menu → \u0026ldquo;Subnets\u0026rdquo; Click Create subnet VPC ID: smoking-cessation-vpc Subnet name: smoking-public-1a Availability Zone: ap-southeast-1a IPv4 CIDR block: 172.0.0.0/24 Click Create subnet Step 2: Create Public Subnet 1b Click Create subnet Subnet name: smoking-public-1b Availability Zone: ap-southeast-1b IPv4 CIDR block: 172.0.1.0/24 Click Create subnet Step 3: Create Private Subnet 1a Click Create subnet Subnet name: smoking-private-1a Availability Zone: ap-southeast-1a IPv4 CIDR block: 172.0.10.0/24 Click Create subnet Step 4: Create Private Subnet 1b Click Create subnet Subnet name: smoking-private-1b Availability Zone: ap-southeast-1b IPv4 CIDR block: 172.0.11.0/24 Click Create subnet Step 5: Create Private Subnet 1c Click Create subnet Subnet name: smoking-private-1c Availability Zone: ap-southeast-1c IPv4 CIDR block: 172.0.12.0/24 Click Create subnet Result: 5 subnets created (2 public + 3 private)\nPart 4: Create \u0026amp; Configure Route Tables Step 1: Create Public Route Table Left menu → \u0026ldquo;Route tables\u0026rdquo; Click Create route table Name: smoking-public-rt VPC: smoking-cessation-vpc Click Create route table Step 2: Add Internet Gateway Route to Public RT Open the public route table Go to Routes → \u0026ldquo;Edit routes\u0026rdquo; Click Add route Destination: 0.0.0.0/0 Target: Internet Gateway → smoking-igw Click Save routes Step 3: Associate Public RT with Public Subnets Go to Subnet associations → \u0026ldquo;Edit subnet associations\u0026rdquo; Select: smoking-public-1a smoking-public-1b Click Save associations Step 4: Create Private Route Table Click Create route table Name: smoking-private-rt VPC: smoking-cessation-vpc Click Create route table Step 5: Associate Private RT with Private Subnets Open the private route table Go to Subnet associations → \u0026ldquo;Edit subnet associations\u0026rdquo; Select: smoking-private-1a smoking-private-1b smoking-private-1c Click Save associations Note:\nPrivate subnets will route internet-bound traffic through the NAT Gateway (configured in the next section).\nPart 5: Create NAT Gateway Step 1: Create Elastic IP for NAT Left menu: \u0026ldquo;Elastic IPs\u0026rdquo; Click \u0026ldquo;Allocate Elastic IP address\u0026rdquo; Region: ap-southeast-1 Click \u0026ldquo;Allocate\u0026rdquo; Note the Elastic IP address Step 2: Create NAT Gateway Left menu: \u0026ldquo;NAT Gateways\u0026rdquo; Click \u0026ldquo;Create NAT gateway\u0026rdquo; Name: smoking-nat Subnet: smoking-public-1a (place in public subnet) Elastic IP allocation ID: Select the IP created in Step 1 Click \u0026ldquo;Create NAT gateway\u0026rdquo; ⏳ Wait 1–2 minutes until NAT Gateway is created\nStep 3: Add NAT Gateway Route to Private RT Go to \u0026ldquo;Route tables\u0026rdquo; Click private route table: smoking-private-rt \u0026ldquo;Routes\u0026rdquo; tab → \u0026ldquo;Edit routes\u0026rdquo; Click \u0026ldquo;Add route\u0026rdquo; Destination: 0.0.0.0/0 Target: NAT Gateway → smoking-nat Click \u0026ldquo;Save routes\u0026rdquo; Now private subnets can reach the internet via the NAT Gateway.\nPart 6: Create Security Groups Step 1: Create NLB Security Group Left menu: \u0026ldquo;Security Groups\u0026rdquo; Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-nlb-sg Description: Security group for Network Load Balancer VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: Click the SG you created \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add: Type: HTTPS (443)\nSource: 0.0.0.0/0 Type: HTTP (80)\nSource: 0.0.0.0/0 Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Default allows all traffic ✅ Step 2: Create Application Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-app-sg Description: Security group for application servers VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add rules: Type: Custom TCP 8000\nSource: smoking-nlb-sg Type: Custom TCP 22 (SSH)\nSource: My IP or 0.0.0.0/0 Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Allow all traffic to private subnets \u0026amp; databases Step 3: Create Database Security Group Click \u0026ldquo;Create security group\u0026rdquo; Name: smoking-db-sg Description: Security group for database servers VPC: smoking-cessation-vpc Click \u0026ldquo;Create security group\u0026rdquo; Add Inbound Rules: \u0026ldquo;Inbound rules\u0026rdquo; → \u0026ldquo;Edit inbound rules\u0026rdquo; Add: Type: PostgreSQL (5432)\nSource: smoking-app-sg Type: Custom TCP 27017 (MongoDB)\nSource: smoking-app-sg Click \u0026ldquo;Save rules\u0026rdquo; Outbound Rules: Default allows all traffic ✅ Result: 3 security groups created with correct rules\nPart 7: Create Network Load Balancer Step 1: Go to Load Balancers Left menu: \u0026ldquo;Load Balancers\u0026rdquo; (under EC2) Click \u0026ldquo;Create load balancer\u0026rdquo; Select Network Load Balancer Click \u0026ldquo;Create\u0026rdquo; Step 2: Configure NLB Basic Settings Name: smoking-nlb Scheme: Internet-facing IP address type: IPv4 VPC: smoking-cessation-vpc Subnets: smoking-public-1a smoking-public-1b Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Security Groups Security groups: Select smoking-nlb-sg Click \u0026ldquo;Next\u0026rdquo; Step 4: Configure Listeners \u0026amp; Routing Protocol: TCP Port: 443 Default action: Forward to target group Click Create target group Create Target Group: Name: smoking-ws-targets Protocol: TCP Port: 8000 VPC: smoking-cessation-vpc Health check: Protocol: TCP Port: 8000 Interval: 30 seconds Healthy threshold: 2 Click \u0026ldquo;Create\u0026rdquo; Step 5: Register Targets After target group creation, click Register targets Add: smoking-app-user (port 8000) smoking-app-social (port 8000) Click Register targets Step 6: Review \u0026amp; Create Review configuration Click Create load balancer ⏳ Wait 3–5 minutes for NLB provisioning\nNote the NLB DNS name\n(e.g., smoking-nlb-123456.elb.ap-southeast-1.amazonaws.com)\nPart 8: Configure NLB with HTTPS/TLS (Optional) Step 1: Request ACM Certificate Search for “ACM” (Certificate Manager) Click Request certificate Domain names: yourdomain.com (if using a custom domain) Or use the NLB DNS name Validation method: DNS Click Request Step 2: Create HTTPS Listener Go to the NLB Open the Listeners tab → Add listener Protocol: TLS Port: 443 Default action: Forward to target group smoking-ws-targets SSL certificate: Select your ACM certificate Click Add Step 3: Create HTTP → HTTPS Redirect (Optional) Add another listener: Protocol: TCP Port: 80 Default action: Redirect to port 443 (HTTPS) Part 9: Configure IAM Policies for Lambda VPC Access Step 1: Update Lambda Execution Role Lambda functions that connect to the database require IAM permissions:\nGo to IAM Console Click Roles Select smoking-cessation-lambda-role Click Add permissions → Create inline policy Select the JSON tab Paste the policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:DescribeNetworkInterfaces\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:AssignPrivateIpAddresses\u0026#34;, \u0026#34;ec2:UnassignPrivateIpAddresses\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-southeast-1:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:ap-southeast-1:*:secret:smoking-cessation/*\u0026#34; } ] } Click \u0026ldquo;Review policy\u0026rdquo; Policy name: lambda-vpc-policy Click \u0026ldquo;Create policy\u0026rdquo; Step 2: Configure Lambda Functions for VPC For each Lambda function that accesses databases:\nGo to Lambda Console Click function name Click \u0026ldquo;Configuration\u0026rdquo; tab Click \u0026ldquo;VPC\u0026rdquo; Click \u0026ldquo;Edit\u0026rdquo; VPC: smoking-cessation-vpc Subnets: Select private subnets smoking-private-1a smoking-private-1b Security groups: smoking-app-sg Click \u0026ldquo;Save\u0026rdquo; This allows Lambda to access EC2 database instances.\nPart 10: Setup VPC Flow Logs Step 1: Enable VPC Flow Logs Go to VPC Console Click \u0026ldquo;VPCs\u0026rdquo; Select smoking-cessation-vpc Click \u0026ldquo;Flow logs\u0026rdquo; tab Click \u0026ldquo;Create flow log\u0026rdquo; Step 2: Configure Flow Logs Name: smoking-vpc-flow-logs Traffic type: All (capture all traffic) Log destination: CloudWatch Logs Log group name: /aws/vpc/smoking-cessation-vpc IAM role: Create new role Role name: vpc-flow-logs-role Click \u0026ldquo;Create flow log\u0026rdquo; ⏳ Wait for flow logs to be enabled\nNow all VPC traffic will be logged to CloudWatch!\nPart 11: Enable GuardDuty (Threat Detection) Step 1: Enable GuardDuty Search \u0026ldquo;GuardDuty\u0026rdquo; Click \u0026ldquo;GuardDuty\u0026rdquo; service Click \u0026ldquo;Enable GuardDuty\u0026rdquo; Read and confirm disclaimer Click \u0026ldquo;Enable GuardDuty\u0026rdquo; ⏳ Wait for GuardDuty to be enabled (a few minutes)\nGuardDuty will analyze VPC Flow Logs for threats.\nPart 12: Test Network Connectivity Step 1: Test Public Subnet Connectivity From an EC2 instance in public subnet:\n# Test internet connectivity ping 8.8.8.8 # Check routing table route -n # Should see: # Destination Gateway # 172.0.0.0/16 0.0.0.0 (local) # 0.0.0.0/0 Internet Gateway Step 2: Test Private Subnet Connectivity From an EC2 instance in private subnet:\n# Test NAT Gateway (internet via NAT) curl https://ip.nslookup.com # Test database connectivity psql -h \u0026lt;DB_IP\u0026gt; -U postgres -d smoking_cessation # Test MongoDB mongosh --host \u0026lt;MONGO_IP\u0026gt;:27017 Step 3: Test Security Group Rules # From app server, test database access nc -zv \u0026lt;POSTGRES_IP\u0026gt; 5432 # Should be successful nc -zv \u0026lt;MONGO_IP\u0026gt; 27017 # Should be successful # From internet, try SSH to app server ssh -i key.pem ec2-user@\u0026lt;NLB_DNS\u0026gt; # May timeout (not open for SSH) Environment Variables \u0026amp; Networking Info Save these for future use:\n# VPC VPC_ID=vpc-046dc916dde2fb93f VPC_CIDR=172.0.0.0/16 # Subnets PUBLIC_SUBNET_1A=subnet-xxx PUBLIC_SUBNET_1B=subnet-xxx PRIVATE_SUBNET_1A=subnet-xxx PRIVATE_SUBNET_1B=subnet-xxx PRIVATE_SUBNET_1C=subnet-xxx # Gateways IGW_ID=igw-xxx NAT_EIP=\u0026lt;elastic-ip\u0026gt; NAT_GW_ID=nat-xxx # Security Groups NLB_SG_ID=sg-xxx APP_SG_ID=sg-xxx DB_SG_ID=sg-xxx # Load Balancer NLB_DNS=smoking-nlb-123456.elb.ap-southeast-1.amazonaws.com NLB_ARN=arn:aws:elasticloadbalancing:ap-southeast-1:xxx Checklist VPC created (smoking-cessation-vpc) 5 subnets created (2 public + 3 private) Internet Gateway created \u0026amp; attached Public route table created \u0026amp; configured NAT Gateway created Private route table created \u0026amp; configured with NAT 3 Security Groups created (NLB, App, DB) Security Group rules configured Network Load Balancer created Target group configured with health checks Application targets registered with NLB HTTPS/TLS listener configured (optional) Lambda functions configured for VPC access Lambda IAM policy updated VPC Flow Logs enabled GuardDuty enabled Network connectivity tested Database access from apps verified Ready for Module 9 (CloudWatch Monitoring) Troubleshooting Instances Cannot Access Internet Issue: Private subnet instance cannot reach internet\nSolution:\nVerify NAT Gateway is running (not failed) Check private route table has NAT route: 0.0.0.0/0 → NAT Gateway Verify Elastic IP is allocated Check security group outbound rules Lambda Cannot Connect to Database Issue: Lambda timeout when connecting to database\nSolution:\nVerify Lambda is in VPC with private subnets Check database security group allows inbound from app SG Verify database instances have correct SG Test from EC2 instance first to isolate issue Check database is actually running NLB Health Checks Failing Issue: Target instances marked unhealthy\nSolution:\nVerify target group health check port: 8000 Verify application listening on port 8000 Check security group (NLB-SG → App-SG) allows traffic SSH to instance and test: curl http://localhost:8000/health Check application logs for errors Cost Analysis VPC costs (mostly free, some charges):\nVPC: Free Subnets: Free IGW: Free NAT Gateway: ~$32/month (data processing charge) NLB: ~$16/month (hourly) + $0.006 per LCU VPC Flow Logs: ~$5/month (CloudWatch Logs storage) Total: ~$50-60/month Next Steps Connect EC2 instances to NLB targets Setup auto-scaling groups (optional) Configure CloudFront to front NLB (optional) Setup WAF for NLB (optional) Monitor with CloudWatch (Module 9) Results Achieved After completing Module 8, you will have:\n✅ VPC created with CIDR 172.0.0.0/16 ✅ 5 subnets (2 public + 3 private) ✅ Internet Gateway attached ✅ NAT Gateway configured for private subnet internet access ✅ Public and private route tables fully configured ✅ 3 Security Groups with correct inbound/outbound rules ✅ Network Load Balancer successfully deployed ✅ Lambda functions integrated with the VPC ✅ VPC Flow Logs capturing all network traffic ✅ GuardDuty enabled and monitoring threats ✅ Network security architecture fully completed ✅ Ready for Module 9 (CloudWatch Monitoring \u0026amp; Alarms) "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Learn and understand core AWS Architecture Pillars: Secure Architectures (IAM, MFA, SCP, KMS, Security Groups, NACLs, GuardDuty, Shield, WAF, Secrets Manager) Resilient Architectures (Multi-AZ/Region, Auto Scaling, Route 53, Load Balancing, Backup \u0026amp; Restore) High-Performing Architectures (Compute scaling, Storage options, Caching, CloudFront) Cost-Optimized Architectures (Cost Explorer, Budgets, Saving Plans, NAT Gateway optimization, Storage tiering) Implement and deploy API Gateway Proxy Resource Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about Secure Architectures + IAM, MFA, SCP, KMS + Security Groups NACLs, GuardDuty, Shield, WAF, Secrets Manager 27/10/2025 27/10/2025 3 - Learn about Resilient Architectures + Multi AZ/Region, Auto Scaling\u0026hellip; + Route 53, Load Balancing, Backup \u0026amp; Restore 28/10/2025 28/10/2025 4 Learn about High-Performing Architectures + Compute scaling (EC2, Lambda, Fargate) + Storage (S3, EFS, EBS), Caching, CloudFront 29/10/2025 29/10/2025 5 - Cost-Optimized Architectures + Cost Explorer, Budgets, Saving Plans Nat gateway, Storage Tiering 30/10/2025 30/10/2025 6 - Learn about Proxy Resource \u0026amp; Deploy Proxy Resource on API gateway 31/10/2025 31/10/2025 https://youtu.be/zZzHTHs72Sk?si=qhdd4v0mADIh3MJ0 Week 8 Achievements: Completed learning modules for: Secure AWS Architectures and core security services Resilient Architectures including multi-AZ/region strategies High-Performance Architectures with compute, storage, and caching Cost Optimization techniques across AWS services Successfully deployed API Gateway Proxy Resource following tutorial Completed all planned tasks from Day 2 to Day 6 on schedule "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.9-monitoring-logging/","title":"Monitoring &amp; Logging","tags":[],"description":"","content":"Module 9: Setup CloudWatch Monitoring, Logging \u0026amp; Alerts Objectives Create CloudWatch Log Groups for all services Build a CloudWatch Dashboard to visualize metrics Create CloudWatch Alarms with SNS notifications Enable CloudTrail for audit logging Enable X-Ray for distributed tracing Configure AWS Cost Monitoring \u0026amp; Budget Alerts Create CloudWatch Synthetics canaries (health checks) Document incident response runbooks Duration: 3–4 hours\nMonitoring \u0026amp; Observability Architecture Infrastructure monitoring will cover:\nCloudWatch Monitoring: ├── Logs (CloudWatch Logs) │ ├── /aws/lambda/functions │ ├── /aws/apigateway/apis │ ├── /aws/ec2/databases │ ├── /aws/vpc/flow-logs │ └── /aws/s3/access-logs ├── Metrics \u0026amp; Dashboards │ ├── EC2 (CPU, Network, Disk) │ ├── Lambda (Invocations, Errors, Duration) │ ├── API Gateway (Requests, Errors, Latency) │ ├── CloudFront (Requests, Cache Hit Rate) │ └── NLB (Connections, Target Health) ├── Alarms (SNS Notifications) │ ├── High error rates │ ├── High latency │ ├── Resource exhaustion │ └── Cost anomalies └── Audit Trail ├── CloudTrail (API calls) └── X-Ray (Request tracing) Part 1: Create CloudWatch Log Groups Step 1: Create Lambda Log Groups CloudWatch Console Left menu: \u0026ldquo;Logs\u0026rdquo; → \u0026ldquo;Log groups\u0026rdquo; Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/lambda/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; ⏳ Wait for the log group to be created\nNote: Lambda functions automatically create their own log streams, but creating parent log group allows custom configuration\nStep 2: Create API Gateway Log Groups Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/apigateway/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; Step 3: Create EC2 Databases Log Groups Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/ec2/databases Click \u0026ldquo;Create log group\u0026rdquo; Step 4: Create VPC Flow Logs Group Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/vpc/flow-logs Click \u0026ldquo;Create log group\u0026rdquo; Step 5: Create CloudFront Log Groups (Optional) Click \u0026ldquo;Create log group\u0026rdquo; Log group name: /aws/cloudfront/smoking-cessation Click \u0026ldquo;Create log group\u0026rdquo; Result: 5 log groups created for centralized logging\nStep 6: Configure Log Retention Policies For each log group:\nClick on log group name Actions → \u0026ldquo;Edit retention settings\u0026rdquo; Retention: 30 days Balances cost vs. historical data Click \u0026ldquo;Save\u0026rdquo; This prevents logs from consuming unlimited storage.\nPart 2: Create CloudWatch Dashboard Step 1: Create Dashboard CloudWatch Console Left menu: \u0026ldquo;Dashboards\u0026rdquo; Click \u0026ldquo;Create dashboard\u0026rdquo; Dashboard name: smoking-cessation-monitoring Click \u0026ldquo;Create dashboard\u0026rdquo; ⏳Wait for the dashboard to be created\nStep 2: Add Lambda Metrics Widget Click \u0026ldquo;Add widget\u0026rdquo; Choose Line chart Metric selection: Namespace: AWS/Lambda Metric: Invocations Statistics: Sum Add multiple metrics: Invocations Duration (Average) Errors (Sum) Throttles (Sum) Widget name: Lambda Performance Click \u0026ldquo;Create widget\u0026rdquo; Step 3: Add API Gateway Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/ApiGateway Metrics: Count (total requests) 4XXError 5XXError Latency (p99) Widget name: API Gateway Metrics Click \u0026ldquo;Create widget\u0026rdquo; Step 4: Add EC2 Database Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/EC2 Filter by instances: DB-PG, DB-Mongo Metrics: CPUUtilization NetworkPacketsIn NetworkPacketsOut DiskReadBytes Widget name: Database Performance Click \u0026ldquo;Create widget\u0026rdquo; Step 5: Add CloudFront Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Number widget Metric selection: Namespace: AWS/CloudFront Metrics: Requests (Sum) BytesDownloaded CacheHitRate 4xxErrorRate 5xxErrorRate Widget name: CDN Performance Click \u0026ldquo;Create widget\u0026rdquo; Step 6: Add NLB Metrics Click \u0026ldquo;Add widget\u0026rdquo; → Line chart Metric selection: Namespace: AWS/NetworkELB Metrics: ActiveFlowCount HealthyHostCount UnHealthyHostCount ProcessedBytes Widget name: Load Balancer Health Click \u0026ldquo;Create widget\u0026rdquo; Step 7: Configure Dashboard Settings Dashboard settings (gear icon) Auto-refresh: 1 minute Save dashboard Now you have a real-time monitoring dashboard!\nPart 3: Create SNS Topic for Notifications Step 1: Create SNS Topic Tìm kiếm \u0026ldquo;SNS\u0026rdquo; Click \u0026ldquo;SNS\u0026rdquo; service Left menu: \u0026ldquo;Topics\u0026rdquo; Click \u0026ldquo;Create topic\u0026rdquo; Type: Standard Name: smoking-cessation-alerts Click \u0026ldquo;Create topic\u0026rdquo; ⏳Wait for the topic to be created\nStep 2: Create Email Subscription Click vào topic vừa tạo \u0026ldquo;Subscriptions\u0026rdquo; tab → \u0026ldquo;Create subscription\u0026rdquo; Protocol: Email Endpoint: your-email@example.com Click \u0026ldquo;Create subscription\u0026rdquo; ⏳ Wait for email confirmation\nCheck your email inbox and click the confirmation link!\nStep 3: Create SMS Subscription (Optional) Click \u0026ldquo;Create subscription\u0026rdquo; Protocol: SMS Endpoint: +1234567890 (your phone number) Click \u0026ldquo;Create subscription\u0026rdquo; Now you\u0026rsquo;ll get SMS alerts for critical issues!\nPart 4: Create CloudWatch Alarms Step 1: Create Lambda Error Alarm CloudWatch → Alarms → \u0026ldquo;Create alarm\u0026rdquo; Select metric: Namespace: AWS/Lambda Metric: Errors Statistics: Sum Conditions: Threshold: \u0026gt; 5 errors Period: 5 minutes Evaluation periods: 1 Click \u0026ldquo;Next\u0026rdquo; Notification: Select SNS topic smoking-cessation-alerts Alarm name: smoking-lambda-errors Alarm description: Alert when Lambda errors exceed threshold Click \u0026ldquo;Create alarm\u0026rdquo; Step 3: Create EC2 Database CPU Alarm Click \u0026ldquo;Create alarm\u0026rdquo; Select metric: Namespace: AWS/EC2 Metric: CPUUtilization Instance: DB-PG Conditions: Threshold: \u0026gt; 80% Period: 5 minutes Evaluation periods: 2 Click \u0026ldquo;Next\u0026rdquo; Notification: smoking-cessation-alerts Alarm name: smoking-db-pg-high-cpu Click \u0026ldquo;Create alarm\u0026rdquo; Step 4: Create Similar Alarms for Other Services Repeat for:\nDB-Mongo CPU \u0026gt; 80% Application servers CPU \u0026gt; 75% CloudFront 4xx errors \u0026gt; 5% CloudFront 5xx errors \u0026gt; 1% NLB unhealthy targets \u0026gt; 0 Step 5: Create Composite Alarm (Optional) Combine multiple alarms into one:\nClick \u0026ldquo;Create alarm\u0026rdquo; Alarm type: Composite alarm Alarm rule: (smoking-lambda-errors OR smoking-apigateway-errors OR smoking-db-pg-high-cpu OR smoking-db-mongo-high-cpu) This triggers if ANY service has issues Click \u0026ldquo;Create alarm\u0026rdquo; Result: Comprehensive alerting system active!\nPart 5: Enable CloudTrail Audit Logging Step 1: Create CloudTrail Search \u0026ldquo;CloudTrail\u0026rdquo; Click \u0026ldquo;CloudTrail\u0026rdquo; service Click \u0026ldquo;Create trail\u0026rdquo; Trail name: smoking-cessation-audit Enable for all AWS regions: ✅ (recommended) Click \u0026ldquo;Next\u0026rdquo; Step 2: Configure S3 for CloudTrail Logs S3 bucket: Create new bucket: ✅ Bucket name: smoking-cessation-cloudtrail-logs S3 key prefix (optional): cloudtrail-logs/ Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure CloudTrail Events Management events: ✅ All (captures API calls) Data events: (Optional - more expensive) Insights: ✅ CloudTrail Insights (detects unusual activity) Click \u0026ldquo;Next\u0026rdquo; Step 4: Review \u0026amp; Create Review all settings Click \u0026ldquo;Create trail\u0026rdquo; ⏳ Chờ trail được tạo\nStep 5: Start Logging Trail created → click \u0026ldquo;Start logging\u0026rdquo; Trail status changes to \u0026ldquo;Logging\u0026rdquo; Now all API calls are being audited!\nStep 6: View CloudTrail Events CloudTrail → Event history Filter by: Event name: (e.g., PutFunction for Lambda code updates) Resource type: (e.g., AWS::Lambda::Function) Time range: Last 24 hours View event details (JSON format) This helps with:\nSecurity audits Compliance investigations Troubleshooting IAM issues Cost allocation Part 6: Enable X-Ray Distributed Tracing Step 1: Create X-Ray Sampling Rule Search \u0026ldquo;X-Ray\u0026rdquo; Click \u0026ldquo;X-Ray\u0026rdquo; service Left menu: \u0026ldquo;Sampling rules\u0026rdquo; Click \u0026ldquo;Create sampling rule\u0026rdquo; Rule name: smoking-cessation-sampling Priority: 1000 (lower = higher priority) Reservoir: 1 (always sample at least 1 per second) Fixed rate: 0.1 (10% of requests) Click \u0026ldquo;Create sampling rule\u0026rdquo; This controls how many traces are recorded (reducing cost).\nStep 2: Enable X-Ray for Lambda Functions For each Lambda function:\nLambda Console Click function name Configuration tab Click \u0026ldquo;General configuration\u0026rdquo; → Edit Under \u0026ldquo;Monitoring tools\u0026rdquo;: ✅ Check \u0026ldquo;Active tracing\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Repeat for all 5 Lambda functions.\nStep 3: Enable X-Ray for API Gateway API Gateway Console Select API: smoking-cessation-user-api Logging → Settings ✅ Check \u0026ldquo;X-Ray request tracing enabled\u0026rdquo; Click \u0026ldquo;Save\u0026rdquo; Repeat for chat API Step 4: Update Lambda IAM Role for X-Ray IAM Console Click \u0026ldquo;Roles\u0026rdquo; Click smoking-cessation-lambda-role Add permissions → Attach policies directly Search: AWSXRayWriteAccess Check ✅ Click \u0026ldquo;Attach policies\u0026rdquo; Now Lambda can write X-Ray traces!\nStep 5: View Service Map X-Ray Console Left menu: \u0026ldquo;Service map\u0026rdquo; You\u0026rsquo;ll see a map showing: API Gateway → Lambda → EC2 (databases) Lambda → S3 Lambda → CloudFront Data flow between services As requests flow through the system, traces are recorded!\nStep 6: Analyze Traces X-Ray → Traces Click on a trace to view: Service timeline Latency breakdown per service Errors and exceptions Database query details Use this to identify performance bottlenecks Part 7: Setup Cost Monitoring Step 1: Create AWS Budget Billing Console Left menu: \u0026ldquo;Budgets\u0026rdquo; Click \u0026ldquo;Create budget\u0026rdquo; Budget type: Cost budget Period: Monthly Amount: $500/month Alerts: When actual \u0026gt; 80% ($400): Email When forecasted \u0026gt; 100% ($500): Email Click \u0026ldquo;Create budget\u0026rdquo; This prevents surprise bills!\nStep 2: Setup Cost Anomaly Detection Cost Management Console Left menu: \u0026ldquo;Anomaly Detection\u0026rdquo; Click \u0026ldquo;Create detector\u0026rdquo; Name: smoking-cessation-cost-anomaly Monitor: All AWS Services Frequency: Daily Alert frequency: Instant SNS topic: smoking-cessation-alerts Click \u0026ldquo;Create detector\u0026rdquo; Now you\u0026rsquo;ll be alerted if costs spike unexpectedly!\nStep 3: Use Cost Explorer Cost Explorer View costs by: Service: See which services cost the most Region: Compare regions Time: Identify trends Filter: Linked account Cost category Granularity: Daily or Monthly Common cost optimization findings:\nNAT Gateway data processing \u0026gt; 50% of bill EC2 instances running 24/7 \u0026gt; 30% of bill CloudFront data transfer \u0026gt; 10% of bill Part 8: Create CloudWatch Synthetics (Health Checks) Step 1: Create API Canary CloudWatch Console Left menu: \u0026ldquo;Synthetics\u0026rdquo; → \u0026ldquo;Canaries\u0026rdquo; Click \u0026ldquo;Create canary\u0026rdquo; Canary type: API canary Name: smoking-api-health-check Endpoint: Your API Gateway URL https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod/health Method: GET Schedule: 5 minutes Click \u0026ldquo;Next\u0026rdquo; Step 2: Configure Success Criteria Status codes: 200 Response time: \u0026lt; 1000ms Click \u0026ldquo;Next\u0026rdquo; Step 3: Set S3 Storage S3 location: Create new bucket or select existing Bucket name: smoking-canary-results Click \u0026ldquo;Create canary\u0026rdquo; ⏳ Chờ canary được tạo\nStep 4: Monitor Canary Results Synthetics → Canaries Click smoking-api-health-check View: Success rate Latency graphs Failed requests If failures: Create CloudWatch alarm This continuously tests API availability!\nPart 9: Create Incident Response Runbooks Step 1: Document High Error Rate Response Create a file or document:\nINCIDENT: High Lambda Error Rate (\u0026gt; 5 errors/5min) Detection: CloudWatch Alarm \u0026#34;smoking-lambda-errors\u0026#34; triggered Immediate Actions: 1. Check CloudWatch Logs: - Go to CloudWatch → Logs → Log groups - Select `/aws/lambda/smoking-cessation` - Search for \u0026#34;error\u0026#34; or \u0026#34;Error\u0026#34; - Note error message \u0026amp; frequency 2. Identify Affected Function: - From alarm, determine which function - Check recent CloudTrail logs - Verify no recent code deployments 3. Database Connectivity Check: - If DB error: - EC2 → Instances - Check DB-PG and DB-Mongo status - Check security groups allow traffic - If not DB: Check Lambda timeout configuration 4. Escalation: - If not resolved in 15 min: Page on-call engineer - If data loss risk: Initiate disaster recovery Resolution: - Rollback recent deployments if applicable - Scale up database resources if overloaded - Increase Lambda memory if timeout issues - Update database connection pooling Post-Incident: - Document root cause - Update monitoring to catch earlier - Schedule post-mortem meeting Step 2: Create High API Latency Runbook INCIDENT: High API Latency (\u0026gt; 1000ms p99) Actions: 1. Check X-Ray service map to identify slow service 2. If Lambda slow: - Increase memory (more CPU) - Check CloudWatch Logs for errors 3. If database slow: - Monitor EC2 instance CPU/Memory - Check slow query logs 4. If API Gateway slow: - Check request volume - Verify cache hit rate (CloudFront) 5. Resolution: - Scale resources up - Optimize queries/code - Add caching layer Step 3: Create Database Disk Full Runbook INCIDENT: Database Disk Full (\u0026gt; 90%) Actions: 1. SSH to DB instance (EC2) 2. Check disk usage: df -h /var 3. Clean up: - Remove old logs: find /var/log -mtime +30 -delete - Archive old data from PostgreSQL - Delete old MongoDB collections 4. If still full: - Add EBS volume or expand existing - Migrate to larger instance type 5. Configure auto-cleanup for future Environment Variables \u0026amp; Monitoring Info Save for reference:\n# CloudWatch DASHBOARD_NAME=smoking-cessation-monitoring LOG_GROUP_LAMBDA=/aws/lambda/smoking-cessation LOG_GROUP_APIGATEWAY=/aws/apigateway/smoking-cessation LOG_GROUP_VPC=/aws/vpc/flow-logs LOG_RETENTION=30 # days # Alarms \u0026amp; Notifications SNS_TOPIC_ARN=arn:aws:sns:ap-southeast-1:xxx:smoking-cessation-alerts ALARM_LAMBDA_ERRORS=smoking-lambda-errors ALARM_APIGATEWAY_ERRORS=smoking-apigateway-errors ALARM_DB_CPU_HIGH=smoking-db-cpu-high # Audit \u0026amp; Tracing CLOUDTRAIL_BUCKET=smoking-cessation-cloudtrail-logs XRAY_SAMPLING_RATE=0.1 SYNTHETICS_BUCKET=smoking-canary-results # Budget MONTHLY_BUDGET=$500 ALERT_THRESHOLD=80% # $400 Checklist CloudWatch Log Groups created for all services Log retention set to 30 days CloudWatch Dashboard created with key metrics SNS topic created for notifications Email subscription verified CloudWatch Alarms created: Lambda errors API Gateway errors EC2 database high CPU CloudFront errors NLB health CloudTrail enabled \u0026amp; logging CloudTrail S3 bucket created X-Ray sampling rule configured X-Ray enabled on Lambda functions X-Ray enabled on API Gateway Lambda IAM role has X-Ray permissions AWS Budget configured ($500/month) Cost Anomaly Detection enabled CloudWatch Synthetics canary created Incident response runbooks documented Team trained on monitoring tools WORKSHOP COMPLETE ✅ Monitoring Best Practices Alert Fatigue Prevention Set thresholds based on historical baselines Use composite alarms for multiple conditions Implement alert deduplication Log Management Set appropriate retention (30 days = balance) Use filters to reduce noise Archive to S3 Glacier for long-term storage Cost Optimization Review CloudWatch costs monthly Use Log Insights selectively Archive old logs to S3 Security Enable CloudTrail multi-region Review CloudTrail logs weekly Monitor for suspicious IAM activity Cost Analysis Monitoring costs (estimated monthly):\nCloudWatch Logs: ~$20 (log ingestion + storage) CloudWatch Alarms: ~$5 (10 alarms × $0.50) CloudTrail: ~$3 (multi-region trail) X-Ray: ~$2 (10% sampling rate) Cost Explorer: Free Synthetics: ~$1 (1 canary every 5 min) Total: ~$31/month Next Steps Monitor dashboard daily during initial rollout Adjust alarm thresholds based on actual metrics Review CloudTrail logs for security Optimize costs based on Cost Explorer findings Plan disaster recovery based on CloudTrail audit trail Schedule monthly post-mortems for any incidents Achieved Results After Module 9, you will have:\n✅ CloudWatch Log Groups for all services ✅ Centralized logging with 30-day retention ✅ Real-time monitoring dashboard ✅ Automated SNS alerts for critical issues ✅ Email/SMS notifications working ✅ CloudWatch Alarms monitoring performance ✅ CloudTrail enabled for compliance auditing ✅ X-Ray distributed tracing for debugging ✅ Service map showing architecture ✅ Cost monitoring \u0026amp; budgets configured ✅ CloudWatch Synthetics for continuous health checks ✅ Incident response runbooks documented ✅ Complete observability of infrastructure ✅ 🎉 AWS WORKSHOP 100% COMPLETE 🎉 Workshop Summary You have successfully built a complete AWS infrastructure for the Smoking Cessation Platform:\nModules Completed (9 Total): Module 1-2: Prerequisites \u0026amp; AWS Account Setup ✅ Module 3: Cognito Authentication ✅ Module 4: Lambda Functions ✅ Module 5: API Gateway REST APIs ✅ Module 6: EC2 Instances \u0026amp; Databases ✅ Module 7: S3 Frontend \u0026amp; CloudFront CDN ✅ Module 8: VPC, Security, Load Balancing ✅ Module 9: Monitoring, Logging \u0026amp; Alerts ✅ Architecture Highlights: ✅ Secure authentication (Cognito) ✅ Serverless compute (Lambda) ✅ RESTful APIs (API Gateway) ✅ Hybrid databases (PostgreSQL + MongoDB on EC2) ✅ Global content delivery (CloudFront) ✅ High-availability networking (VPC, NLB) ✅ Comprehensive monitoring (CloudWatch, X-Ray) ✅ Complete audit trail (CloudTrail) Estimated Monthly Cost: $320-350 EC2 (4 instances): $120 Lambda: $10 API Gateway: $5 S3 + CloudFront: $10 NAT Gateway: $32 NLB: $16 CloudWatch/Logs: $30 Other services: $30 Your infrastructure is production-ready! 🚀\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives Study and strengthen understanding of key API Gateway concepts: Path Parameters Query String Parameters Lambda Integration Proxy Usage Plans \u0026amp; API Keys Configuring CloudWatch Logs for API Gateway Tasks Completed This Week Day Task Start Date Completion Date Reference Material 2 - Learned about Path Parameters in API Gateway 03/11/2025 03/11/2025 https://youtu.be/5cMHc1kiq2M?si=zip07VzxdNcjCQpF 3 - Studied Query String Parameters in API Gateway 04/11/2025 04/11/2025 https://youtu.be/BZbF5n39Xnc?si=QHhm0xDo36cuOFcI 4 - Explored the use of Lambda Integration Proxy 05/11/2025 05/11/2025 https://youtu.be/369Em-gKTlE?si=veLKX3EbbLW-S6uO 5 - Learned how to create and configure Usage Plans and API Keys 06/11/2025 06/11/2025 https://youtu.be/rMG5-pklJO0?si=n14pWvOIGxTkbbw0 6 - Configured CloudWatch Logs for API Gateway 07/11/2025 07/11/2025 https://youtu.be/OIR2I4CC4N8?si=_5A7an6gxSFcuepv Week 9 Outcomes Successfully completed learning topics on: Path and Query String Parameters Lambda Integration Proxy behavior Usage Plans and API Keys Enabling and configuring CloudWatch Logs for API Gateway All tasks scheduled from Day 2 to Day 6 were finished on time. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.10-cleanup/","title":"Cleanup &amp; Cost Optimization","tags":[],"description":"","content":"Module 10: Cleanup \u0026amp; Cost Optimization Objectives Identify unused/underutilized resources Delete test resources Optimize costs Archive important data Backup before deletion Documentation \u0026amp; lessons learned Part 1: Resource Inventory \u0026amp; Assessment Current AWS Resources List all resources from the AWS Console:\nLambda Functions:\nGo to Lambda console List functions in each region (us-east-1, ap-southeast-1) Note: Function names, creation dates, memory allocation API Gateways:\nGo to API Gateway console List all REST APIs in ap-southeast-1 Note: API names, deployment status EC2 Database Instances:\nGo to EC2 console List all instances in ap-southeast-1 Filter for database instances (DB-PG, DB-Mongo) Note: Instance IDs, instance types, IPs, creation dates S3 Buckets:\nGo to S3 console List all buckets Note: Bucket names, creation dates, storage used CloudFront Distributions:\nGo to CloudFront console List all distributions Note: Domain names, distribution IDs VPC Resources:\nGo to VPC console List all VPCs in ap-southeast-1 Note: VPC IDs, CIDR ranges Create an inventory spreadsheet:\nResource name \u0026amp; type Region Creation date Current usage Estimated monthly cost Part 2: Identify Unused Resources Check Resource Usage Lambda Functions To check Lambda invocations:\nGo to CloudWatch console Click Metrics → Lambda Select each function Choose metric: Invocations Set time range: Last 7 days Check if Sum = 0 (unused function) → If no invocations in last 7 days → unused → consider deletion\nAPI Gateways To check API request count:\nGo to CloudWatch console Click Metrics → API Gateway Select your API Choose metric: Count Set time range: Last 30 days Check if Sum = 0 → No requests → safe to delete\nS3 Buckets To check bucket sizes:\nGo to S3 console Click each bucket Go to Storage tab Check \u0026ldquo;Storage used\u0026rdquo; Review storage classes Consider moving old objects to cheaper classes S3 Storage Class Pricing:\nStandard: $0.023/GB/month Infrequent Access: $0.0125/GB/month Glacier: $0.004/GB/month CloudFront To check cache hit ratio:\nGo to CloudWatch console Click Metrics → CloudFront Select distribution Metric: CacheHitRate Range: Last 30 days → If \u0026lt; 50%, caching may need optimization\nEC2 Database Instances To check CPU \u0026amp; memory usage:\nGo to CloudWatch console Click Metrics → EC2 Select DB instance Metric: CPUUtilization Time range: Last 30 days Check Average and Maximum → If CPU \u0026lt; 10%, consider downsizing instance\nPart 3: Cost Optimization Strategies 1. Right-Sizing EC2 Database Instances Current: t4g.small (PostgreSQL + MongoDB)\nCost: ~$30–40/month per instance\nAlternative options:\nt4g.nano: ~$3–5/month (testing/dev) t4g.micro: ~$8–10/month (light production) t4g.small: Recommended for production Rule:\n→ If CPU \u0026lt; 10% on average → downsize to save cost\n2. Reserved Instances (if workload is stable) AWS EC2 Reserved Instances provide discounts:\n1-year term → ~30% off 3-year term → ~50% off To purchase:\nEC2 console Left menu → Reserved Instances Purchase Reserved Instances Choose instance type: t4g.small Choose term: 1-year or 3-year Click Purchase 3. Optimize Data Transfer Costs Key facts:\nS3 → CloudFront: Free S3 → Internet: $0.09/GB S3 → Lambda (same region): Free Recommendation:\n→ Keep using CloudFront to reduce data transfer cost\n4. Lambda Optimization Default memory: 256 MB\nCost per invocation: ~$0.0000002\nIf high traffic:\nConsider Provisioned Concurrency (more stable but slightly higher cost) Increase memory if it reduces execution time (may reduce total cost) 5. Database Optimization Recommendations:\nAutomated backups (already enabled) Read replicas if read-heavy workload Set CloudWatch retention = 30 days (reduce log storage cost) 6. CloudFront Optimization If cache hit rate \u0026lt; 50%:\nIncrease TTL for static assets Add more cache behaviors Use cache policies with fewer dynamic parameters Part 4: Backup \u0026amp; Archive Step 1: Backup EC2 Databases To backup PostgreSQL and MongoDB on EC2:\nPostgreSQL (DB-PG: 172.0.8.55):\nSSH into the EC2 instance Create backup: pg_dump smokingcessation \u0026gt; backup_$(date +%Y%m%d).sql Compress: gzip backup_*.sql MongoDB (DB-Mongo: 172.0.8.124):\nSSH into the EC2 instance Create backup: mongodump --db smokingcessation --out backup_$(date +%Y%m%d) Compress: tar czf backup_*.tar backup_* Step 2: Upload Database Backups to S3 To export database backups for archival:\nSSH into database EC2 instance Upload to S3: Via AWS CLI (if configured): aws s3 sync /backups s3://smoking-cessation-backups/ Or manually download and upload via S3 console Step 3: Archive S3 Data For old data (\u0026gt; 90 days), setup lifecycle policies:\nGo to S3 console Click on bucket name (e.g., \u0026ldquo;leaflungs-images\u0026rdquo;) Go to \u0026ldquo;Management\u0026rdquo; tab Click \u0026ldquo;Create lifecycle rule\u0026rdquo; Configure: Name: \u0026ldquo;archive-old-data\u0026rdquo; Filter: Prefix \u0026ldquo;chat/\u0026rdquo; Transitions: Move to Glacier after 90 days Expiration: Delete after 365 days Click \u0026ldquo;Create rule\u0026rdquo; Part 5: Test Resource Cleanup (Non-Production) Step 1: Delete Test Lambda Functions If any test functions exist:\nGo to Lambda console Click on test function name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete\u0026rdquo; Type function name to confirm Click \u0026ldquo;Delete\u0026rdquo; Step 2: Delete Unused API Gateway If multiple APIs for testing:\nGo to API Gateway console Click on API name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete API\u0026rdquo; Confirm deletion Step 3: Delete Empty S3 Buckets To delete a bucket:\nGo to S3 console Click on bucket name Click \u0026ldquo;Empty\u0026rdquo; to remove all objects Confirm emptying Once empty, click \u0026ldquo;Delete\u0026rdquo; button Type bucket name to confirm Click \u0026ldquo;Delete bucket\u0026rdquo; Step 4: Delete Unused CloudFront Distributions To delete a CloudFront distribution:\nGo to CloudFront console Click on distribution Click \u0026ldquo;Disable\u0026rdquo; (if enabled) Wait 15 minutes for propagation Once status shows \u0026ldquo;Disabled\u0026rdquo;, click \u0026ldquo;Delete\u0026rdquo; Confirm deletion Part 6: Delete Production Resources (if shutting down) WARNING: This is destructive and cannot be undone!\nBackup Checklist Before Deletion PostgreSQL data backed up (pg_dump) MongoDB data backed up (mongodump) Database backups uploaded to S3 S3 data backed up externally (if needed) CloudTrail logs reviewed \u0026amp; archived Code backed up to GitHub DNS records updated (if redirecting) Team notified Step 1: Delete EC2 Database Instances To delete database EC2 instances:\nGo to EC2 console Click \u0026ldquo;Instances\u0026rdquo; Select database instance (DB-PG or DB-Mongo) Click \u0026ldquo;Instance State\u0026rdquo; → \u0026ldquo;Terminate\u0026rdquo; Confirm termination Wait for instance to terminate Verify EBS volumes are deleted (optional: create snapshots first if needed) Repeat for second database instance Step 2: Delete Lambda Functions To delete each Lambda function:\nGo to Lambda console Click on function name Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete\u0026rdquo; Type function name to confirm Click \u0026ldquo;Delete\u0026rdquo; Repeat for each function Step 3: Delete API Gateways To delete each API Gateway:\nGo to API Gateway console Click on API name (e.g., \u0026ldquo;LeafLungs-UserInfo-API\u0026rdquo;) Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete API\u0026rdquo; Confirm deletion Repeat for second API (leaflungs-chat-api) Step 4: Delete Cognito User Pool To delete Cognito User Pool:\nGo to Cognito console Click \u0026ldquo;User pools\u0026rdquo; Click on your user pool Click \u0026ldquo;Delete user pool\u0026rdquo; (bottom right) Type the user pool name to confirm Click \u0026ldquo;Delete\u0026rdquo; Step 5: Delete S3 Buckets (and contents) To delete each S3 bucket:\nGo to S3 console For each bucket (leaflungs-frontend-new, leaflungs-images, leaflungs-images-sg): Click on bucket name Click \u0026ldquo;Empty\u0026rdquo; to remove all objects Confirm emptying Once empty, click \u0026ldquo;Delete\u0026rdquo; button Type bucket name to confirm Click \u0026ldquo;Delete bucket\u0026rdquo; Step 6: Delete CloudFront Distribution To delete CloudFront distribution:\nGo to CloudFront console Click on distribution (if not already disabled) If enabled, click \u0026ldquo;Disable\u0026rdquo; first Wait 15 minutes for propagation Once status shows \u0026ldquo;Disabled\u0026rdquo;, click \u0026ldquo;Delete\u0026rdquo; Confirm deletion Part 7: Cost Analysis \u0026amp; Reporting Monthly Cost Breakdown Typical costs for this architecture:\nService Usage Cost Lambda 100K invocations/month ~$2 API Gateway 10M requests/month ~$50 EC2 (2x DB instances) 2 x t4g.small for PostgreSQL + MongoDB ~$60-70 EC2 (2x App instances) 2 x t4g.small for applications ~$60-70 S3 100 GB storage ~$2 CloudFront 1 TB/month transfer ~$85 Cognito 1K users ~$0 (free tier) NAT Gateway 10 GB transfer ~$5 Total ~$300-350/month Cost optimization opportunities:\nUse t4g.nano/micro for light databases: Saves ~$20-30/month Cache more aggressively: Saves ~$30/month Reserved EC2 instances: Saves ~$60-80/month Total savings: ~$110-140/month (35-40% reduction) AWS Cost Explorer AWS Console → Billing → Cost Explorer View costs by: Service Linked account Region Usage type Set up cost anomaly detection Review trends Part 8: Documentation \u0026amp; Lessons Learned Create Post-Mortem Document # Workshop Completion Report ## Architecture Summary - Services deployed: Lambda, API Gateway, EC2 (PostgreSQL + MongoDB), S3, CloudFront, Cognito, NLB - Regions: us-east-1 (Cognito), ap-southeast-1 (main) - Total users: 1000+ - Monthly costs: $300-350 ## Key Learnings 1. Regional considerations - Cognito must be in us-east-1 for CloudFront - Main services in ap-southeast-1 for latency 2. Security best practices implemented - VPC isolation - Security group restrictions - IAM least-privilege - Secrets Manager for credentials 3. Cost optimization - CloudFront caching important - EC2 instances can be right-sized or use Reserved Instances - Reserved instances save 30-50% 4. Monitoring critical - CloudWatch alarms prevented many issues - X-Ray helped debug performance ## Recommendations for Next Phase 1. Setup automated backups for EC2 databases (pg_dump/mongodump cronjobs) 2. Implement CI/CD for automated deployments 3. Add comprehensive test suite 4. Setup on-call rotation \u0026amp; runbooks 5. Quarterly cost reviews Checklist - Cleanup Decision Before final cleanup, verify:\nAll data backed up Snapshots created CloudTrail logs archived Code pushed to GitHub Cost analysis completed Team trained on infrastructure Documentation complete Stakeholders approved DNS cutover plan (if applicable) Rollback plan documented Final Recommendations Keep infrastructure running (you\u0026rsquo;ve built it correctly) Implement automated scaling if needed Setup CI/CD pipeline for updates Add comprehensive testing Plan quarterly cost reviews Train team on operational procedures Consider disaster recovery plan Summary \u0026amp; Next Steps Congratulations! You\u0026rsquo;ve successfully:\n✓ Verified/setup Cognito authentication ✓ Verified/setup Lambda functions ✓ Verified/setup API Gateways ✓ Verified EC2 databases (PostgreSQL + MongoDB) ✓ Verified S3 \u0026amp; CloudFront ✓ Verified VPC \u0026amp; Security ✓ Implemented monitoring \u0026amp; logging ✓ Optimized costs This infrastructure can support:\n1000+ concurrent users 100K+ requests/day Highly available (multi-AZ capable) Scalable (auto-scale Lambda, upgrade EC2 instance types) Secure (VPC isolation, encryption, IAM) Observable (comprehensive logging \u0026amp; monitoring) Final Outcomes After completing Module 10, you will have:\nResource inventory \u0026amp; usage analyzed Cost optimization strategies identified Unused resources identified for cleanup Backup procedures implemented Cost reduction plan created (up to 36% savings possible) Post-mortem \u0026amp; lessons learned documented Recommendations for next phase Workshop complete \u0026amp; infrastructure production-ready "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives Strengthen understanding of API Gateway fundamentals and integration mechanisms. Build and deploy Lambda functions that parse Excel files and load the data into DynamoDB. Implement full CRUD operations using Lambda and DynamoDB. Configure API Gateway and validate Lambda execution through Postman. Learn and apply request body validation using API Gateway Models. Tasks Completed This Week Day Task Start Date Completion Date Reference Material 2 - Studied API Gateway fundamentals 10/11/2025 10/11/2025 https://youtu.be/YjOjDtprDSo?si=NYb88SlpO2VMhLYx 3 - Created a Lambda function to process Excel uploads and store parsed data in DynamoDB 11/11/2025 11/11/2025 4 - Developed a Lambda function to perform CRUD operations on DynamoDB 12/11/2025 12/11/2025 5 - Configured API Gateway and tested Lambda endpoints using Postman 13/11/2025 13/11/2025 https://000079.awsstudygroup.com/ 6 - Implemented body validation using API Gateway Models 14/11/2025 14/11/2025 https://youtu.be/tmhZbcqlEiQ?si=MBkltclc2rWTlHKr Week 10 Outcomes Strengthened understanding of API Gateway’s architecture and request flow. Built a Lambda function capable of reading Excel files and saving structured data to DynamoDB. Developed complete CRUD features using Lambda + DynamoDB. Successfully configured and validated API Gateway endpoints through Postman. Applied API Gateway Models to enforce request body validation for more reliable API interactions. "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives Strengthen understanding of DevOps practices on AWS: Infrastructure as Code (IaC) Container services and orchestration Monitoring \u0026amp; Observability tools Deploy APIs across multiple environments using Stage Variables Learn and implement Canary Deployment on API Gateway Use the ANY method in API Gateway for flexible endpoint handling Study Route 53 and learn how DNS routing works on AWS Tasks Completed This Week Day Task Start Date Completion Date Reference Material 2 - Studied AWS DevOps components:\n+ IaC\n+ Container Services\n+ Monitoring \u0026amp; Observability 17/11/2025 17/11/2025 3 - Used Stage Variables to deploy APIs across multiple environments 18/11/2025 18/11/2025 https://youtu.be/nubjfS50wFg?si=XQsWE01pyAtyrJh8 4 - Practiced Canary Deployment on API Gateway 19/11/2025 19/11/2025 https://youtu.be/BAjj_XUXnVA?si=21aaQMnOoLTGAeGk 5 - Applied the ANY Method in API Gateway for dynamic routing 20/11/2025 20/11/2025 https://youtu.be/nXqXJPepMJU?si=mwUbp48qdAHSHaT7 6 - Learned about Route 53 and DNS routing concepts 21/11/2025 21/11/2025 https://youtu.be/JRZiQFVWpi8?si=hIE5i0OnqhTw-5nI Week 11 Outcomes Gained deeper knowledge of DevOps concepts on AWS, including IaC, container technologies, and monitoring tools. Deployed APIs in multiple environments using Stage Variables. Implemented Canary Deployment to roll out updates safely. Used the ANY Method on API Gateway for flexible endpoint configuration. Studied DNS routing with Amazon Route 53 and understood its core mechanisms. "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Objectives Learn the core concepts of CloudFront and understand its pricing structure. Build foundational knowledge of Docker and the containerization workflow. Study Amazon ECR and practice pushing Docker images to an ECR repository. Develop an Auto Scoring Lambda function to process data using ML model predictions. Add functionality to store Auto Scoring results into DynamoDB. Tasks Completed This Week Day Task Start Date Completion Date Reference Material 2 - Studied CloudFront and its pricing model 24/11/2025 24/11/2025 3 - Learned how to use Docker 25/11/2025 25/11/2025 4 - Explored Amazon ECR and practiced pushing Docker images to ECR 26/11/2025 26/11/2025 5 - Built the Auto Scoring Lambda function 27/11/2025 27/11/2025 6 - Added DynamoDB integration to store Auto Scoring results 28/11/2025 28/11/2025 Week 12 Outcomes Gained a clear understanding of CloudFront’s architecture and pricing model. Learned Docker fundamentals, including image building and container execution. Successfully pushed Docker images to Amazon ECR using AWS CLI commands. Implemented an Auto Scoring Lambda function capable of running ML-based predictions. Integrated DynamoDB for storing and retrieving Auto Scoring results. "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/aws_resources_inventory/","title":"","tags":[],"description":"","content":"AWS Resources Inventory - Smoking Cessation Platform Cập nhật: 2025-12-03\nArchitecture Type: HYBRID (EC2 + Lambda + Managed Services) This platform uses a hybrid architecture combining:\nAlways-on EC2 servers for main applications Serverless Lambda for event-driven tasks Managed services for CDN, authentication, load balancing Account Information Account ID: 140570829989 User: AdminUser (IAM) Regions: us-east-1 (Cognito), ap-southeast-1 (main infrastructure)\nS3 Buckets Bucket Name Region Created Purpose leaflungs-frontend-new us-east-1 2025-11-24 Frontend hosting leaflungs-images ap-southeast-1 2025-11-25 Chat/message images leaflungs-images-sg ap-southeast-1 2025-11-30 Image storage Cognito User Pool:\nID: us-east-1_dskUsnKt3 Name: leaflungs-user-pool Region: us-east-1 Created: 2025-11-24 Last Modified: 2025-11-25 EC2 Instances (Hybrid Architecture) ap-southeast-1 (4 instances - t4g.small) Database Tier (leaflungs-db-sg):\nInstance ID Name IP Address Type Status Created i-0d82a626b99a2fecd DB-PG 172.0.8.55 t4g.small running 2025-11-30 i-0374ff6972fd306fe DB-Mongo 172.0.8.124 t4g.small running 2025-12-02 Application Tier (leaflungs-backend-sg):\nInstance ID Name IP Address Type Status Created i-01dd1a4b2b8b4a41f user-cessation 172.0.3.240 t4g.small running 2025-11-30 i-059fae7766eb52ae3 social-media 172.0.3.236 t4g.small running 2025-12-02 Lambda Functions (Event-driven) us-east-1 (1 function) Function Name Runtime Last Modified Role CognitoPostConfirmationTrigger nodejs20.x 2025-11-24 CognitoPostConfirmationLambdaRole ap-southeast-1 (4 functions) Function Name Runtime Last Modified Role Purpose AdminManageCoachesFunction nodejs20.x 2025-12-01 AdminOperationsLambdaRole Admin operations PaymentFunction nodejs24.x 2025-11-30 ? Payment processing leaflungs-websocket-authorizer nodejs20.x 2025-12-02 ? WebSocket auth image-upload-lambda nodejs20.x 2025-11-30 ImageUploadLambdaRole File uploads API Gateways (ap-southeast-1) API Name ID Created Type LeafLungs-UserInfo-API v7agf76rrh 2025-11-24 REST API leaflungs-chat-api vuds39de1b 2025-12-02 REST API + WebSocket Load Balancers (ap-southeast-1) Name Type Status Purpose leaflungs-userinfo-nlb Network active WebSocket chat endpoint VPC \u0026amp; Networking (ap-southeast-1) VPC VPC ID: vpc-046dc916dde2fb93f Name: project-bundau-milo CIDR: 172.0.0.0/18 Security Groups Group ID Name Purpose sg-012293e2687464913 launch-wizard-1 Default sg-0cf34158cb7f5440b leaflungs-backend-sg Backend Lambda sg-0adb5d7ea1fe0f6bb leaflungs-nlb-sg NLB (WebSocket) sg-027ef04aa3c769ecf leaflungs-db-sg EC2 Database Instances sg-0d2dbd7d32700d8c8 default Default EC2 Database Servers Status: DEPLOYED\nInstance ID Name Type IP Database Status i-01dd1a4b2b8b4a41f DB-PG t4g.small 172.0.8.55 PostgreSQL Running i-012ab3c4d5e6f7g8h0 DB-Mongo t4g.small 172.0.8.124 MongoDB Running CloudFront Distribution ID Domain Status E1NREZDKTJH6Y9 d2yo2hr161ib8h.cloudfront.net Deployed IAM Roles Role Name Created AdminOperationsLambdaRole 2025-12-01 AWSServiceRoleForAPIGateway 2025-11-23 CognitoPostConfirmationLambdaRole 2025-11-24 ImageUploadLambdaRole 2025-11-25 Environment Variables Status From .env file:\nCOGNITO_USER_POOL_ID=us-east-1_dskUsnKt3 ✓ EXISTS COGNITO_CLIENT_ID=4175kqc33olfjinhkll4jme379 ✓ EXISTS COGNITO_REGION=us-east-1 ✓ S3_BUCKET_NAME=leaflungs-frontend-new ✓ EXISTS CLOUDFRONT_DISTRIBUTION_ID=E1NREZDKTJH6Y9 ✓ EXISTS CLOUDFRONT_DOMAIN=d2yo2hr161ib8h.cloudfront.net ✓ VITE_API_GATEWAY_URL=https://v7agf76rrh.execute-api.ap-southeast-1.amazonaws.com/prod ✓ EXISTS VITE_CHAT_API_URL=https://vuds39de1b.execute-api.ap-southeast-1.amazonaws.com/prod ✓ EXISTS VITE_CHAT_WS_URL=https://leaflungs-userinfo-nlb-3c1d58c7a3d41477.elb.ap-southeast-1.amazonaws.com/ws ✓ EXISTS Outstanding Items Needed EC2 Database configuration verification - DEPLOYED Verify PaymentFunction Lambda role - UNKNOWN Verify leaflungs-websocket-authorizer Lambda role - UNKNOWN Verify API Gateway resources \u0026amp; methods Verify WebSocket integration Verify Cognito client configuration Database schema \u0026amp; migration scripts - CHECK IF EXISTS Next Steps Module 3: Verify Cognito configuration Module 4: Verify Lambda functions \u0026amp; roles Module 5: Verify API Gateway setup Module 6: Verify EC2 Database Servers (PostgreSQL + MongoDB) Module 7: Verify S3 \u0026amp; CloudFront Module 8: Verify VPC \u0026amp; Security Groups Module 9: Setup Monitoring (CloudWatch, CloudTrail) Module 10: Cost optimization \u0026amp; cleanup Notes Mixed regions: Cognito in us-east-1, most services in ap-southeast-1 WebSocket via NLB (not API Gateway WebSocket) All major resources already created - workshop will focus on verification \u0026amp; documentation "},{"uri":"https://thienluhoan.github.io/workshop-template/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://thienluhoan.github.io/workshop-template/tags/","title":"Tags","tags":[],"description":"","content":""}]